{"version":2,"kind":"Notebook","sha256":"58bef56ec29cb52bc34809b5461a9a900cf9b12006bbd19310fcf7ad50631ddd","slug":"notebooks.era5-data-access","location":"/notebooks/era5_data_access.ipynb","dependencies":[],"frontmatter":{"title":"ERA5","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"snow-cookbook-test","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"source_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/era5_data_access.ipynb","edit_url":"https://github.com/SnowEx/snow-cookbook/edit/HEAD/notebooks/era5_data_access.ipynb","exports":[{"format":"ipynb","filename":"era5_data_access.ipynb","url":"/snow-cookbook/_preview/36/build/era5_data_access-0f4febb676a4dbb8bd50a96ec5e54f2c.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This is a script designed to obtain snow data from the ERA5 reanalysis product. We will be using the Copernicus API to get global, daily snow cover and snow depth information.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"y6UiX9uWnu"}],"key":"OfJx9f7nQH"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This code is adapted from Tasha Snow’s ERA5 downloading script: ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"rPwwkK1SOp"},{"type":"link","url":"https://github.com/tsnow03/Landsat_SST_algorithm/blob/main/ERADownload.ipynb","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"ERADownload.ipynb","key":"wdFOSSXkS6"}],"urlSource":"https://github.com/tsnow03/Landsat_SST_algorithm/blob/main/ERADownload.ipynb","data":{"kind":"file","org":"tsnow03","repo":"Landsat_SST_algorithm","reference":"main","file":"ERADownload.ipynb","raw":"https://raw.githubusercontent.com/tsnow03/Landsat_SST_algorithm/main/ERADownload.ipynb"},"internal":false,"protocol":"github","key":"UXZHETvE2i"}],"key":"OpPLl1kA6c"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The Copernicus Climate Data Store (CDS) API is not on CryoCloud by default, so the following cell needs to be run, followed by restarting the kernel.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"RVLAbdbjjM"}],"key":"giidWRf3yo"}],"key":"PaslNqVcwE"},{"type":"block","kind":"notebook-content","children":[],"key":"qsVxbr9Vty"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To use the CDS API, the user needs credentials to the Copernicus Climate Data Store (CDS). Upon getting a user ID (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LnB0RMDit3"},{"type":"inlineCode","value":"uid","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TBLq2l1L8T"},{"type":"text","value":") and an API key (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QonFyaEj8Y"},{"type":"inlineCode","value":"api-key","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"WE20wYbYuZ"},{"type":"text","value":"), they need to run the following cell (skip if you already have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"n1VcKVN14g"},{"type":"inlineCode","value":"./cdsapirc","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nahTeVvVxY"},{"type":"text","value":" in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OHVpCvB51o"},{"type":"inlineCode","value":"/home/jovyan/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"l8ttHjhXEw"},{"type":"text","value":" directory).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jIfXqWkgFA"}],"key":"ZX27jeeUr0"}],"key":"kTHlW5QPCh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# !echo url: https://cds.climate.copernicus.eu/api/v2 >> /home/jovyan/.cdsapirc\n# !echo key: {uid}:{api-key} >> /home/jovyan/.cdsapirc","key":"r4hBpjmlhI"},{"type":"output","id":"pKttPkBWdNvRkE7IY8NZ6","data":[],"key":"xz9dKasGhx"}],"key":"eIsG2e1mSs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from ecmwfapi import ECMWFDataServer # Need a ecmwf user name and password first\nimport cdsapi ","key":"SkG2V9BPjx"},{"type":"output","id":"neqkrGjLb9uzPlnKvAg00","data":[],"key":"ALlDHyGI92"}],"key":"C3OZnp0wYE"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The CDS API can be a bit picky with inputs from ERA5, so first-time users are encouraged to use the online request form (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DaCkiVLufG"},{"type":"link","url":"https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"https://​cds​.climate​.copernicus​.eu​/datasets​/reanalysis​-era5​-single​-levels​?tab​=​download","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FhkXt3D4of"}],"urlSource":"https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download","key":"YXw0PyxvMd"},{"type":"text","value":") to automatically generate a code for their API request, to ensure that the syntax is correct.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"qmpUvz3Jgm"}],"key":"sErivA9v3a"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The below functions retrieve ERA5 snow depth and snow density and download them to a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NKxWMFB2wK"},{"type":"inlineCode","value":"tmp/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"KC4v2PBnsc"},{"type":"text","value":" folder. Additional parameters to consider:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xuY2EVwkeL"}],"key":"IJMilN5qhm"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"yearStart","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"dxe7Nqq65y"},{"type":"text","value":" and ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"UhD22LjHlx"},{"type":"inlineCode","value":"yearEnd","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"H9uRbhkXPA"},{"type":"text","value":": Start and end year.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"ZcgjjmXkM8"}],"key":"Kqzo582Q4Z"}],"key":"hoZ3Qy0eP6"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"monthStart","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"KSb8HdCgG8"},{"type":"text","value":" and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"A7uQdo28Jt"},{"type":"inlineCode","value":"monthEnd","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"T8WYcJTItY"},{"type":"text","value":": Start and end month.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RHUDZ8Z345"}],"key":"qRRSrhqD4K"}],"key":"Bx71at6XHI"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"paragraph","children":[{"type":"inlineCode","value":"dayStart","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"c8bibPruln"},{"type":"text","value":" and ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"PMCfoeJpfN"},{"type":"inlineCode","value":"dayEnd","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"MHFdrsmH88"},{"type":"text","value":": Start and end day.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"UFw5dt6Fcs"}],"key":"X1ix1gfqd7"}],"key":"nu6kilKeDZ"}],"key":"B4W5vcyrHj"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"The function currently grabs daily data from March 1, 2020 - April 30, 2020 at 12:00 UTC each day, and downloads as daily netCDF files. Because ERA5 is generated hourly, users can expand the ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"eOUEeVep0A"},{"type":"inlineCode","value":"time","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"yOU0zM9aXP"},{"type":"text","value":" entry to include more hours per day.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Dlf4A4LS42"}],"key":"SgiuQCOtBz"}],"key":"OTWsxzoP4T"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# from pathlib import Path\n\n# # Initialize the CDS API\n# c = cdsapi.Client()\n\n# def retrieve_era5():\n#     \"\"\"      \n#        A function to demonstrate how to iterate efficiently over several years and months etc    \n#        for a particular ERA5 request.\n#     \"\"\"\n#     yearStart = 2020\n#     yearEnd = 2020\n#     monthStart = 3\n#     monthEnd = 3\n#     dayStart = 1\n#     dayEnd = 31\n#     for year in list(range(yearStart, yearEnd + 1)):\n#         for month in list(range(monthStart, monthEnd + 1)):\n#             for day in list(range(dayStart, dayEnd + 1)):\n#                 startDy = '%02d' % (day)\n#                 startMo = '%02d' % (month)\n#                 startYr = '%04d' % (year)\n#                 tmp_dir = Path.cwd() / \"tmp\"\n#                 tmp_dir.mkdir(exist_ok=True)\n#                 target = f\"{tmp_dir}/era5_SWE_{startYr}{startMo}{startDy}.nc\"\n#                 era5_request(startYr, startMo, startDy, target)\n\n# def era5_request(startYr, startMo, startDy, target):\n#     \"\"\"      \n#         Helper function for era5_retrieve. An ERA-5 request for snow\n#         depth and snow cover data for the given years/months/days.\n\n#         Inputs\n#         ------------\n#         startYr: str\n#             Starting year of data query, in YYYY format.\n#         startMo: str\n#             Starting month of data query, in MM format.\n#         startDy: str\n#             Starting day of data query, in DD format.\n#         target: str\n#             Path and name of netCDF file to be saved.\n#     \"\"\"\n#     c.retrieve(\n#     'reanalysis-era5-land',\n#     {\n#         'product_type':['reanalysis'],\n#         'data_format':'netcdf',\n#         'variable':['snow_depth', 'snow_cover'],\n#         'year':[startYr],\n#         'month':[startMo],\n#         'day':[startDy],\n#         'time':['12:00']\n#     },\n#     target)\n        \n# if __name__ == '__main__':\n#     retrieve_era5()","key":"Ee84772i8i"},{"type":"output","id":"PcftONlCok1hwv7cE69Uq","data":[],"key":"ZtEslNQ5Ht"}],"key":"GWhJwrALvq"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Depending on the number of files downloaded (31 in the case of the above example), it can take a while to download everything.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BowO6khGfj"}],"key":"nhW1uGW47n"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When it finishes, there should now be daily ERA5 data in netCDF format! To efficiently load all of this data, we are going to use Xarray and its ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"toyeMcHayg"},{"type":"inlineCode","value":"open_mfdataset()","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TBY5vmAT4O"},{"type":"text","value":" function.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"sArCngAts7"}],"key":"rDz1Sjl0WK"}],"key":"Ds9NoMBklH"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import os\nimport re\nimport zipfile\nimport xarray as xr\n\nfrom os import listdir\nfrom os.path import join","key":"XT8R1rXUTB"},{"type":"output","id":"_EQSmLXCfeMP3Nf0sSles","data":[],"key":"AzJ5AUSDTQ"}],"key":"zucOYpUpCw"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# def process_era5_data(tmp_path):\n#     # Find ERA5 Zip files in downloaded directory\n#     era5_files = [join(tmp_path,f) for f in listdir(tmp_path) if \"era5_\" in join(tmp_path, f)]\n    \n#     # Iteratively unzip each file and collect into a list\n#     tmp_files = era5_extract(era5_files, tmp_dir)\n\n#     print('------------')\n#     # Open all ERA5 files into single Xarray\n#     ds = xr.open_mfdataset(tmp_files)\n#     print(\"All data has been lazy-loaded into Xarray.\")\n\n#     # Remove extracted files, for cleanliness\n#     for file in tmp_files:\n#         os.remove(file)\n#     print(\"Extracted ERA-5 files deleted.\")\n\n#     return ds\n\n# def era5_extract(era5_files, tmp_dir):\n#     for file in era5_files:\n#         with zipfile.ZipFile(file, 'r') as zfile:\n#             print(f'Now extracting data for file: {file}')\n#             # Extract all files from current Zip file\n#             zfile.extractall(tmp_dir)\n\n#             # Rename output file to prevent overwriting\n#             outfile = join(tmp_dir, \"data_0.nc\")\n#             date_pattern = re.search(r'\\d{8}', file).group(0)\n#             newfile = join(tmp_dir, f'data_{date_pattern}.nc')\n#             os.rename(outfile, newfile)\n#             print(f'Data extracted and saved to file: data_{date_pattern}.nc')\n#             print(' ')\n\n#     # List of output files\n#     tmp_files = [join(tmp_dir,f) for f in os.listdir(tmp_dir) if \"data_\" in join(tmp_dir, f)]\n\n#     return tmp_files","key":"hvc5m2cIEp"},{"type":"output","id":"LWxJGRHSMmgfzzWxLnitm","data":[],"key":"HhPZnBgkgB"}],"key":"UgI0B1Rc8L"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# tmp_dir = Path.cwd() / \"tmp\"\n# ds = process_era5_data(tmp_dir)","key":"LM4VzfwX3x"},{"type":"output","id":"Nyl_zthVwvKZQUhNibEan","data":[],"key":"x6QznuRm87"}],"key":"tonnjPIhAe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# ds","key":"SsRsjZScH5"},{"type":"output","id":"WMhNblVrQJ7X0AEm5JNN5","data":[],"key":"bDD1Vf8Pz5"}],"key":"urHdMrmhkv"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Thanks to the above function, loading all of that data is pretty easy! However, it is important to note that the data is currently “lazy-loaded” - we can easily subset and resample the data for our needs, but we will need to load it into memory if we wish to make figures.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TAF1QsFEKb"}],"key":"drGdRXTNu8"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Fully loading the data as is can be time-consuming, so let’s reduce the data first, starting with making monthly means of snow depth.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AW1RD8cIfY"}],"key":"OcBKPPilnl"}],"key":"POyMuCZBTd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Calculate monthly mean snow depth and snow cover\n# era5_monthly = ds.resample(valid_time='1ME').mean()","key":"JFskCB70Ey"},{"type":"output","id":"eyrUWM18ZarBT7EteVK0F","data":[],"key":"DTSxu46rPL"}],"key":"BvtOydPPS3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Resampling to monthly means reduces the data volume by quite a bit, so let’s now look at global snow depth from the month of March. We will go ahead and load the result into memory using the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ccNRaY1ivn"},{"type":"inlineCode","value":"compute()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xier0m9XNb"},{"type":"text","value":" function.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HZr9qBhvHx"}],"key":"mDSflptekL"}],"key":"Fl5se1Bd8r"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Load March snow depths into memory\n# era5_sd_march = era5_monthly['snowc'].compute().squeeze()","key":"U3eEWd0ECA"},{"type":"output","id":"E4NAVS6U0hg5x__LsQ3aU","data":[],"key":"Ixse1S3Noo"}],"key":"WFGu5cIgjz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Finally, we can make a map figure showing global, monthly-averaged snow depth from ERA5.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ziOGjzw63Y"}],"key":"UkhArVG2Rn"}],"key":"qIpRV2xpKa"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# import matplotlib.pyplot as plt\n\n# fig, ax = plt.subplots()\n# era5_sd_march.plot.imshow(ax=ax, cmap='Blues')\n# ax.set_xlabel(\"Longitude\", fontsize=12)\n# ax.set_ylabel(\"Latitude\", fontsize=12)\n# ax.set_title(\"ERA5 Snow Cover, March 2020\", fontsize=12)\n# fig.tight_layout()","key":"pZIqJqh2g7"},{"type":"output","id":"Cigl9tIJA77ilm9cZsVkh","data":[],"key":"XCZdEbPEUv"}],"key":"uOWLehNve3"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now for a different example. Here, we will examine snow depths over Alaska only, and generate a state-wide time series for the month of March.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"wnS9SvYMrM"}],"key":"Y74NEQqpFp"}],"key":"ZVuDUUG8s9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Making bounds for Alaska\n# mask_lon = (ds.longitude >= -168.75+360) & (ds.longitude <= -136.01+360)\n# mask_lat = (ds.latitude >= 52.64) & (ds.latitude <= 71.59)\n\n# # Subset ERA5 data to Alaska lats/lons only\n# era5_alaska = ds.where(mask_lon & mask_lat, drop=True)","key":"ghPzmgpZ00"},{"type":"output","id":"FiygLOPCaOodwk-DehhPc","data":[],"key":"A3mkKD8utu"}],"key":"dZ7lkCX1yP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As before, we need to load the Alaska data into memory. Because we are looking over a much smaller spatial domain, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RLMWrU4bGb"},{"type":"inlineCode","value":"compute()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hKq2L4x2UE"},{"type":"text","value":" will be much faster.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Xl1N8Zr0fw"}],"key":"FJtSn1iWnh"}],"key":"c1qVIja0C9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Load Alaska data into memory\n# era5_alaska = era5_alaska.compute().squeeze()","key":"hivSoxzCF5"},{"type":"output","id":"_Z6AT-TYrwkzdh_tgSMXP","data":[],"key":"oXoWf2xYMl"}],"key":"ndM6UmfsQX"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Again, we can make a map figure showing snow depth over the state of Alaska, this time for March 1, 2020:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EHFDNoUv2e"}],"key":"sWAKT8FQ4m"}],"key":"iHpqfdbCoP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Map plot of Alaska snow depths\n# era5_alaska['snowc'].isel(valid_time=0).plot.imshow(vmin=0, vmax=1, cmap=\"Blues\")","key":"mTestLXhtu"},{"type":"output","id":"Ckp82T6Yp4EJ4GwlUQe69","data":[],"key":"N83thr6yjh"}],"key":"qlPVffMb2Q"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can also create a spatially-averaged time series of snow depth over the state of Alaska for the entire time period March 1 - April 30:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sdHAXc5FhH"}],"key":"qoXJQDTGF5"}],"key":"L5s6nQ5E7W"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Calculate spatial average of snow depths over Alaska\n# era5_sd_alaska = era5_alaska['snowc'].mean(('longitude', 'latitude'))","key":"nEBV48sqv1"},{"type":"output","id":"Hf2rjoh5h-sC1R7kSYbXz","data":[],"key":"E9im6zk44d"}],"key":"K9qYgwPsuK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# # Time series plot of Alaska snow depths\n# fig, ax = plt.subplots()\n# era5_sd_alaska.plot(ax=ax)\n# ax.set_xlabel(\"Day\", fontsize=12)\n# ax.set_ylabel(\"Snow depth [m]\", fontsize=12)\n# ax.set_title(\"March 1 - April 30, 2020\", fontsize=12)\n# fig.tight_layout()","key":"MOtxnyW1SU"},{"type":"output","id":"uPSfLq__upFDb3n3n8y5I","data":[],"key":"s6jyHopCng"}],"key":"UZO1suAtwQ"}],"key":"ukTAU9TPU4"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"MERRA-2","url":"/notebooks/merra2-data-access","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}