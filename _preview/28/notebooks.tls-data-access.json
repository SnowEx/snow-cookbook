{"version":2,"kind":"Notebook","sha256":"05efc3d1b07660e2732c6347352fce2948a2e3ea8073ade49be56a38d1a9f731","slug":"notebooks.tls-data-access","location":"/notebooks/tls_data_access.ipynb","dependencies":[],"frontmatter":{"title":"Terrestrial Laser Scanning","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"source_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/tls_data_access.ipynb","edit_url":"https://github.com/SnowEx/snow-cookbook/edit/HEAD/notebooks/tls_data_access.ipynb","exports":[{"format":"ipynb","filename":"tls_data_access.ipynb","url":"/snow-cookbook/_preview/28/build/tls_data_access-06e73ef9ea19f85b54f3f6e79d3906ae.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"TWJz1mPDp4"}],"key":"G8yp6lRRnQ"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The TLS data is available through the cloud on NSIDC, so we will be using the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"lRK9RP0gKr"},{"type":"inlineCode","value":"earthaccess","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"y5AIn87r1B"},{"type":"text","value":" package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"O0hIY0kZTB"}],"key":"LA1MypW7IX"}],"key":"UXvWzELwU1"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install --upgrade earthaccess","key":"YXQQCtFxnS"},{"type":"output","id":"ToP9kG2m5hM5gI7UTZ638","data":[{"output_type":"stream","name":"stdout","text":"Collecting earthaccess\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading earthaccess-0.15.1-py3-none-any.whl.metadata (9.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting fsspec>=2025.2 (from earthaccess)\r\n  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting importlib-resources>=6.3.2 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting multimethod>=1.8 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\r\nCollecting pqdm>=0.1 (from earthaccess)\r\n  Downloading pqdm-0.2.0-py2.py3-none-any.whl.metadata (3.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting python-cmr>=0.10.0 (from earthaccess)\r\n  Downloading python_cmr-0.13.0-py3-none-any.whl.metadata (10 kB)\r\nRequirement already satisfied: requests>=2.26 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from earthaccess) (2.32.5)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting s3fs>=2025.2 (from earthaccess)\r\n  Downloading s3fs-2025.9.0-py3-none-any.whl.metadata (1.4 kB)\r\nCollecting tenacity>=9.0 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\r\nCollecting tinynetrc>=1.3.1 (from earthaccess)\r\n  Downloading tinynetrc-1.3.1-py2.py3-none-any.whl.metadata (2.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: typing-extensions>=4.10.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from earthaccess) (4.15.0)\r\nCollecting bounded-pool-executor (from pqdm>=0.1->earthaccess)\r\n  Downloading bounded_pool_executor-0.0.3-py3-none-any.whl.metadata (2.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tqdm (from pqdm>=0.1->earthaccess)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from python-cmr>=0.10.0->earthaccess) (2.9.0.post0)\r\nRequirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from python-dateutil<3.0.0,>=2.8.2->python-cmr>=0.10.0->earthaccess) (1.17.0)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from requests>=2.26->earthaccess) (3.4.4)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from requests>=2.26->earthaccess) (3.11)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from requests>=2.26->earthaccess) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from requests>=2.26->earthaccess) (2025.10.5)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2025.2->earthaccess)\r\n  Downloading aiobotocore-2.25.0-py3-none-any.whl.metadata (25 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2025.2->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiohttp-3.13.2-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2025.2->earthaccess)\r\n  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting botocore<1.40.50,>=1.40.46 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2025.2->earthaccess)\r\n  Downloading botocore-1.40.49-py3-none-any.whl.metadata (5.7 kB)\r\nCollecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2025.2->earthaccess)\r\n  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2025.2->earthaccess)\r\n  Downloading multidict-6.7.0-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2025.2->earthaccess)\r\n  Downloading wrapt-1.17.3-cp314-cp314-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\r\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess)\r\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: attrs>=17.3.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess) (25.4.0)"},{"output_type":"stream","name":"stdout","text":"\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess)\r\n  Downloading frozenlist-1.8.0-cp314-cp314-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess)\r\n  Downloading propcache-0.4.1-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2025.2->earthaccess)\r\n  Downloading yarl-1.22.0-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading earthaccess-0.15.1-py3-none-any.whl (70 kB)\r\nDownloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\r\nDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading multimethod-2.0-py3-none-any.whl (9.8 kB)\r\nDownloading pqdm-0.2.0-py2.py3-none-any.whl (6.8 kB)\r\nDownloading python_cmr-0.13.0-py3-none-any.whl (14 kB)\r\nDownloading s3fs-2025.9.0-py3-none-any.whl (30 kB)\r\nDownloading aiobotocore-2.25.0-py3-none-any.whl (86 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading aiohttp-3.13.2-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading botocore-1.40.49-py3-none-any.whl (14.1 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/14.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m209.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\nDownloading multidict-6.7.0-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (248 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading wrapt-1.17.3-cp314-cp314-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (87 kB)\r\nDownloading yarl-1.22.0-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (372 kB)\r\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\nDownloading frozenlist-1.8.0-cp314-cp314-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (231 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading propcache-0.4.1-cp314-cp314-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (201 kB)\r\nDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\r\nDownloading tinynetrc-1.3.1-py2.py3-none-any.whl (3.9 kB)\r\nDownloading bounded_pool_executor-0.0.3-py3-none-any.whl (3.4 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tinynetrc, bounded-pool-executor, wrapt, tqdm, tenacity, propcache, multimethod, multidict, jmespath, importlib-resources, fsspec, frozenlist, aioitertools, aiohappyeyeballs, yarl, python-cmr, pqdm, botocore, aiosignal, aiohttp, aiobotocore, s3fs, earthaccess\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/23\u001b[0m [multidict]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/23\u001b[0m [fsspec]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/23\u001b[0m [aioitertools]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m17/23\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m17/23\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m17/23\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m19/23\u001b[0m [aiohttp]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m20/23\u001b[0m [aiobotocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [earthaccess]\r\n\u001b[?25h\r\u001b[1A\u001b[2KSuccessfully installed aiobotocore-2.25.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aioitertools-0.12.0 aiosignal-1.4.0 botocore-1.40.49 bounded-pool-executor-0.0.3 earthaccess-0.15.1 frozenlist-1.8.0 fsspec-2025.9.0 importlib-resources-6.5.2 jmespath-1.0.1 multidict-6.7.0 multimethod-2.0 pqdm-0.2.0 propcache-0.4.1 python-cmr-0.13.0 s3fs-2025.9.0 tenacity-9.1.2 tinynetrc-1.3.1 tqdm-4.67.1 wrapt-1.17.3 yarl-1.22.0\r\n"}],"key":"nIyr0QEsY3"}],"key":"PVR86PLu5T"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import earthaccess\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport shutil\nimport tempfile\nimport xarray as xr","key":"aeLTfdaLHb"},{"type":"output","id":"TFkVBzPepqWydYhfMEU6B","data":[{"output_type":"stream","name":"stderr","text":"/home/runner/micromamba/envs/cookbook-dev/lib/python3.14/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"},{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mearthaccess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"Im6DuUpFbw"}],"key":"I6KeWjYEtN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QnFuiTE2vq"}],"key":"iVVIs9lmF9"}],"key":"If9rXQpWrD"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate with Earthdata Login servers\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for snow-on granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-15', '2023-03-15'),\n)","key":"wqjz2TqKuH"},{"type":"output","id":"JV97qSeE-6nMFoWsz3zCE","data":[],"key":"iA1kgZIwAW"}],"key":"RmjPkRFMR0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TWiEwojZSO"},{"type":"inlineCode","value":"rioxarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QoTJ0csVII"},{"type":"text","value":"!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N2H2QdzxHd"}],"key":"rd0JA3CotP"}],"key":"PcMEeQoiSO"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Load a single TLS scan\nfiles = earthaccess.open(results)\nsnow_on = rxr.open_rasterio(files[1])","key":"LvMhgsKmKZ"},{"type":"output","id":"Ipy-W5JxFKTt3WTapwfYv","data":[],"key":"RVPJt9qQqK"}],"key":"l0n7XXwMu5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_on.rio.width","key":"woBdM6hK59"},{"type":"output","id":"QZAeYq82jV-kACnlNyb71","data":[],"key":"Vn9nAM3hKp"}],"key":"rE0k5mzfIg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"AIgY9nhkcR"},{"type":"output","id":"XQMUZaCkoSrw0IjxzJ8cB","data":[],"key":"dXsQwTvcI9"}],"key":"NrciuBKNVC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Two things are noticeable from this TLS data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zxxHRF4Gu6"}],"key":"Fo3PSqqQVS"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"It has a very high resolution (0.15 m).","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jTtCElntfT"}],"key":"hkKa4udouM"}],"key":"PAKQmlJ2zL"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"paragraph","children":[{"type":"text","value":"The signal attenutates after ~60 m, so we have a small field of view.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"epmhkfZE5Y"}],"key":"GchbEYPho5"}],"key":"Tx16P1FKPB"}],"key":"TmAX4MsgcA"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"IHdLq17Rvv"}],"key":"kVvokaz8Im"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In any case, let’s grab the snow-off data from the same location, and try to derive snow depth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"zkqm9r4arq"}],"key":"Cii3kecWrW"}],"key":"Zdwb2aI38r"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Now search for snow-off granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-25', '2022-10-25'),\n)","key":"tTXaZTuUQL"},{"type":"output","id":"1_eAa0WlRMb2otHP6-qRY","data":[],"key":"YmksNzPGtc"}],"key":"cHwvjaW1Ra"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"display(results)","key":"x4PBI3EMWg"},{"type":"output","id":"kyL75UmVSDYM5Qm-syw6U","data":[],"key":"xcJjq6chJQ"}],"key":"eGRwbsm0ma"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Again, load a single snow-off TLS scan\nfiles = earthaccess.open(results)\nsnow_off = rxr.open_rasterio(files[1])","key":"ZsQj7PhBVj"},{"type":"output","id":"q2kPTFyWSqB0C568DMj0A","data":[],"key":"Dv4DPqCFmc"}],"key":"YDHGeHGbXO"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"fYY5wHpSYq"},{"type":"output","id":"B7Vayf2X5kdayMGM1_SEL","data":[],"key":"fJxYRO3Ecj"}],"key":"SOEpicUVkV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"T2D8E0lZOP"}],"key":"DGkk9MWt1l"}],"key":"mxhg6XshIA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))","key":"nU5EuAFkN1"},{"type":"output","id":"fpf8Vz2Bv5wmDDaiQb5l3","data":[],"key":"bBnOEdDjbp"}],"key":"AVIlStmWi6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"NWInA7Guxf"},{"type":"output","id":"4wFh1CEgSdSsq44D0E2Bc","data":[],"key":"psJwBXMR2y"}],"key":"dehIHIypfB"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cGOn6vfRoC"}],"key":"qeU5UiAn0L"}],"key":"xXbNiuckHg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)","key":"ZdTGojygmJ"},{"type":"output","id":"ZAMzmh-Jaq8R-VS25Lqkm","data":[],"key":"JQy0p4uAJR"}],"key":"BF1aXd0E2p"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple Scans Example","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IFooQqeqaM"}],"identifier":"multiple-scans-example","label":"Multiple Scans Example","html_id":"multiple-scans-example","implicit":true,"key":"W3AmC2cxXo"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mJrMuHKZEE"}],"key":"Rib0Se5hwU"}],"key":"tWlTtqsiTf"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Search for snow-on granules\nsnow_on_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-01', '2023-03-31'),\n)\n\nsnow_off_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-01', '2022-10-31'),\n)","key":"QtF9HGceI2"},{"type":"output","id":"2GeOvurLE6fkJIEopk_zk","data":[],"key":"gePxAJHFCk"}],"key":"xLkGM0OZMg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create list of snow-on DataArrays\nsnow_on_files = earthaccess.open(snow_on_results)\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_files = earthaccess.open(snow_off_results)\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]","key":"ybR4wwplRh"},{"type":"output","id":"W_qbEo-wQcciDqCWRPuz0","data":[],"key":"MWqvjb1xuZ"}],"key":"jzrcmPdqS1"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Wz2Sa8MT2D"}],"key":"VOD9GPCt3V"}],"key":"SslIpBIR19"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snon_site_ids = []\nsnoff_site_ids = []\n# Get site IDs for each snow-on DataArray\nfor f in snow_on_files:\n    # Get path from file name\n    path = f.path\n    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off DataArray\nfor f in snow_off_files:\n    # Step 1: Extract path\n    path = f.path\n    # Step 2: Use regex to extract the site ID\n    # Pattern: _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(snon_site_ids)\nprint(snoff_site_ids)","key":"J3j8msoFMz"},{"type":"output","id":"ZxBqXsN6YYfb0k8qi3buo","data":[],"key":"HwD6Fj5dpt"}],"key":"JZ9AYjwupi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site","key":"Po2hBxCH5V"},{"type":"output","id":"-ynX9e0sq5o_OcpkDJooX","data":[],"key":"oLt4bCuHFH"}],"key":"IrYsUe8CR3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}","key":"XvO0dTkADD"},{"type":"output","id":"Fz3XfAJKAwNaXW5euYDaP","data":[],"key":"nJZyZJEgGA"}],"key":"SQWS6veR0D"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LuvNNyd9Fu"}],"key":"sa0AjE4soc"}],"key":"fMXKHsl6dJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)","key":"HLJ7wOUdn2"},{"type":"output","id":"-_4kQs92GwRCPW8IlWkI2","data":[],"key":"fgjxAvIrWy"}],"key":"b8PqToztTB"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]","key":"CH3LMEU3i8"},{"type":"output","id":"kxU4z9kyOcRLIbUYrvUvI","data":[],"key":"xsLfKXlmoT"}],"key":"kjjAKwi1xI"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"dZcBmTbyEV"}],"key":"IMHFNq9h6Z"}],"key":"FJN64PkJoU"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)","key":"aRQdqeod0a"},{"type":"output","id":"Al-Mg8dnGNmrqI4jci79o","data":[],"key":"zXChF2Cbk9"}],"key":"Zlspe8XPFq"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()","key":"Cbw5YXYoS5"},{"type":"output","id":"LFYGhRRSFiH9TVEWChdyp","data":[],"key":"Js4jsAnfLJ"}],"key":"DtDduMHxfk"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"y6Y5BBcF3y"}],"key":"e0boNHewhl"}],"key":"rteRhiQrDu"}],"key":"LtclnnmmOq"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"AVIRIS-NG","url":"/notebooks/aviris-ng-data","group":"Observations"},"next":{"title":"Snow Depth Estimates with ICESat-2","url":"/notebooks/is2-snow-depth-workflow","group":"Observations"}}},"domain":"http://localhost:3000"}