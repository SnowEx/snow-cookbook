{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authentic-device",
   "metadata": {},
   "source": [
    "# Time-lapse Cameras\n",
    "\n",
    ":::{admonition} Learning Objectives\n",
    "\n",
    "**At the conclusion of this tutorial, you will...:**\n",
    "- Know about all the time-lapse images available from the SnowEx 2017 and 2020 field campaigns \n",
    "- View example time-lapse images from SnowEx 2020 and visualize their locations\n",
    "- Access snow depth measurements extracted from the SnowEx 2020 time-lapse images \n",
    "- Compare snow depths from different SnowEx 2020 time-lapse cameras \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-teens",
   "metadata": {},
   "source": [
    "## Time-lapse Cameras on Grand Mesa during SnowEx Field Campaigns\n",
    "Time-lapse cameras were installed in both the SnowEx 2017 and 2020 field campaigns on Grand Mesa in similar locations. \n",
    "\n",
    "**SnowEx 2017 Time-lapse Cameras** \n",
    "* 28 Total Time-lapse Cameras\n",
    "* Capturing the entire winter season (September 2016-June 2017)\n",
    "* Taking 4 photos/day at 8AM, 10AM, 12PM, 2PM, 4PM\n",
    "* An orange pole was installed in front of 15 cameras for snow depth measurements\n",
    "* Time-lapse images have been submitted to the NSIDC by Mark Raleigh with all the required metadata (e.g., locations, naming convention, etc.) for use. \n",
    "\n",
    "**SnowEx 2020 Time-lapse Cameras**\n",
    "* 29 Total Time-lapse Cameras\n",
    "* Capturing the entire winter season (September 2019-June 2020)\n",
    "* Taking 3 photos/day at 11AM, 12PM, 1PM or 2 photos/day at 11AM and 12PM\n",
    "* A red pole was installed in front of each camera for snow depth measurements.\n",
    "* Cameras were installed on the east and west side of the Grand Mesa, across a vegetation scale of 1-9, using the convention __XMR__:\n",
    "    * **X** = East (E) or West (W) areas of the Mesa\n",
    "    * **M** = number 1-9, representing 1 (least vegetation) to 9 (most vegetation). Within each vegetation class, there were three sub-classes of snow depths derived from 2017 SnowEx lidar measurements. \n",
    "    * **R** = Replicate of vegetation assignment, either A, B, C, D, or E. \n",
    "        \n",
    "* *The complete set of time-lapse images from 2020 are in progress for submission to the NSIDC. A subset of them are available here for you to use during hackweek.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-edwards",
   "metadata": {},
   "source": [
    "### An automated way of viewing and mapping time-lapse photos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-bahamas",
   "metadata": {},
   "source": [
    "**First, import all the packages we'll need for this tutorial**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3532c1-9e34-4650-9203-9ccd0a3e2ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "measurements = PointMeasurements()\n",
    "\n",
    "# Get the unique instrument in the table\n",
    "results = measurements.all_instruments\n",
    "print('\\nAvailable Instruments = {}'.format(', '.join([str(r) for r in results])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SnowEx database package for point-based data (applies for camera data)\n",
    "from snowexsql.api import PointMeasurements\n",
    "\n",
    "# Packages for data analysis \n",
    "import geopandas as gpd # geopandas library for data analysis and visualization\n",
    "import pandas as pd # pandas as to read csv data and visualize tabular data\n",
    "import numpy as np # numpy for data analysis \n",
    "\n",
    "# Packages for data visualization\n",
    "import matplotlib.pyplot as plt # matplotlib.pyplot for plotting images and graphs\n",
    "\n",
    "plt.rcParams['figure.figsize']  = (10, 4) # figure size\n",
    "plt.rcParams['axes.titlesize']  = 14 # title size \n",
    "plt.rcParams['axes.labelsize']  = 12 # axes label size \n",
    "plt.rcParams['xtick.labelsize'] = 11 # x tick label size \n",
    "plt.rcParams['ytick.labelsize'] = 11 # y tick label size \n",
    "plt.rcParams['legend.fontsize'] = 11 # legend size \n",
    "mpl.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0f7c6f-0fe2-4bb3-b0c6-9283d039799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the database for camera-based snow depths\n",
    "camera_depths = measurements.from_filter(\n",
    "    type=\"depth\",\n",
    "    site_name=\"Grand Mesa\",\n",
    "    instrument=\"camera\"\n",
    ")\n",
    "\n",
    "camera_depths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modern-airport",
   "metadata": {},
   "source": [
    "#### Plot the camera locations, using snow pit locations for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e058b412-44b5-4606-bdeb-fe1d495048db",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_depths.explore(tooltip=['equipment','date','latitude','longitude','value','type','units'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-revolution",
   "metadata": {},
   "source": [
    "### Viewing the time-lapse photos\n",
    "**Download the sample datasets for this tutorial** \\\n",
    "For ease of access during the hackweek, sample files are available for download for running the command in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a81e7-9e75-433c-9c2b-fa2c37116f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "\n",
    "# Authenticate with Earthdata Login servers\n",
    "auth = earthaccess.login(strategy=\"interactive\")\n",
    "\n",
    "# Search for snow-on granules\n",
    "results = earthaccess.search_data(\n",
    "    doi = \"10.5067/WYRNU50R9L5R\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc2ecd-cee4-40d3-8c97-55a0f6dd1f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = earthaccess.open(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d24841-5cc4-4141-96eb-7a75526b23d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_files = earthaccess.download(\n",
    "    results[0],\n",
    "    local_path = \"C:/Users/zfair/OneDrive - NASA/Documents/Python/Projects/SnowPit/Workflows/tmp\", # Change this string to download to a different path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e75bf3-1f4e-4d27-b81d-8b2519d7796d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Improved way to work with camera files directly - WORK IN PROGRESS\n",
    "import requests\n",
    "from io import BytesIO\n",
    "\n",
    "# Get the URL of the zip file from the collection metadata\n",
    "zip_url = 'https://n5eil01u.ecs.nsidc.org/DP6/SNOWEX/SNEX_Met_Raw.001/2016.10.09/SNEX_Met_Raw.zip' \n",
    "\n",
    "# Download the zip file\n",
    "response = requests.get(zip_url)\n",
    "response.raise_for_status()\n",
    "\n",
    "# Open the zip file in memory\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as z:\n",
    "    # List all files in the zip archive\n",
    "    file_list = z.namelist()\n",
    "    print(\"Files in the archive:\", file_list)\n",
    "    \n",
    "    # Extract CSV files\n",
    "    for file_name in file_list:\n",
    "        if file_name.endswith('.csv'):\n",
    "            with z.open(file_name) as csv_file:\n",
    "                # Read the CSV content\n",
    "                csv_data = csv_file.read().decode('utf-8')\n",
    "                print(f\"Contents of {file_name}:\\n\", csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471e416d-e1ef-4c39-a899-8498e2b72905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "path = \"/tmp\"\n",
    "\n",
    "with tarfile.open(downloaded_files[0], \"r:gz\") as tar:\n",
    "    tar.extractall(path=path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-albuquerque",
   "metadata": {},
   "source": [
    "**Now display an example time-lapse image inside the notebook**\n",
    "\n",
    "\n",
    "We will now pull time-lapse imagery for one camera, camera E9B, from the SnowEx 2020 field campaign. E9B is from the __E__ ast side of the Mesa, in a high vegetation area (__9__), and it is the second replicate of this combination (__B__). We will pull images and display a sample from various times of the winter season to provide a sense of what image and the snow poles look like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00fcca8-5efc-4c45-9893-b0020882bc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from IPython.display import Image, display\n",
    " \n",
    "files = ['C:/Users/zfair/OneDrive - NASA/Documents/Python/Projects/SnowPit/Workflows/tmp/TLS-L2E/WSCT1463.JPG',\n",
    "         'C:/Users/zfair/OneDrive - NASA/Documents/Python/Projects/SnowPit/Workflows/tmp/TLS-L2E/WSCT1644.JPG',\n",
    "         'C:/Users/zfair/OneDrive - NASA/Documents/Python/Projects/SnowPit/Workflows/tmp/TLS-L2E/WSCT1844.JPG']\n",
    "for file in files:\n",
    "    creationTime = os.path.getmtime(file)\n",
    "    dt_c = datetime.datetime.fromtimestamp(creationTime)\n",
    "    formatted_datetime = dt_c.strftime(\"%m/%d/%Y %H:%M\")\n",
    "\n",
    "    print(f'Site L2E: {formatted_datetime}')\n",
    "    display(Image(file, width=300))\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-provider",
   "metadata": {},
   "source": [
    "## Time-lapse Camera Applications\n",
    "\n",
    "Installing snow poles in front of time-lapse camera provides low-cost, long-term snow depth timeseries. Snow depths from the 2020 SnowEx time-lapse imagery have been manually processed with estimation of submission to the NSIDC database in summer 2021. \n",
    "\n",
    "The snow depth is the difference between the number of pixels in a snow-free image and an image with snow, with a conversion from pixels to centimeters (**Figure 1**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-mayor",
   "metadata": {},
   "source": [
    "![equation](./images/time-lapse-camera/timelapse-camera-tutorial_27_0.png)\n",
    "\n",
    "**Figure 1: Equation to extract snow depth from camera images. For each image, take the difference in pixels between the length of a snow-free stake and the length of the stake and multiply by length(cm)/pixel. The ratio can be found by dividing the full length of the stake (304.8 cm) by the length of a snow-free stake in pixels.**\n",
    "\n",
    "Snow depth can be obtained in this manner manually, but it is now easier to determine the pixel size of the stakes through machine learning. For the sake of completeness, we will provide a brief example using the camera imagery above. Otherwise, users interested in using the camera imagery with machine learning are encouraged to check out the following resources by Katherine Breen and others:\n",
    "\n",
    "**Publication on method**  \n",
    "Breen C. M., W. R. Currier, C. Vuyovich, et al. 2024. \"Snow Depth Extraction From Time‚ÄêLapse Imagery Using a Keypoint Deep Learning Model.\" Water Resources Research 60 (7): [10.1029/2023wr036682]\n",
    "\n",
    "**Github page for algorithm**  \n",
    "https://github.com/catherine-m-breen/snowpoles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36ce93-f6be-4a0e-a89a-b187f3a54e16",
   "metadata": {},
   "source": [
    "In the example images above, we use the red pole in the fully snow-off and snow-on images for estimation.\n",
    "\n",
    "For the snow-off image, the length of the red pole is **136 pixels**. If we assume that the pole is 304.8 cm in length, then each pixel is approximately **2.24 cm** in length.\n",
    "\n",
    "For the snow-on image, the length of the red pole is **72 pixels**, much shorter than the snow-off length. So, there is a **~64 pixel** difference between the snow-on and snow-off lengths. Using the equation in Figure 1, we can calculate snow depth:\n",
    "\n",
    "Depth = 2.24 * (136-72) = **143.36 cm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-reviewer",
   "metadata": {},
   "source": [
    "*Acknowledgements: Anthony Arendt, Scott Henderson, Micah Johnson, Carrie Vuyovich, Ryan Currier, Megan Mason, Mark Raleigh*\n",
    "\n",
    "**Additional References**\\\n",
    "Dickerson-Lange et al., 2017. *Snow disappearance timing is dominated by forest effects on snow accumulation in warm winter climates of the Pacific Northwest, United States.* Hydrological Processes. Vol 31, Issue 10. 13 February 2017. https://doi.org/10.1002/hyp.11144\n",
    "\n",
    "Raleigh et al., 2013. *Approximating snow surface temperature from standard temperature and humidity data: New possibilities for snow model and remote sensing evaluation*. Water Resources Research. Vol 49, Issue 12. 07 November 2013.  https://doi.org/10.1002/2013WR013958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e629a55-56be-4c80-91a8-40ccd16638e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
