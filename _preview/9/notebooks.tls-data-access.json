{"version":2,"kind":"Notebook","sha256":"05efc3d1b07660e2732c6347352fce2948a2e3ea8073ade49be56a38d1a9f731","slug":"notebooks.tls-data-access","location":"/notebooks/tls_data_access.ipynb","dependencies":[],"frontmatter":{"title":"Terrestrial Laser Scanning","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/tls_data_access.ipynb","exports":[{"format":"ipynb","filename":"tls_data_access.ipynb","url":"/snow-cookbook/_preview/9/build/tls_data_access-b8de13b8174db30640fa07fdce231f8d.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"WWoDeo3qYm"}],"key":"xP1JJceoAl"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The TLS data is available through the cloud on NSIDC, so we will be using the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"BfzYYSPsZB"},{"type":"inlineCode","value":"earthaccess","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WvwOkVXCn1"},{"type":"text","value":" package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"hgayNY205u"}],"key":"x9zDUC8h4s"}],"key":"GaIfwl8rum"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install --upgrade earthaccess","key":"adswvNb3oP"},{"type":"output","id":"nrRrENbiJOfcroV58ox3U","data":[{"output_type":"stream","name":"stdout","text":"Collecting earthaccess\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading earthaccess-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting fsspec>=2022.11 (from earthaccess)\r\n  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting importlib-resources>=6.3.2 (from earthaccess)\r\n  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multimethod>=1.8 (from earthaccess)\r\n  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting pqdm>=0.1 (from earthaccess)\r\n  Downloading pqdm-0.2.0-py2.py3-none-any.whl.metadata (3.2 kB)\r\nCollecting python-cmr>=0.10.0 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading python_cmr-0.13.0-py3-none-any.whl.metadata (10 kB)\r\nRequirement already satisfied: requests>=2.26 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (2.32.5)\r\nCollecting s3fs>=2022.11 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\r\nCollecting tinynetrc>=1.3.1 (from earthaccess)\r\n  Downloading tinynetrc-1.3.1-py2.py3-none-any.whl.metadata (2.9 kB)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (4.14.1)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting bounded-pool-executor (from pqdm>=0.1->earthaccess)\r\n  Downloading bounded_pool_executor-0.0.3-py3-none-any.whl.metadata (2.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tqdm (from pqdm>=0.1->earthaccess)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-cmr>=0.10.0->earthaccess) (2.9.0.post0)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->python-cmr>=0.10.0->earthaccess) (1.17.0)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2025.8.3)\r\nCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiobotocore-2.24.1-py3-none-any.whl.metadata (25 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2022.11->earthaccess)\r\n  Downloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting botocore<1.39.12,>=1.39.9 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\r\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: attrs>=17.3.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess) (25.3.0)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading earthaccess-0.14.0-py3-none-any.whl (64 kB)\r\nDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\nDownloading multimethod-2.0-py3-none-any.whl (9.8 kB)\r\nDownloading pqdm-0.2.0-py2.py3-none-any.whl (6.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading python_cmr-0.13.0-py3-none-any.whl (14 kB)\r\nDownloading s3fs-2025.7.0-py3-none-any.whl (30 kB)\r\nDownloading aiobotocore-2.24.1-py3-none-any.whl (85 kB)\r\nDownloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\nDownloading botocore-1.39.11-py3-none-any.whl (13.9 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m224.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\r\nDownloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\r\nDownloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\r\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\nDownloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\nDownloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\r\nDownloading tinynetrc-1.3.1-py2.py3-none-any.whl (3.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading bounded_pool_executor-0.0.3-py3-none-any.whl (3.4 kB)\r\nUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tinynetrc, bounded-pool-executor, wrapt, tqdm, propcache, multimethod, multidict, jmespath, importlib-resources, fsspec, frozenlist, aioitertools, aiohappyeyeballs, yarl, python-cmr, pqdm, botocore, aiosignal, aiohttp, aiobotocore, s3fs, earthaccess\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/22\u001b[0m [importlib-resources]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/22\u001b[0m [frozenlist]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m18/22\u001b[0m [aiohttp]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [earthaccess]\r\n\u001b[?25h\r\u001b[1A\u001b[2K"},{"output_type":"stream","name":"stdout","text":"Successfully installed aiobotocore-2.24.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 botocore-1.39.11 bounded-pool-executor-0.0.3 earthaccess-0.14.0 frozenlist-1.7.0 fsspec-2025.7.0 importlib-resources-6.5.2 jmespath-1.0.1 multidict-6.6.4 multimethod-2.0 pqdm-0.2.0 propcache-0.3.2 python-cmr-0.13.0 s3fs-2025.7.0 tinynetrc-1.3.1 tqdm-4.67.1 wrapt-1.17.3 yarl-1.20.1\r\n"}],"key":"z9j83A4bVK"}],"key":"Ej1xvhXu1e"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import earthaccess\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport shutil\nimport tempfile\nimport xarray as xr","key":"GM8bCoDjme"},{"type":"output","id":"sVlJcJ7WvgOtI_5J3DKG-","data":[{"output_type":"stream","name":"stderr","text":"/home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"},{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mearthaccess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"uc8NXhaEiF"}],"key":"Fl0ZUX1VRe"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BOf094sg2c"}],"key":"tB9Qpxqfxi"}],"key":"SqHCziSjPK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate with Earthdata Login servers\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for snow-on granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-15', '2023-03-15'),\n)","key":"ExLLUkAvYw"},{"type":"output","id":"1Ds_iqL6OoSl2MNiQLkPw","data":[],"key":"PIbCId8aO4"}],"key":"PwdHDXhB8w"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zOtp2C6FRi"},{"type":"inlineCode","value":"rioxarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FKNLMRct48"},{"type":"text","value":"!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"N9UKJ1E3X0"}],"key":"Vvpv5NEqDI"}],"key":"oUagutEfn3"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Load a single TLS scan\nfiles = earthaccess.open(results)\nsnow_on = rxr.open_rasterio(files[1])","key":"Yl8OoxXxxJ"},{"type":"output","id":"lxWyKEOBIJhb39vBE7Tmk","data":[],"key":"KbPoc4LNj3"}],"key":"HPDxRG5KvL"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_on.rio.width","key":"yUkqb4TX7t"},{"type":"output","id":"mC9cLZMNx0VHKE6aA80W8","data":[],"key":"cmUYgDy63Z"}],"key":"tZQojGxVZ3"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"kIDVkonDSZ"},{"type":"output","id":"7M-PNDqjMKTXMRtE6TRo8","data":[],"key":"f98zyfCLpH"}],"key":"BOTjv5YR4c"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Two things are noticeable from this TLS data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"cVYbgBkbfM"}],"key":"svjoyxfqGM"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It has a very high resolution (0.15 m).","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"zCr6pm5X57"}],"key":"zB94ZaCOpd"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The signal attenutates after ~60 m, so we have a small field of view.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"N0e3HyZ7wU"}],"key":"ZurWnqcJzt"}],"key":"eUVMkR4x5k"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"RZDEesXn7S"}],"key":"aS6iKjQ1bT"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In any case, let’s grab the snow-off data from the same location, and try to derive snow depth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"eqKx4Permz"}],"key":"q2zellWcve"}],"key":"RRY6sJ9Ok9"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Now search for snow-off granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-25', '2022-10-25'),\n)","key":"xp7q5ETNPR"},{"type":"output","id":"oY-qA1UvmQ0H_d29TKRuk","data":[],"key":"iqxlArbBr2"}],"key":"hawcfoHTX4"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"display(results)","key":"slG37Qk19n"},{"type":"output","id":"iz2gfGWzg60d8SUgWMDOK","data":[],"key":"C4ICRnolfo"}],"key":"UzuUF5GYc2"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Again, load a single snow-off TLS scan\nfiles = earthaccess.open(results)\nsnow_off = rxr.open_rasterio(files[1])","key":"kYBCSENyU5"},{"type":"output","id":"qfCKEBflOYo8tULljF4zm","data":[],"key":"gxOdn6RCW0"}],"key":"VJHrMJ7s9d"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"DHlX7LqGu7"},{"type":"output","id":"yaY8LcKxhNZuyrDQACHXl","data":[],"key":"SBdwYqd6LJ"}],"key":"H8odCraDBN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"q68agi2T1H"}],"key":"eRhccq3qS5"}],"key":"gQFDugsqAT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))","key":"Vj5kVAlN0k"},{"type":"output","id":"6vF6PfCq-pa_jc80lkiTL","data":[],"key":"SU3odDZl3q"}],"key":"WPgTLepcmd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"SMJ9se736Q"},{"type":"output","id":"ulLNNMpy16VAFRSZGfvvX","data":[],"key":"xEJNP43uKh"}],"key":"AfUpAve48s"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HQJ2kbWFyX"}],"key":"dGCXIhKY85"}],"key":"U6u8ZYTMzF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)","key":"vf9E58u5H5"},{"type":"output","id":"xG4uDAaG-itMSR6TBojLj","data":[],"key":"wrbKAH9Tb0"}],"key":"v9PFxm65Gg"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple Scans Example","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"usFQkmPjEc"}],"identifier":"multiple-scans-example","label":"Multiple Scans Example","html_id":"multiple-scans-example","implicit":true,"key":"dRvB76xgIK"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"NagRBhyUWF"}],"key":"emsq6ePBem"}],"key":"t564WsfeCn"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Search for snow-on granules\nsnow_on_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-01', '2023-03-31'),\n)\n\nsnow_off_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-01', '2022-10-31'),\n)","key":"dOPCtrNpPd"},{"type":"output","id":"WWoQbGdjTSaSF2Sw0ZZYc","data":[],"key":"jrzSGRCwps"}],"key":"TXgIlJLPjh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create list of snow-on DataArrays\nsnow_on_files = earthaccess.open(snow_on_results)\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_files = earthaccess.open(snow_off_results)\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]","key":"rMMoYNdQbj"},{"type":"output","id":"v0SCGvHlOhBLmzC-Y2nJz","data":[],"key":"ocuY4t6NEt"}],"key":"AeaMCo3o7V"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aL6Y9cMx3K"}],"key":"jpBODThW3q"}],"key":"QTwVHUEDXv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snon_site_ids = []\nsnoff_site_ids = []\n# Get site IDs for each snow-on DataArray\nfor f in snow_on_files:\n    # Get path from file name\n    path = f.path\n    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off DataArray\nfor f in snow_off_files:\n    # Step 1: Extract path\n    path = f.path\n    # Step 2: Use regex to extract the site ID\n    # Pattern: _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(snon_site_ids)\nprint(snoff_site_ids)","key":"jkQLL3mlge"},{"type":"output","id":"PtZo196M0Y7ZTtqxODfQ8","data":[],"key":"sSgKfPGg9l"}],"key":"UaWNZ91oKi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site","key":"ECcO65rAx0"},{"type":"output","id":"1R_VWuYRXQtqaaAoVhcof","data":[],"key":"kcHM8R3Fwc"}],"key":"NkB0qPC5pP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}","key":"KWnoSqmtXy"},{"type":"output","id":"lQoHitYPyHlLQQriuLzvr","data":[],"key":"BXZTBv8ZyZ"}],"key":"SArGiiHb48"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xY2fEKBQhb"}],"key":"HzxJuekpOY"}],"key":"wJzZtQh0r6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)","key":"evjLQSgta8"},{"type":"output","id":"BjS8CHzVtH4iScToOwqP2","data":[],"key":"eCGkXDBqfe"}],"key":"XkuTi4nQeA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]","key":"CX9XHVN5SG"},{"type":"output","id":"PqlSrGcIZ9zjlIGHcy492","data":[],"key":"pOoZV45vI3"}],"key":"xmOu6kYhtQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FtRD6LvwHW"}],"key":"TuayvMUqXy"}],"key":"EcgDKDvM1p"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)","key":"o0WPg2ZgPT"},{"type":"output","id":"eOHSIy18YR6nbv62LloQ9","data":[],"key":"t249mRWCW0"}],"key":"kL9ezt4qhT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()","key":"Ai6Q2XnIFZ"},{"type":"output","id":"AWyIXmiwIbM2fdBjCt1Jc","data":[],"key":"jaehFg05je"}],"key":"L8jw53wbfC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k758N5E2KQ"}],"key":"aafgtIJxCq"}],"key":"HfALHtjOHZ"}],"key":"wehqDC71eY"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"AVIRIS-NG","url":"/notebooks/aviris-ng-data","group":"Observations"},"next":{"title":"Neural Networks with PyTorch","url":"/notebooks/pytorch-tutorial","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}