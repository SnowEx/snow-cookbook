{"version":2,"kind":"Notebook","sha256":"05efc3d1b07660e2732c6347352fce2948a2e3ea8073ade49be56a38d1a9f731","slug":"notebooks.tls-data-access","location":"/notebooks/tls_data_access.ipynb","dependencies":[],"frontmatter":{"title":"Terrestrial Laser Scanning","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/tls_data_access.ipynb","exports":[{"format":"ipynb","filename":"tls_data_access.ipynb","url":"/snow-cookbook/_preview/9/build/tls_data_access-328f91b8e3f8eb20e1c33d440b5010d1.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dUJPPboBoW"}],"key":"GAMhmbMC4N"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The TLS data is available through the cloud on NSIDC, so we will be using the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"d9cswWRDaj"},{"type":"inlineCode","value":"earthaccess","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"NioGrQJq48"},{"type":"text","value":" package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"dH1OaJm0lc"}],"key":"GR71wjwmkW"}],"key":"zMhlieCx8n"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install --upgrade earthaccess","key":"g9gyfyHUHH"},{"type":"output","id":"lW0T3Xf2rLbk8pOavdjoH","data":[{"output_type":"stream","name":"stdout","text":"Collecting earthaccess\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading earthaccess-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting fsspec>=2022.11 (from earthaccess)\r\n  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting importlib-resources>=6.3.2 (from earthaccess)\r\n  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multimethod>=1.8 (from earthaccess)\r\n  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting pqdm>=0.1 (from earthaccess)\r\n  Downloading pqdm-0.2.0-py2.py3-none-any.whl.metadata (3.2 kB)\r\nCollecting python-cmr>=0.10.0 (from earthaccess)\r\n  Downloading python_cmr-0.13.0-py3-none-any.whl.metadata (10 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: requests>=2.26 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (2.32.5)\r\nCollecting s3fs>=2022.11 (from earthaccess)\r\n  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tinynetrc>=1.3.1 (from earthaccess)\r\n  Downloading tinynetrc-1.3.1-py2.py3-none-any.whl.metadata (2.9 kB)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (4.14.1)\r\nCollecting bounded-pool-executor (from pqdm>=0.1->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading bounded_pool_executor-0.0.3-py3-none-any.whl.metadata (2.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tqdm (from pqdm>=0.1->earthaccess)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-cmr>=0.10.0->earthaccess) (2.9.0.post0)\r\nRequirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->python-cmr>=0.10.0->earthaccess) (1.17.0)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2025.8.3)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2022.11->earthaccess)\r\n  Downloading aiobotocore-2.24.1-py3-none-any.whl.metadata (25 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2022.11->earthaccess)\r\n  Downloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting botocore<1.39.12,>=1.39.9 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\r\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: attrs>=17.3.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess) (25.3.0)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading earthaccess-0.14.0-py3-none-any.whl (64 kB)\r\nDownloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\nDownloading multimethod-2.0-py3-none-any.whl (9.8 kB)\r\nDownloading pqdm-0.2.0-py2.py3-none-any.whl (6.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading python_cmr-0.13.0-py3-none-any.whl (14 kB)\r\nDownloading s3fs-2025.7.0-py3-none-any.whl (30 kB)\r\nDownloading aiobotocore-2.24.1-py3-none-any.whl (85 kB)\r\nDownloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\nDownloading botocore-1.39.11-py3-none-any.whl (13.9 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m198.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\nDownloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\r\nDownloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\r\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\nDownloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\nDownloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\r\nDownloading tinynetrc-1.3.1-py2.py3-none-any.whl (3.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading bounded_pool_executor-0.0.3-py3-none-any.whl (3.4 kB)\r\nUsing cached tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tinynetrc, bounded-pool-executor, wrapt, tqdm, propcache, multimethod, multidict, jmespath, importlib-resources, fsspec, frozenlist, aioitertools, aiohappyeyeballs, yarl, python-cmr, pqdm, botocore, aiosignal, aiohttp, aiobotocore, s3fs, earthaccess\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/22\u001b[0m [fsspec]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/22\u001b[0m [aiohappyeyeballs]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m18/22\u001b[0m [aiohttp]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [earthaccess]\r\n\u001b[?25h\r\u001b[1A\u001b[2KSuccessfully installed aiobotocore-2.24.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 botocore-1.39.11 bounded-pool-executor-0.0.3 earthaccess-0.14.0 frozenlist-1.7.0 fsspec-2025.7.0 importlib-resources-6.5.2 jmespath-1.0.1 multidict-6.6.4 multimethod-2.0 pqdm-0.2.0 propcache-0.3.2 python-cmr-0.13.0 s3fs-2025.7.0 tinynetrc-1.3.1 tqdm-4.67.1 wrapt-1.17.3 yarl-1.20.1\r\n"}],"key":"q9H4NFTulV"}],"key":"r7TbzJuS8Z"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import earthaccess\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport shutil\nimport tempfile\nimport xarray as xr","key":"Q7eE4Avm87"},{"type":"output","id":"VlSqUXDbJNVRn-u_NQALX","data":[{"output_type":"stream","name":"stderr","text":"/home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"},{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mearthaccess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"HRl23hQFS4"}],"key":"x8uYdwFXXc"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GbrVDKf0XK"}],"key":"ytFnxJ57Ss"}],"key":"E8DX42Oped"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate with Earthdata Login servers\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for snow-on granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-15', '2023-03-15'),\n)","key":"POW3y8ZSw4"},{"type":"output","id":"oOQFO01t7Zwo26bXbQGzc","data":[],"key":"MYZKp2Kwu2"}],"key":"qZ18XkT85y"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ou3qW7hoUg"},{"type":"inlineCode","value":"rioxarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"O3KkrifFpG"},{"type":"text","value":"!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"YxyAXCqqDS"}],"key":"Z3UpRx5rej"}],"key":"RRmiR5wzOE"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Load a single TLS scan\nfiles = earthaccess.open(results)\nsnow_on = rxr.open_rasterio(files[1])","key":"pLI3S3ZBIz"},{"type":"output","id":"kPfduW8V6VFBAa670bufZ","data":[],"key":"SBsujkrcje"}],"key":"KgK1I7LlxI"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_on.rio.width","key":"llLSqpwOQB"},{"type":"output","id":"Nt4MFs5Y9SHtMEo3t9Ku4","data":[],"key":"M2vwfAc4sd"}],"key":"fpGSnbWsLx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"GjIxWctYcT"},{"type":"output","id":"WwFRElKuiPkS7DHUqiBrz","data":[],"key":"odrhm4CeOD"}],"key":"M7roddWjpg"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Two things are noticeable from this TLS data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"rT1gOD3eMx"}],"key":"cHNQImEAP0"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It has a very high resolution (0.15 m).","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"exlvTgZ9M7"}],"key":"vm880ngbKz"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The signal attenutates after ~60 m, so we have a small field of view.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"MtzaC34nhC"}],"key":"Nba8pJXPkf"}],"key":"wHU7H09CXT"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nuPsHHU4ZB"}],"key":"iwKfL0Hy93"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In any case, let’s grab the snow-off data from the same location, and try to derive snow depth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"F4cQVhuiui"}],"key":"VOXtDix9qw"}],"key":"h8aCc3JBXh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Now search for snow-off granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-25', '2022-10-25'),\n)","key":"zn6ycAxasM"},{"type":"output","id":"IEhAhdOcZakVOOhbXACYE","data":[],"key":"lY9Q67vysU"}],"key":"VbN54HaPI6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"display(results)","key":"V8jYeU6TbU"},{"type":"output","id":"mPQ07EJ1hyYe-Su2VU0sv","data":[],"key":"IcAn9x2TBM"}],"key":"u4btE93zaA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Again, load a single snow-off TLS scan\nfiles = earthaccess.open(results)\nsnow_off = rxr.open_rasterio(files[1])","key":"pmdo5f9gUq"},{"type":"output","id":"vhTsJcSZ3gY9j2mFa6cOq","data":[],"key":"Q4mhRCDOrr"}],"key":"qnblprCWoe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"NCxG0N12hX"},{"type":"output","id":"1kr06SHMTtrnoHJxswvl9","data":[],"key":"CPeJ9AZciU"}],"key":"k3Oop152ZJ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aAjXFjdPf3"}],"key":"SyL7Gm0DcM"}],"key":"mPbjT3Sl2L"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))","key":"E8abFOvXLb"},{"type":"output","id":"lXZhCejm71sjmibLNUAi3","data":[],"key":"c1npyLDESq"}],"key":"uJQOv9aFXP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"ms4Ci1vZRo"},{"type":"output","id":"CgFJVZ7iF_BzkT5rRW3Uz","data":[],"key":"xDLl4wuyy6"}],"key":"cQVJxxyb7G"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"vJnNTkRsho"}],"key":"WRC4rTLntH"}],"key":"xxkOqufGvz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)","key":"snanpttq7X"},{"type":"output","id":"Nwz4LU1dHJPwrPCs4gaad","data":[],"key":"R8gWmZXi6M"}],"key":"vutqzoJPT9"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple Scans Example","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"myEEuqj6Km"}],"identifier":"multiple-scans-example","label":"Multiple Scans Example","html_id":"multiple-scans-example","implicit":true,"key":"PUAWOcJblD"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"lljV5Wlo22"}],"key":"aHmQN5VmoL"}],"key":"Tbeg0jP493"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Search for snow-on granules\nsnow_on_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-01', '2023-03-31'),\n)\n\nsnow_off_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-01', '2022-10-31'),\n)","key":"kZnXFpKpq1"},{"type":"output","id":"S1cy2nf-_-RL789dz-79B","data":[],"key":"xNKiBHb3Kx"}],"key":"ikZhsxrsWh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create list of snow-on DataArrays\nsnow_on_files = earthaccess.open(snow_on_results)\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_files = earthaccess.open(snow_off_results)\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]","key":"C9d7P9RFH2"},{"type":"output","id":"a0FquJiyRh8UC-tCEEYXz","data":[],"key":"ZCak04Ai4O"}],"key":"S88PlroVHa"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kBS20Ew8DP"}],"key":"Qg0WyqInR7"}],"key":"snk8lhGAZl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snon_site_ids = []\nsnoff_site_ids = []\n# Get site IDs for each snow-on DataArray\nfor f in snow_on_files:\n    # Get path from file name\n    path = f.path\n    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off DataArray\nfor f in snow_off_files:\n    # Step 1: Extract path\n    path = f.path\n    # Step 2: Use regex to extract the site ID\n    # Pattern: _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(snon_site_ids)\nprint(snoff_site_ids)","key":"zao2Zzl56a"},{"type":"output","id":"wmwx5--JDWwvud_qZf7fu","data":[],"key":"PG4QA0OpHo"}],"key":"dj3V1hOiQe"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site","key":"Q2jA4tC15Y"},{"type":"output","id":"fNctMhr9iSwTppggF61kB","data":[],"key":"Ixg5DyE1gh"}],"key":"Lzyl1xfPvK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}","key":"ppce7ZXbxP"},{"type":"output","id":"q27q2zfENwwroYz2yF8T6","data":[],"key":"kuH7BhF0ut"}],"key":"xm63qCZQBb"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"s6LHlRNs0S"}],"key":"vS4Nsn634m"}],"key":"KWv9S2KurY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)","key":"I4m8kkAqVb"},{"type":"output","id":"LWaxrQvJTQ_xyxMnWiMrZ","data":[],"key":"q2tU4YlBxr"}],"key":"RVutjW2y4v"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]","key":"rBV0MReCiw"},{"type":"output","id":"pjLBR0k78sY6pp_Lcfjjn","data":[],"key":"rSMGEnNGRx"}],"key":"iPZ0MOQ6p2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Kxdjwzqi3c"}],"key":"wMihKaeQ5l"}],"key":"EaqeQpi1jM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)","key":"wwUlc98kmR"},{"type":"output","id":"Bp149sYK_Io6cjvla85uR","data":[],"key":"akB8RrF3tI"}],"key":"ibHFsiJ7bM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()","key":"N4ztQxEQo5"},{"type":"output","id":"UWK8lm_Y6f10JWZo1YmAT","data":[],"key":"khxvCNdJyW"}],"key":"jcc5K05KBf"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"HxcJHR42Mr"}],"key":"xy9fRlGVu6"}],"key":"UqDetaC5uz"}],"key":"SdJhLywa6R"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"AVIRIS-NG","url":"/notebooks/aviris-ng-data","group":"Observations"},"next":{"title":"Neural Networks with PyTorch","url":"/notebooks/pytorch-tutorial","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}