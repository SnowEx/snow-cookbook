<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Neural Networks with PyTorch - Snow Cookbook</title><meta property="og:title" content="Neural Networks with PyTorch - Snow Cookbook"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/snow-cookbook/_preview/9/build/3a5b2698b5d21d107a57901ba13beff9.png"/><meta property="og:image" content="/snow-cookbook/_preview/9/build/3a5b2698b5d21d107a57901ba13beff9.png"/><link rel="stylesheet" href="/snow-cookbook/_preview/9/build/_assets/app-5WKS5EPQ.css"/><link rel="stylesheet" href="/snow-cookbook/_preview/9/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-T52X8HNYE8"></script><script>window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-T52X8HNYE8');</script><link rel="icon" href="/snow-cookbook/_preview/9/favicon.ico"/><link rel="stylesheet" href="/snow-cookbook/_preview/9/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="https://projectpythia.org"><div class="p-1 mr-3"><img src="/snow-cookbook/_preview/9/build/config-item-24692dda-d4ef5a1cfa73b56d76f286a3bac560d5.svg" class="h-9 dark:hidden" height="2.25rem"/><img src="/snow-cookbook/_preview/9/build/config-item-84d6d338-8663e489e7743f1ba8960e99b6403756.svg" class="hidden h-9 dark:block" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Home</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://foundations.projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Foundations</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://cookbooks.projectpythia.org/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Cookbooks</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org/resource-gallery/" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Resources</a></div><div class="relative inline-block mx-2 grow-0"><a href="https://projectpythia.org/#join-us" target="_blank" rel="noopener noreferrer" class="inline-flex items-center justify-center w-full mx-2 py-1 text-md font-medium dark:text-white focus:outline-none focus-visible:ring-2 focus-visible:ring-white focus-visible:ring-opacity-75">Community</a></div></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R74op:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode" aria-label="Toggle theme between light and dark mode"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"><div class="relative" data-headlessui-state=""><div><button class="flex text-sm bg-transparent rounded-full focus:outline-none" id="headlessui-menu-button-:Rr4op:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Open Menu</span><div class="flex items-center text-stone-200 hover:text-white"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="p-1"><path fill-rule="evenodd" d="M10.5 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Zm0 6a1.5 1.5 0 1 1 3 0 1.5 1.5 0 0 1-3 0Z" clip-rule="evenodd"></path></svg></div></button></div></div></div><div class="hidden sm:block"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="inline-block px-4 py-2 mx-1 mt-0 leading-none border rounded text-md border-stone-700 dark:border-white text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 hover:bg-neutral-100">Project Pythia</a></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white font-medium"><a href="https://projectpythia.org" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Home</a><a href="https://foundations.projectpythia.org" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Foundations</a><a href="https://cookbooks.projectpythia.org/" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Cookbooks</a><a href="https://projectpythia.org/resource-gallery/" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Resources</a><a href="https://projectpythia.org/#join-us" target="_blank" rel="noopener noreferrer" class="p-2 my-1 rounded-lg hover:bg-slate-300/30 block break-words focus:outline outline-blue-200 outline-2 rounded">Community</a></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Snow Cookbook" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/snow-cookbook/_preview/9/">Snow Cookbook</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Preamble" class="block break-words rounded py-2 grow cursor-pointer">Preamble</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rmp8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rmp8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Data Access" class="block break-words rounded py-2 grow cursor-pointer">Data Access</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rup8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rup8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Observations" class="block break-words rounded py-2 grow cursor-pointer">Observations</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R16p8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R16p8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Analysis and Machine Learning" class="block break-words rounded py-2 grow cursor-pointer">Analysis and Machine Learning</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1ep8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1ep8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://creativecommons.org/licenses/by/4.0/" target="_blank" rel="noopener noreferrer" class="opacity-50 hover:opacity-100 text-inherit hover:text-inherit" aria-label="Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mx-1"><title>Content License: Creative Commons Attribution 4.0 International (CC-BY-4.0)</title><path d="M12 2.2c2.7 0 5 1 7 2.9.9.9 1.6 2 2.1 3.1.5 1.2.7 2.4.7 3.8 0 1.3-.2 2.6-.7 3.8-.5 1.2-1.2 2.2-2.1 3.1-1 .9-2 1.7-3.2 2.2-1.2.5-2.5.7-3.7.7s-2.6-.3-3.8-.8c-1.2-.5-2.2-1.2-3.2-2.1s-1.6-2-2.1-3.2-.8-2.4-.8-3.7c0-1.3.2-2.5.7-3.7S4.2 6 5.1 5.1C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C5.6 7.1 5 8 4.6 9c-.4 1-.6 2-.6 3s.2 2.1.6 3c.4 1 1 1.8 1.8 2.6S8 19 9 19.4c1 .4 2 .6 3 .6s2.1-.2 3-.6c1-.4 1.9-1 2.7-1.8 1.5-1.5 2.3-3.3 2.3-5.6 0-1.1-.2-2.1-.6-3.1-.4-1-1-1.8-1.7-2.6C16.1 4.8 14.2 4 12 4zm-.1 6.4l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.5.3-1 .4-1.5.4-.9 0-1.6-.3-2.1-.8-.5-.6-.8-1.3-.8-2.3 0-.9.3-1.7.8-2.2.6-.6 1.3-.8 2.1-.8 1.2 0 2.1.4 2.6 1.4zm5.6 0l-1.3.7c-.1-.3-.3-.5-.5-.6-.2-.1-.4-.2-.6-.2-.9 0-1.3.6-1.3 1.7 0 .5.1.9.3 1.3.2.3.5.5 1 .5.6 0 1-.3 1.2-.8l1.2.6c-.3.5-.6.9-1.1 1.1-.4.2-.9.3-1.4.3-.9 0-1.6-.3-2.1-.8s-.8-1.3-.8-2.2c0-.9.3-1.7.8-2.2.5-.5 1.2-.8 2-.8 1.2 0 2.1.4 2.6 1.4z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1"><title>Credit must be given to the creator</title><path d="M12 2.2c2.7 0 5 .9 6.9 2.8 1.9 1.9 2.8 4.2 2.8 6.9s-.9 5-2.8 6.8c-2 1.9-4.3 2.9-7 2.9-2.6 0-4.9-1-6.9-2.9-1.8-1.7-2.8-4-2.8-6.7s1-5 2.9-6.9C7 3.2 9.3 2.2 12 2.2zM12 4c-2.2 0-4.1.8-5.6 2.3C4.8 8 4 9.9 4 12c0 2.2.8 4 2.4 5.6C8 19.2 9.8 20 12 20c2.2 0 4.1-.8 5.7-2.4 1.5-1.5 2.3-3.3 2.3-5.6 0-2.2-.8-4.1-2.3-5.7C16.1 4.8 14.2 4 12 4zm2.6 5.6v4h-1.1v4.7h-3v-4.7H9.4v-4c0-.2.1-.3.2-.4.1-.2.2-.2.4-.2h4c.2 0 .3.1.4.2.2.1.2.2.2.4zm-4-2.5c0-.9.5-1.4 1.4-1.4s1.4.5 1.4 1.4c0 .9-.5 1.4-1.4 1.4s-1.4-.5-1.4-1.4z"></path></svg></a><a href="https://opensource.org/licenses/Apache-2.0" target="_blank" rel="noopener noreferrer" title="Code License: Apache License 2.0 (Apache-2.0)" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mx-1 inline-block opacity-60 hover:opacity-100 hover:text-[#599F46]"><path d="M13.2 15.6c1.4-.5 2.1-1.6 2.1-3.3S13.8 8.9 12 8.9c-1.9 0-3.3 1.6-3.3 3.3 0 1.8.8 3 2.2 3.4l-2.3 5.9c-3.1-.8-6.3-4.6-6.3-9.3 0-5.5 4.3-10 9.7-10s9.8 4.5 9.8 10c0 4.7-3.1 8.5-6.3 9.3l-2.3-5.9z"></path></svg></a><a href="https://en.wikipedia.org/wiki/Open_access" target="_blank" rel="noopener noreferrer" title="Open Access" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="mr-1 inline-block opacity-60 hover:opacity-100 hover:text-[#E18435]"><path d="M17.1 12.6h-2V7.5c0-1.7-1.4-3.1-3-3.1-.8 0-1.6.3-2.2.9-.6.5-.9 1.3-.9 2.2v.7H7v-.7c0-1.4.5-2.7 1.5-3.7s2.2-1.5 3.6-1.5 2.6.5 3.6 1.5 1.5 2.3 1.5 3.7v5.1z"></path><path d="M12 21.8c-.8 0-1.6-.2-2.3-.5-.7-.3-1.4-.8-1.9-1.3-.6-.6-1-1.2-1.3-2-.3-.8-.5-1.6-.5-2.4s.2-1.6.5-2.4c.3-.7.7-1.4 1.3-2s1.2-1 1.9-1.3c.7-.3 1.5-.5 2.3-.5.8 0 1.6.2 2.3.5.7.3 1.4.8 1.9 1.3.6.6 1 1.2 1.3 2 .3.8.5 1.6.5 2.4s-.2 1.6-.5 2.4c-.3.7-.7 1.4-1.3 2-.6.6-1.2 1-1.9 1.3-.7.3-1.5.5-2.3.5zm0-10.3c-2.2 0-4 1.8-4 4.1s1.8 4.1 4 4.1 4-1.8 4-4.1-1.8-4.1-4-4.1z"></path><circle cx="12" cy="15.6" r="1.7"></circle></svg></a><a href="https://github.com/SnowEx/snow-cookbook" title="GitHub Repository: SnowEx/snow-cookbook" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="inline-block mr-1"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block"><title>Jupyter Notebook</title><path d="M20.2 1.7c0 .8-.5 1.4-1.3 1.5-.8 0-1.4-.5-1.5-1.3 0-.8.5-1.4 1.3-1.5.8-.1 1.5.5 1.5 1.3zM12 17.9c-3.7 0-7-1.3-8.7-3.3 1.8 4.8 7.1 7.3 11.9 5.5 2.5-.9 4.5-2.9 5.5-5.5-1.7 2-4.9 3.3-8.7 3.3zM12 5.1c3.7 0 7 1.3 8.7 3.3-1.8-4.8-7.1-7.3-11.9-5.5-2.5.9-4.5 2.9-5.5 5.5 1.7-2 5-3.3 8.7-3.3zM6.9 21.8c.1 1-.7 1.8-1.7 1.9-1 .1-1.8-.7-1.9-1.7 0-1 .7-1.8 1.7-1.9 1-.1 1.8.7 1.9 1.7zM3.7 4.6c-.6 0-1-.4-1-1s.4-1 1-1 1 .4 1 1c0 .5-.4 1-1 1z"></path></svg></div><a href="https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/pytorch_tutorial.ipynb" title="Edit This Page" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path stroke-linecap="round" stroke-linejoin="round" d="m16.862 4.487 1.687-1.688a1.875 1.875 0 1 1 2.652 2.652L10.582 16.07a4.5 4.5 0 0 1-1.897 1.13L6 18l.8-2.685a4.5 4.5 0 0 1 1.13-1.897l8.932-8.931Zm0 0L19.5 7.125M18 14v4.75A2.25 2.25 0 0 1 15.75 21H5.25A2.25 2.25 0 0 1 3 18.75V8.25A2.25 2.25 0 0 1 5.25 6H10"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rs8top:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><title>Download</title><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div><button class="inline-flex size-[24px] hover:text-[#E18435] items-center justify-center" aria-label="Launch in external computing interface" title="Launch in external computing interface" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:Re8top:" data-state="closed"><svg width="15" height="15" viewBox="0 0 15 15" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M6.85357 3.85355L7.65355 3.05353C8.2981 2.40901 9.42858 1.96172 10.552 1.80125C11.1056 1.72217 11.6291 1.71725 12.0564 1.78124C12.4987 1.84748 12.7698 1.97696 12.8965 2.10357C13.0231 2.23018 13.1526 2.50125 13.2188 2.94357C13.2828 3.37086 13.2779 3.89439 13.1988 4.44801C13.0383 5.57139 12.591 6.70188 11.9464 7.34645L7.49999 11.7929L6.35354 10.6465C6.15827 10.4512 5.84169 10.4512 5.64643 10.6465C5.45117 10.8417 5.45117 11.1583 5.64643 11.3536L7.14644 12.8536C7.34171 13.0488 7.65829 13.0488 7.85355 12.8536L8.40073 12.3064L9.57124 14.2572C9.65046 14.3893 9.78608 14.4774 9.9389 14.4963C10.0917 14.5151 10.2447 14.4624 10.3535 14.3536L12.3535 12.3536C12.4648 12.2423 12.5172 12.0851 12.495 11.9293L12.0303 8.67679L12.6536 8.05355C13.509 7.19808 14.0117 5.82855 14.1887 4.58943C14.2784 3.9618 14.2891 3.33847 14.2078 2.79546C14.1287 2.26748 13.9519 1.74482 13.6035 1.39645C13.2552 1.04809 12.7325 0.871332 12.2045 0.792264C11.6615 0.710945 11.0382 0.721644 10.4105 0.8113C9.17143 0.988306 7.80189 1.491 6.94644 2.34642L6.32322 2.96968L3.07071 2.50504C2.91492 2.48278 2.75773 2.53517 2.64645 2.64646L0.646451 4.64645C0.537579 4.75533 0.484938 4.90829 0.50375 5.0611C0.522563 5.21391 0.61073 5.34954 0.742757 5.42876L2.69364 6.59928L2.14646 7.14645C2.0527 7.24022 2.00002 7.3674 2.00002 7.50001C2.00002 7.63261 2.0527 7.75979 2.14646 7.85356L3.64647 9.35356C3.84173 9.54883 4.15831 9.54883 4.35357 9.35356C4.54884 9.1583 4.54884 8.84172 4.35357 8.64646L3.20712 7.50001L3.85357 6.85356L6.85357 3.85355ZM10.0993 13.1936L9.12959 11.5775L11.1464 9.56067L11.4697 11.8232L10.0993 13.1936ZM3.42251 5.87041L5.43935 3.85356L3.17678 3.53034L1.80638 4.90074L3.42251 5.87041ZM2.35356 10.3535C2.54882 10.1583 2.54882 9.8417 2.35356 9.64644C2.1583 9.45118 1.84171 9.45118 1.64645 9.64644L0.646451 10.6464C0.451188 10.8417 0.451188 11.1583 0.646451 11.3535C0.841713 11.5488 1.1583 11.5488 1.35356 11.3535L2.35356 10.3535ZM3.85358 11.8536C4.04884 11.6583 4.04885 11.3417 3.85359 11.1465C3.65833 10.9512 3.34175 10.9512 3.14648 11.1465L1.14645 13.1464C0.95119 13.3417 0.951187 13.6583 1.14645 13.8535C1.34171 14.0488 1.65829 14.0488 1.85355 13.8536L3.85358 11.8536ZM5.35356 13.3535C5.54882 13.1583 5.54882 12.8417 5.35356 12.6464C5.1583 12.4512 4.84171 12.4512 4.64645 12.6464L3.64645 13.6464C3.45119 13.8417 3.45119 14.1583 3.64645 14.3535C3.84171 14.5488 4.1583 14.5488 4.35356 14.3535L5.35356 13.3535ZM9.49997 6.74881C10.1897 6.74881 10.7488 6.1897 10.7488 5.5C10.7488 4.8103 10.1897 4.25118 9.49997 4.25118C8.81026 4.25118 8.25115 4.8103 8.25115 5.5C8.25115 6.1897 8.81026 6.74881 9.49997 6.74881Z" fill="currentColor" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div><h1 class="mb-0">Neural Networks with PyTorch</h1><header class="mt-4 not-prose"><div><span class="font-semibold text-sm inline-block"><button class="focus:shadow-[0_0_0_2px] focus:shadow-black outline-none hover:underline" aria-label="Author Details" type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R78top:" data-state="closed">The SnowPit Community</button></span></div></header></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div class="sticky top-[60px] pb-[14px] flex justify-end w-full z-20 pointer-events-none"><div class="flex p-1 m-1 space-x-1 border rounded-full shadow pointer-events-auto border-stone-300 bg-white/80 dark:bg-stone-900/80 backdrop-blur"><div class="rounded"><button class="flex text-center rounded-full cursor-pointer text-stone-800 dark:text-white hover:opacity-100 opacity-60" aria-label="start compute environment"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="inline-block w-6 h-6 align-top"><title>Launch kernel</title><path stroke-linecap="round" stroke-linejoin="round" d="M5.636 5.636a9 9 0 1 0 12.728 0M12 3v9"></path></svg></button></div></div></div><div id="skip-to-article"></div><div id="nA6ZIfRKBi" class="relative group/block"><p>This is a notebook designed to introduce users to machine learning using <code>PyTorch</code> and station data. The <code>metloom</code> package developed by M3Works is needed to run this script.</p><p>This notebook is adapted from a SnowEx Hackweek tutorial developed by Ibrahim Alabi. The full tutorial may be found here: <a target="_blank" rel="noreferrer" href="https://snowex-2024.hackweek.io/tutorials/NN_with_Pytorch/intro.html" class="">https://<wbr/>snowex<wbr/>-2024<wbr/>.hackweek<wbr/>.io<wbr/>/tutorials<wbr/>/NN<wbr/>_with<wbr/>_Pytorch<wbr/>/intro<wbr/>.html</a></p></div><div id="gCj5sYAm8n" class="relative group/block"><h2 id="what-is-machine-learning" class="relative group"><span class="heading-text">What is Machine Learning?</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#what-is-machine-learning" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>Machine learning (ML) is a field of artificial intelligence (AI) that focuses on developing algorithms or computer models using data. The goal is to use these “trained” compuer models to make decisions. Unlike traditional programming, where we write explicit rules for every situation, ML models learn patterns from data to perform tasks.</p></div><div id="leN5wKHw1I" class="relative group/block"><aside class="myst-admonition myst-admonition-warning my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-amber-600"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-amber-600 bg-amber-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-amber-600"><path fill-rule="evenodd" d="M9.401 3.003c1.155-2 4.043-2 5.197 0l7.355 12.748c1.154 2-.29 4.5-2.599 4.5H4.645c-2.309 0-3.752-2.5-2.598-4.5L9.4 3.003ZM12 8.25a.75.75 0 0 1 .75.75v3.75a.75.75 0 0 1-1.5 0V9a.75.75 0 0 1 .75-.75Zm0 8.25a.75.75 0 1 0 0-1.5.75.75 0 0 0 0 1.5Z" clip-rule="evenodd"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Important</div></div><div class="myst-admonition-body px-4 py-1"><p>Machine learning is useful when the function (<span><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi></mrow><annotation encoding="application/x-tex">f</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span></span></span></span></span>) cannot be explicitly programmed, or when the relationship between the feature(s) and outcome is unknown.</p></div></aside></div><div id="f9x6qKIDTP" class="relative group/block"><h3 id="data-download-and-cleaning" class="relative group"><span class="heading-text">Data Download and Cleaning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#data-download-and-cleaning" title="Link to this Section" aria-label="Link to this Section">¶</a></h3></div><div id="QGWoSKCASr" class="relative group/block"><p>To begin with this tutorial, we will download SNOTEL data using the <code>metloom</code> package. Users that don’t have it installed can run the cell below.</p></div><div id="MIImpKJ0sw" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">!pip install -q metloom torch torchvision torchaudio</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="6y3_GR6g0cCG6PIFacThT" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="kgT0Qez8Zs" class="relative group/block"><p>For a more detailed explanation on <code>metloom</code>, check out the tutorial on SNOTEL data access.</p><p>In this notebook, we will grab the following variables: SWE (<code>SWE</code>), average temperature (<code>TEMPAVG</code>), snow depth (<code>SNOWDEPTH</code>), and precipitation (<code>PRECIPITATION</code>). These variables will be obtained from the SNOTEL station at Green Lake, WA.</p></div><div id="AEOYtS1bqT" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from datetime import datetime
from metloom.pointdata import SnotelPointData

# Define variables of interest
ALLOWED_VARIABLES = [
    SnotelPointData.ALLOWED_VARIABLES.SWE,
    SnotelPointData.ALLOWED_VARIABLES.TEMPAVG,
    SnotelPointData.ALLOWED_VARIABLES.SNOWDEPTH,
    SnotelPointData.ALLOWED_VARIABLES.PRECIPITATION,
]

# Define SNOTEL station
snotel_point = SnotelPointData(station_id=&quot;502:WA:SNTL&quot;, name=&quot;Green Lake&quot;)

# Get daily SNOTEL data from Green Lake, WA
data = snotel_point.get_daily_data(
    start_date=datetime(*(2010, 1, 1)),
    end_date=datetime(*(2023, 1, 1)),
    variables=ALLOWED_VARIABLES
)

data.head()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="L0GLlMZo8Ry7PytMigbKA" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><div class="p-2.5">Loading...</div></div></div></div><div id="oLypGrZkCX" class="relative group/block"><p>Let’s take a look at the data that we just collected.</p></div><div id="nMyhtmuRK2" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Reset the index of the DataFrame for plotting purposes
for_plotting=data.reset_index()

# Define the units for each variable
units={
    &quot;SWE&quot;: &quot;in&quot;,
    &quot;SNOWDEPTH&quot;: &quot;in&quot;,
    &quot;AVG AIR TEMP&quot;: &quot;degF&quot;,
    &quot;PRECIPITATION&quot;: &quot;in&quot;
}

# List the variables for plotting
variables_to_plot = [
    &quot;SWE&quot;, &quot;SNOWDEPTH&quot;, &quot;AVG AIR TEMP&quot;, &quot;PRECIPITATION&quot;
]

# Make the plot
plt.figure(figsize=(12, 8))

for variable in variables_to_plot:
    plt.subplot(2, 2, variables_to_plot.index(variable) + 1)
    plt.plot(for_plotting[&quot;datetime&quot;], for_plotting[variable], label=variable)
    plt.ylabel(f&quot;{variable} ({units[variable]})&quot;, fontsize=14)
    plt.xlabel(&quot;Date&quot;, fontsize=14)

plt.tight_layout()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="u2JvDctNdWNrtGO8Shtbj" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left mb-5"><div><pre class="text-sm font-thin font-system jupyter-error"><code><span style="color:rgb(187, 0, 0)">---------------------------------------------------------------------------</span><span>
</span><span style="color:rgb(187, 0, 0)">ModuleNotFoundError</span><span>                       Traceback (most recent call last)
</span><span style="color:rgb(0, 187, 187)">Cell</span><span style="color:rgb(0, 187, 187)"> </span><span style="color:rgb(0, 187, 0)">In[3]</span><span style="color:rgb(0, 187, 0)">, line 3</span><span>
</span><span style="color:rgb(0, 187, 0)">      1</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">numpy</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">as</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">np</span><span>
</span><span style="color:rgb(0, 187, 0)">      2</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">pandas</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">as</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">pd</span><span>
</span><span style="color:rgb(0, 187, 0)">----&gt; </span><span style="color:rgb(0, 187, 0)">3</span><span> </span><span style="color:rgb(0, 135, 0);font-weight:bold">import</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">matplotlib</span><span style="color:rgb(0, 0, 187);font-weight:bold">.</span><span style="color:rgb(0, 0, 187);font-weight:bold">pyplot</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 135, 0);font-weight:bold">as</span><span style="color:rgb(undefined, undefined, undefined)"> </span><span style="color:rgb(0, 0, 187);font-weight:bold">plt</span><span>
</span><span style="color:rgb(0, 187, 0)">      5</span><span> </span><span style="color:rgb(95, 135, 135);font-style:italic"># Reset the index of the DataFrame for plotting purposes</span><span>
</span><span style="color:rgb(0, 187, 0)">      6</span><span> for_plotting=data.reset_index()

</span><span style="color:rgb(187, 0, 0)">ModuleNotFoundError</span><span>: No module named &#x27;matplotlib&#x27;</span></code></pre></div></div></div><div id="M6Q8qJcVNu" class="relative group/block"><p>We will now process this data so it’s easier to work with. First, we convert from imperial to metric units for easier interpretation. We then set the dates as the index, so that we can derive weekly rolling averages of precipitation and tempoerature.</p><p>The dataframe is then cleaned so that only snow depth, SWE, weekly temperature, and weekly precipitation are left. The dataframe is then filtered  for any NaN values, and for any zero/unrealistic snow depth and SWE values. Finally, we derive snow density from the SWE and depth data.</p></div><div id="Eu5bz6UAJu" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">clean_df=(
    for_plotting
    .assign(
        swe=lambda x: x.SWE.map(lambda y: y*2.54 if y is not None else None),
        snowdepth=lambda x: x.SNOWDEPTH.map(lambda y: y*2.54 if y is not None else None),
        precipitation=lambda x: x.PRECIPITATION.map(lambda y: y*2.54 if y is not None else None),
        tempavg=lambda x: x[&#x27;AVG AIR TEMP&#x27;].map(lambda y: (y-32)*5/9 if y is not None else None)
    )
    .set_index(&#x27;datetime&#x27;)
    .assign(
        precip_7_days_avg=lambda x: x.precipitation.shift().rolling(window=&quot;7D&quot;, min_periods=7).mean(),
        tempavg_7_days_avg=lambda x: x.tempavg.shift().rolling(window=&quot;7D&quot;, min_periods=7).mean(),
    )
    .filter([&quot;datetime&quot;, &quot;swe&quot;, &quot;snowdepth&quot;, &quot;tempavg_7_days_avg&quot;, &quot;precip_7_days_avg&quot;])
    .dropna()
    .query(
        &quot;snowdepth != 0 and swe != 0 and &quot;
        &quot;snowdepth &gt; 5 and swe &gt; 3&quot;
    )
    .assign(snowdensity=lambda x: x.swe / x.snowdepth)
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="vbBxJOeiLAB2MKG16cBPl" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="d4Fgarmiel" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">clean_df</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="Gp2lh8wn5Gt9KlRRAb81F" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="sdiai1tVco" class="relative group/block"><h2 id="building-and-training-a-neural-network" class="relative group"><span class="heading-text">Building and Training a Neural Network</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#building-and-training-a-neural-network" title="Link to this Section" aria-label="Link to this Section">¶</a></h2></div><div id="CotIJh59W6" class="relative group/block"><p>Now that we have SNOTEL data configured in a desirable format, we can build a simple neural network using PyTorch.</p></div><div id="YZDZjFGxYz" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Basic analysis libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# PyTorch libraries
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader

# Find the best available computing resource
available_device = (
    &quot;cuda&quot;
    if torch.cuda.is_available()
    else &quot;mps&quot;
    if torch.backends.mps.is_available()
    else &quot;cpu&quot;
)

print(f&quot;Available device: {available_device}&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="owGMNVS04K6NO1xtPS1WR" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="DhIyhZssWk" class="relative group/block"><p>The above cell identifies the most appropriate computing resource, based on what is available. If NVIDIA GPU or Apple’s Metal Performance Shaders are available, then they are prioritized. Otherwise, the code defaults to CPU. The former options offer faster GPU support, though the CPU option is universally available.</p></div><div id="tOr0vir0UJ" class="relative group/block"><h4 id="data-splitting" class="relative group"><span class="heading-text">Data Splitting</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#data-splitting" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>With our current SNOTEL data, we are going to split it into training, validation, and testing sets. A typical split is 70% training data, 15% validation data, and 15% testing data.</p></div><div id="yPi8uBtKCQ" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Non-snow density data
features = clean_df.drop(&#x27;snowdensity&#x27;, axis=1).values

# Snow density data only
targets = clean_df[&#x27;snowdensity&#x27;].values

# Split the data into training and temporary sets (70% training, 30% temporary)
features_train,features_temp,targets_train,targets_temp = train_test_split(features, targets, 
                                                                           test_size=0.3, random_state=0)

# Further split the temp set into validation and test sets (15% each)
features_val,features_test,targets_val,targets_test = train_test_split(features_temp, targets_temp, 
                                                                       test_size=0.5, random_state=0)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="trBt-X6grndKb2VjHwcxY" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="J9yECfRtOp" class="relative group/block"><p>Here is a breakdown of the above cell:</p><ol start="1"><li>We identify our “features”, or datasets that will be used to predict snow density. These include SWE, snow depth, temperature, and precipitation.</li><li>We identify our “target”, which is snow density in this example.</li><li>The data is split into model training data (<code>features_train</code>, <code>targets_train</code>) and validation/testing data (<code>features_temp</code>, <code>targets_temp</code>).</li><li>The temporary data sets are further split in half to validation data (<code>features_val</code>, <code>targets_val</code>) and test data (<code>features_test</code>, <code>targets_test</code>).</li></ol><p>In both splitting operations, we also set <code>random_state=0</code>. This means that the same training/validation/testing split occurs every time the code is run, to ensure reproducibility.</p></div><div id="ZUY5gL6lHJ" class="relative group/block"><h4 id="data-scaling" class="relative group"><span class="heading-text">Data Scaling</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#data-scaling" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Now that we’ve split the data, we can apply scaling. The scaler should be fit on the training data and then used to transform the training, validation, and test sets.</p></div><div id="qpQ4c9BsMy" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Generate scaler
scaler = StandardScaler()

# Fit scaler to training data
scaler.fit(features_train)

# Transform the training, validation, and test sets
features_train = scaler.transform(features_train)
features_val = scaler.transform(features_val)
features_test = scaler.transform(features_test)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="kXRI4d3YZ0Sweow4KUhH-" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="BJCKdNw9KG" class="relative group/block"><h4 id="create-dataset-classes" class="relative group"><span class="heading-text">Create Dataset Classes</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#create-dataset-classes" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Next, we define custom <code>Dataset</code> classes for each of the three sets: training, validation, and testing.</p></div><div id="S0b7UN9wZC" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Create class for available data
class SNOTELDataset(Dataset):
    def __init__(self, data, targets):
        self.data = torch.tensor(data, dtype=torch.float32)
        self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        sample = self.data[idx]
        target = self.targets[idx]
        return sample, target

# Create instances of the custom datasets for training, validation, and testing sets
train_dataset = SNOTELDataset(data=features_train, targets=targets_train)
val_dataset = SNOTELDataset(data=features_val, targets=targets_val)
test_dataset = SNOTELDataset(data=features_test, targets=targets_test)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="mjjaBfjX0skq1CN_1zc_u" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="J7ygTsGAfz" class="relative group/block"><p>Now, we use DataLoader to manage our data in mini-batches during training, validation, and testing.</p></div><div id="OhXV24Qf6f" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Create DataLoaders for training, validation, and testing sets
train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)
test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="mbgKWj-kSCyfcqVxhqwvO" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="PY7pwTg3tl" class="relative group/block"><h3 id="define-the-neural-network" class="relative group"><span class="heading-text">Define the neural network</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#define-the-neural-network" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>To set up our model, we begin by generating a simple feedforward neural network using <code>torch.nn.Module</code>.</p></div><div id="Oh0sbE53td" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Define new class for neural network
class SNOTELNN(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super(SNOTELNN, self).__init__() # super class to inherit from nn.Module
        # Define the layers
        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1
        self.relu = nn.ReLU()  # ReLU activation function
        self.fc2 = nn.Linear(hidden_size, output_size)  # Fully connected layer 2
    
    def forward(self, x): # x is the batch of input
        # Define the forward pass
        out = self.fc1(x)  # Pass input through first layer
        out = self.relu(out)  # Apply ReLU activation
        out = self.fc2(out)  # Pass through second layer to get output
        return out

# Instantiate the model and move it to the device (GPU or CPU)
model = SNOTELNN(input_size=features_train.shape[1], hidden_size=128, output_size=1).to(available_device)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="iwInIyaEHaRjV-3mAcYPw" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="x6VpgIaLtu" class="relative group/block"><p>The <code>forward</code> method defines how the input data flows through the network layers. It specifies the sequence of operations that the data undergoes as it moves from the input layer to the output layer. This method is automatically called when you pass data through the model (e.g., <code>outputs = model(inputs)</code>).</p></div><div id="ylhKXR3Pb6" class="relative group/block"><p>For any ML application, we need to define a loss function and an optimizer. Here, we’ll use Mean Squared Error Loss since we’re dealing with a regression problem. We’ll use the Adam optimizer, which is a good default choice due to its adaptive learning rates.</p></div><div id="aNCy38GiWn" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Loss function
criterion = nn.MSELoss()

# Optimizer function
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="CC_AQVEuV4YYyY-D6K47Y" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="HwDcXPCrVZ" class="relative group/block"><h3 id="training-the-neural-network" class="relative group"><span class="heading-text">Training the Neural Network</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#training-the-neural-network" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>We now write the training loop, which includes zeroing the gradients, performing the forward pass, computing the loss, backpropagating, and updating the model parameters. We will also validate the model on the validation set after each epoch.</p></div><div id="XFo4VM45W5" class="relative group/block"><aside class="myst-admonition myst-admonition-note my-5 shadow-md dark:shadow-2xl dark:shadow-neutral-900 bg-gray-50/10 dark:bg-stone-800 overflow-hidden myst-admonition-default rounded border-l-4 border-blue-500"><div class="myst-admonition-header m-0 font-medium py-1 flex min-w-0 text-lg text-blue-600 bg-blue-50 dark:bg-slate-900"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="myst-admonition-header-icon inline-block pl-2 mr-2 self-center flex-none text-blue-600"><path stroke-linecap="round" stroke-linejoin="round" d="m11.25 11.25.041-.02a.75.75 0 0 1 1.063.852l-.708 2.836a.75.75 0 0 0 1.063.853l.041-.021M21 12a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9-3.75h.008v.008H12V8.25Z"></path></svg><div class="myst-admonition-header-text text-neutral-900 dark:text-white grow self-center overflow-hidden break-words">Note</div></div><div class="myst-admonition-body px-4 py-1"><p>An <strong>Epoch</strong> refers to one complete pass through the entire training dataset. During each epoch, the model sees every example in the dataset once.</p></div></aside></div><div id="hrPfICUKwN" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">num_epochs = 5

# Lists to store the training and validation losses
train_losses = []
val_losses = []

for epoch in range(num_epochs):
    # Training phase
    model.train()
    train_loss = 0.0  # Initialize cumulative training loss
    
    for inputs, labels in train_loader:
        # Move data to the appropriate device
        inputs, labels = inputs.to(available_device), labels.to(available_device)
        
        # Zero the gradients from the previous iteration
        optimizer.zero_grad()
        
        # Perform forward pass
        outputs = model(inputs)
        
        # Compute the loss
        loss = criterion(outputs, labels)
        
        # Perform backward pass (compute gradients)
        loss.backward()
        
        # Update the model parameters
        optimizer.step()
        
        # Accumulate training loss
        train_loss += loss.item()
    
    # Average training loss
    train_loss /= len(train_loader)
    train_losses.append(train_loss)  # Store the training loss for this epoch
    
    # Validation phase
    model.eval()  # Set model to evaluation mode
    val_loss = 0.0
    
    with torch.no_grad():
        for inputs, labels in val_loader:
            inputs, labels = inputs.to(available_device), labels.to(available_device)  # Move to device
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
    
    # Average validation loss
    val_loss /= len(val_loader)
    val_losses.append(val_loss)  # Store the validation loss for this epoch
    
    print(f&#x27;Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}&#x27;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="rrFF4Gwy1LRMxyN4bkMNJ" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="bTpZKtalKy" class="relative group/block"><p>Let’s check out the loss from both the training data and the validation data.</p></div><div id="lwXXnKvLmf" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Plotting the training and validation losses
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs + 1), train_losses, label=&#x27;Training Loss&#x27;)
plt.plot(range(1, num_epochs + 1), val_losses, label=&#x27;Validation Loss&#x27;)
plt.xlabel(&#x27;Epoch&#x27;)
plt.ylabel(&#x27;Loss&#x27;)
plt.title(&#x27;Training and Validation Loss Over Epochs&#x27;)
plt.legend()
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="XNzSckIuJ8YyUVXwYzUYh" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="FEMDIlIzQp" class="relative group/block"><h3 id="testing-the-model" class="relative group"><span class="heading-text">Testing the Model</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#testing-the-model" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>We’ve done a lot of work to prepare the machine learning model for our applications. Now, it’s finally time to test it against our observations.</p></div><div id="ArNM694FIC" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Evaluate the model on the test set and collect predictions
model.eval()  # Set the model to evaluation mode
test_loss = 0.0  # Initialize cumulative test loss
all_preds = []
all_labels = []

with torch.no_grad():  # Disable gradient computation for inference
    for inputs, labels in test_loader:
        # Move data to the appropriate device
        inputs, labels = inputs.to(available_device), labels.to(available_device)
        
        # Perform forward pass
        outputs = model(inputs)
        
        # Compute the loss
        loss = criterion(outputs, labels)
        
        # Accumulate test loss
        test_loss += loss.item()
        
        # Store the predictions and the corresponding labels
        all_preds.extend(outputs.cpu().numpy())
        all_labels.extend(labels.cpu().numpy())

# Calculate the average test loss
test_loss /= len(test_loader)
print(f&#x27;Test Loss: {test_loss:.4f}&#x27;)

# Convert lists to numpy arrays for plotting
all_preds = np.array(all_preds)
all_labels = np.array(all_labels)

# Plot observed vs predicted
plt.figure(figsize=(8, 8))
plt.scatter(all_labels, all_preds, alpha=0.7)
plt.xlabel(&#x27;Observed (Actual) Values&#x27;)
plt.ylabel(&#x27;Predicted Values&#x27;)
plt.title(&#x27;Observed vs. Predicted Values&#x27;)
plt.grid(True)
plt.show()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="ht8XKvS9YyceI0FwWl-Ie" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="bXq8SmFCTP" class="relative group/block"><h3 id="save-the-model" class="relative group"><span class="heading-text">Save the Model</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#save-the-model" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>We now have some pretty good results for predicting snow density. Now it is essential to save our trained model, as doing so allows you to reuse the model for predictions, further training, or sharing with others without having to retrain it from scratch. In PyTorch, saving and loading models is straightforward and can be done using the <code>torch.save</code> and <code>torch.load</code> functions.</p></div><div id="Vk5jKwjLwq" class="relative group/block"><div class="flex sticky top-[115px] z-10 opacity-90 group-hover/block:opacity-100 group-hover/block:hidden"><div class="flex absolute top-0 right-0"></div></div><div class="hidden sticky top-[80px] z-10 opacity-70 group-hover/block:opacity-100 group-hover/block:flex"><div class="absolute top-0 -right-[28px] flex md:flex-col"></div></div><div class="relative myst-code group not-prose my-5 text-sm shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 border border-l-4 border-gray-200 border-l-blue-400 dark:border-l-blue-400 dark:border-gray-800"><pre class="block overflow-auto p-3 myst-code-body hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Save the model&#x27;s state dictionary
torch.save(model.state_dict(), &#x27;snotel_nn_model.pth&#x27;)


# Initialize the model architecture
model = SNOTELNN(input_size=features_train.shape[1], hidden_size=128, output_size=1)

# Load the model&#x27;s state dictionary
model.load_state_dict(torch.load(&#x27;snotel_nn_model.pth&#x27;, weights_only=True))

# Set the model to evaluation mode before inference
model.eval()</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 myst-code-copy-icon top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div data-mdast-node-id="FhiN6Llprfdz_LawdEiix" class="max-w-full overflow-y-visible overflow-x-auto m-0 group not-prose relative text-left"></div></div><div id="zgmomdBK7d" class="relative group/block"><h3 id="further-information" class="relative group"><span class="heading-text">Further Information</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#further-information" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><h4 id="hyperparameter-tuning" class="relative group"><span class="heading-text">Hyperparameter Tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#hyperparameter-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><p>Hyperparameter tuning is a critical step in building machine learning models. Unlike model parameters (like weights and biases), which are learned from the data during training, hyperparameters are the settings you choose before the training process begins. These include:</p><ul><li><strong>Learning Rate</strong>: Controls how much to adjust the model’s weights with respect to the loss gradient.</li><li><strong>Batch Size</strong>: Determines the number of training examples utilized in one iteration.</li><li><strong>Number of Hidden Layers and Neurons</strong>: Specifies the architecture of the neural network.</li><li><strong>Optimizer</strong>: The algorithm used to update model weights based on the computed gradients (e.g., Adam, SGD).</li></ul><p>Tuning these hyperparameters can significantly affect the performance of your model. However, finding the optimal set of hyperparameters can be a challenging and time-consuming process, often requiring experimentation.</p><h4 id="manual-vs-automated-tuning" class="relative group"><span class="heading-text">Manual vs. Automated Tuning</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#manual-vs-automated-tuning" title="Link to this Section" aria-label="Link to this Section">¶</a></h4><ul><li><p><strong>Manual Tuning</strong>: Involves adjusting hyperparameters based on intuition, experience, or trial and error. While straightforward, this approach can be inefficient and might not always yield the best results.</p></li><li><p><strong>Automated Tuning</strong>: Tools like Optuna can help automate the search for the best hyperparameters. These tools explore the hyperparameter space more systematically and can save a lot of time compared to manual tuning.</p></li></ul></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/snow-cookbook/_preview/9/notebooks/tls-data-access"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Observations</div>Terrestrial Laser Scanning</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/snow-cookbook/_preview/9/notebooks/snowmodeling-tutorial-pt1"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Analysis and Machine Learning</div>Snow Modeling</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-JSE36H2O.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-C7FW3E47.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-ND43KHSX.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/root-IB5726YR.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/_shared/chunk-NBON2RSI.js"/><link rel="modulepreload" href="/snow-cookbook/_preview/9/build/routes/$-LXLHKVOR.js"/><script>window.__remixContext = {"url":"/notebooks/pytorch-tutorial","state":{"loaderData":{"root":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/snow-cookbook/_preview/9/build/config-item-9b3afca6-c29d6bd1362be837b3b8ab2f3e26c335.ico","logo":"/snow-cookbook/_preview/9/build/config-item-24692dda-d4ef5a1cfa73b56d76f286a3bac560d5.svg","logo_dark":"/snow-cookbook/_preview/9/build/config-item-84d6d338-8663e489e7743f1ba8960e99b6403756.svg","logo_url":"https://projectpythia.org","analytics_google":"G-T52X8HNYE8","folders":true},"parts":{},"nav":[{"title":"Home","url":"https://projectpythia.org"},{"title":"Foundations","url":"https://foundations.projectpythia.org"},{"title":"Cookbooks","url":"https://cookbooks.projectpythia.org/"},{"title":"Resources","url":"https://projectpythia.org/resource-gallery/"},{"title":"Community","url":"https://projectpythia.org/#join-us"}],"actions":[{"title":"Project Pythia","url":"https://projectpythia.org","internal":false,"static":false}],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Snow Cookbook","authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/SnowEx/snow-cookbook","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2025","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/cookbook-template","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/snowex_data_overview.ipynb"},{"file":"notebooks/earthaccess_snowex.ipynb"},{"file":"notebooks/snowex_database.ipynb"}],"title":"Data Access"},{"children":[{"file":"notebooks/GPR_Lidar_HackweekTutorial.ipynb"},{"file":"notebooks/thermal-ir-tutorial-pt1.ipynb"},{"file":"notebooks/timelapse-camera-tutorial.ipynb"},{"file":"notebooks/uavsar_accessing_imagery_pt1.ipynb"},{"file":"notebooks/microstructure-tutorial.ipynb"},{"file":"notebooks/aviris-ng-data.ipynb"},{"file":"notebooks/tls_data_access.ipynb"}],"title":"Observations"},{"children":[{"file":"notebooks/pytorch_tutorial.ipynb"},{"file":"notebooks/snowmodeling_tutorial_pt1.ipynb"},{"file":"notebooks/UCLA_data_access.ipynb"},{"file":"notebooks/merra2_data_access.ipynb"},{"file":"notebooks/era5_data_access.ipynb"}],"title":"Analysis and Machine Learning"}],"thumbnail":"/snow-cookbook/_preview/9/build/3a5b2698b5d21d107a57901ba13beff9.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Data Access"},{"slug":"notebooks.snowex-data-overview","title":"Field Campaigns Overview","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.earthaccess-snowex","title":"Search and Download using earthaccess","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowex-database","title":"SnowExSQL Database","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Observations"},{"slug":"notebooks.gpr-lidar-hackweektutorial","title":"GPR and Lidar","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.timelapse-camera-tutorial","title":"Time-lapse Cameras","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.uavsar-accessing-imagery-pt1","title":"UAVSAR","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.microstructure-tutorial","title":"Microstructure","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.aviris-ng-data","title":"AVIRIS-NG","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/2f77469a46f5527021926e2a430aabc5.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.tls-data-access","title":"Terrestrial Laser Scanning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Analysis and Machine Learning"},{"slug":"notebooks.pytorch-tutorial","title":"Neural Networks with PyTorch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowmodeling-tutorial-pt1","title":"Snow Modeling","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.ucla-data-access","title":"Reanalysis Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.merra2-data-access","title":"MERRA-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.era5-data-access","title":"ERA5","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static","BASE_URL":"/snow-cookbook/_preview/9"},"routes/$":{"config":{"version":2,"myst":"1.6.0","options":{"favicon":"/snow-cookbook/_preview/9/build/config-item-9b3afca6-c29d6bd1362be837b3b8ab2f3e26c335.ico","logo":"/snow-cookbook/_preview/9/build/config-item-24692dda-d4ef5a1cfa73b56d76f286a3bac560d5.svg","logo_dark":"/snow-cookbook/_preview/9/build/config-item-84d6d338-8663e489e7743f1ba8960e99b6403756.svg","logo_url":"https://projectpythia.org","analytics_google":"G-T52X8HNYE8","folders":true},"parts":{},"nav":[{"title":"Home","url":"https://projectpythia.org"},{"title":"Foundations","url":"https://foundations.projectpythia.org"},{"title":"Cookbooks","url":"https://cookbooks.projectpythia.org/"},{"title":"Resources","url":"https://projectpythia.org/resource-gallery/"},{"title":"Community","url":"https://projectpythia.org/#join-us"}],"actions":[{"title":"Project Pythia","url":"https://projectpythia.org","internal":false,"static":false}],"projects":[{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Snow Cookbook","authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/SnowEx/snow-cookbook","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2025","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/cookbook-template","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/snowex_data_overview.ipynb"},{"file":"notebooks/earthaccess_snowex.ipynb"},{"file":"notebooks/snowex_database.ipynb"}],"title":"Data Access"},{"children":[{"file":"notebooks/GPR_Lidar_HackweekTutorial.ipynb"},{"file":"notebooks/thermal-ir-tutorial-pt1.ipynb"},{"file":"notebooks/timelapse-camera-tutorial.ipynb"},{"file":"notebooks/uavsar_accessing_imagery_pt1.ipynb"},{"file":"notebooks/microstructure-tutorial.ipynb"},{"file":"notebooks/aviris-ng-data.ipynb"},{"file":"notebooks/tls_data_access.ipynb"}],"title":"Observations"},{"children":[{"file":"notebooks/pytorch_tutorial.ipynb"},{"file":"notebooks/snowmodeling_tutorial_pt1.ipynb"},{"file":"notebooks/UCLA_data_access.ipynb"},{"file":"notebooks/merra2_data_access.ipynb"},{"file":"notebooks/era5_data_access.ipynb"}],"title":"Analysis and Machine Learning"}],"thumbnail":"/snow-cookbook/_preview/9/build/3a5b2698b5d21d107a57901ba13beff9.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Data Access"},{"slug":"notebooks.snowex-data-overview","title":"Field Campaigns Overview","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.earthaccess-snowex","title":"Search and Download using earthaccess","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowex-database","title":"SnowExSQL Database","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Observations"},{"slug":"notebooks.gpr-lidar-hackweektutorial","title":"GPR and Lidar","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.timelapse-camera-tutorial","title":"Time-lapse Cameras","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.uavsar-accessing-imagery-pt1","title":"UAVSAR","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.microstructure-tutorial","title":"Microstructure","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.aviris-ng-data","title":"AVIRIS-NG","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/2f77469a46f5527021926e2a430aabc5.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.tls-data-access","title":"Terrestrial Laser Scanning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Analysis and Machine Learning"},{"slug":"notebooks.pytorch-tutorial","title":"Neural Networks with PyTorch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowmodeling-tutorial-pt1","title":"Snow Modeling","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.ucla-data-access","title":"Reanalysis Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.merra2-data-access","title":"MERRA-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.era5-data-access","title":"ERA5","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"version":2,"kind":"Notebook","sha256":"01f4d8fc291599d82686ca3a8c17e20fc258edbcfb559b44e81a2b4ff6a72d23","slug":"notebooks.pytorch-tutorial","location":"/notebooks/pytorch_tutorial.ipynb","dependencies":[],"frontmatter":{"title":"Neural Networks with PyTorch","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/pytorch_tutorial.ipynb","exports":[{"format":"ipynb","filename":"pytorch_tutorial.ipynb","url":"/snow-cookbook/_preview/9/build/pytorch_tutorial-252578f3f081b2be24b54410116eefae.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This is a notebook designed to introduce users to machine learning using ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"qMVWXmDMak"},{"type":"inlineCode","value":"PyTorch","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"C3KrcgsQqU"},{"type":"text","value":" and station data. The ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"FBjQCvQKVe"},{"type":"inlineCode","value":"metloom","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gBOLy2KvbQ"},{"type":"text","value":" package developed by M3Works is needed to run this script.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xse4t1r3My"}],"key":"LUQT4gQW8i"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This notebook is adapted from a SnowEx Hackweek tutorial developed by Ibrahim Alabi. The full tutorial may be found here: ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"MpgscNALWj"},{"type":"link","url":"https://snowex-2024.hackweek.io/tutorials/NN_with_Pytorch/intro.html","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"https://​snowex​-2024​.hackweek​.io​/tutorials​/NN​_with​_Pytorch​/intro​.html","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"fTiCBCunPd"}],"urlSource":"https://snowex-2024.hackweek.io/tutorials/NN_with_Pytorch/intro.html","key":"a66TS8n9rp"}],"key":"jPKPJsJXpu"}],"key":"nA6ZIfRKBi"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"What is Machine Learning?","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JOyhrYxHF0"}],"identifier":"what-is-machine-learning","label":"What is Machine Learning?","html_id":"what-is-machine-learning","implicit":true,"key":"oMZRRstp59"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Machine learning (ML) is a field of artificial intelligence (AI) that focuses on developing algorithms or computer models using data. The goal is to use these “trained” compuer models to make decisions. Unlike traditional programming, where we write explicit rules for every situation, ML models learn patterns from data to perform tasks.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"a12l0POzjs"}],"key":"fIeaitJEJo"}],"key":"gCj5sYAm8n"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"warning","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Important","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Clg9GzsegA"}],"key":"zV5CYnf57d"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Machine learning is useful when the function (","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"jOl5RvGTCJ"},{"type":"inlineMath","value":"f","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"html":"\u003cspan class=\"katex\"\u003e\u003cspan class=\"katex-mathml\"\u003e\u003cmath xmlns=\"http://www.w3.org/1998/Math/MathML\"\u003e\u003csemantics\u003e\u003cmrow\u003e\u003cmi\u003ef\u003c/mi\u003e\u003c/mrow\u003e\u003cannotation encoding=\"application/x-tex\"\u003ef\u003c/annotation\u003e\u003c/semantics\u003e\u003c/math\u003e\u003c/span\u003e\u003cspan class=\"katex-html\" aria-hidden=\"true\"\u003e\u003cspan class=\"base\"\u003e\u003cspan class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"\u003e\u003c/span\u003e\u003cspan class=\"mord mathnormal\" style=\"margin-right:0.10764em;\"\u003ef\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e\u003c/span\u003e","key":"poGJ6ZkQrT"},{"type":"text","value":") cannot be explicitly programmed, or when the relationship between the feature(s) and outcome is unknown.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ZoklYDfwCy"}],"key":"VVhRmolLLO"}],"key":"rGsMv3LJWH"}],"key":"leN5wKHw1I"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Data Download and Cleaning","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kByCRO645y"}],"identifier":"data-download-and-cleaning","label":"Data Download and Cleaning","html_id":"data-download-and-cleaning","implicit":true,"key":"KkvIbbcpZ8"}],"key":"f9x6qKIDTP"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To begin with this tutorial, we will download SNOTEL data using the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"LmczSBXqfF"},{"type":"inlineCode","value":"metloom","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fo0IF3I6z0"},{"type":"text","value":" package. Users that don’t have it installed can run the cell below.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FUDK8XsESa"}],"key":"hQqv5i8JPS"}],"key":"QGWoSKCASr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"!pip install -q metloom torch torchvision torchaudio","key":"NmuKWgsiM5"},{"type":"output","id":"6y3_GR6g0cCG6PIFacThT","data":[],"key":"xh92IFnkPL"}],"key":"MIImpKJ0sw"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For a more detailed explanation on ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BcAQER5mxu"},{"type":"inlineCode","value":"metloom","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VDBB1Rx4FV"},{"type":"text","value":", check out the tutorial on SNOTEL data access.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k1F6WwPpO7"}],"key":"UrqaDjKr0O"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"In this notebook, we will grab the following variables: SWE (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"PQryaYyNDU"},{"type":"inlineCode","value":"SWE","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"D1aHFw1Xh6"},{"type":"text","value":"), average temperature (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"cHG59zGTag"},{"type":"inlineCode","value":"TEMPAVG","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"w0FcgFI1qP"},{"type":"text","value":"), snow depth (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Ew4B7LyQUq"},{"type":"inlineCode","value":"SNOWDEPTH","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dLUSmmXPI3"},{"type":"text","value":"), and precipitation (","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"xIOEYuHQoy"},{"type":"inlineCode","value":"PRECIPITATION","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"eeGb2aoP6n"},{"type":"text","value":"). These variables will be obtained from the SNOTEL station at Green Lake, WA.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"I9J2deZ8CZ"}],"key":"PGkx0JELJU"}],"key":"kgT0Qez8Zs"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from datetime import datetime\nfrom metloom.pointdata import SnotelPointData\n\n# Define variables of interest\nALLOWED_VARIABLES = [\n    SnotelPointData.ALLOWED_VARIABLES.SWE,\n    SnotelPointData.ALLOWED_VARIABLES.TEMPAVG,\n    SnotelPointData.ALLOWED_VARIABLES.SNOWDEPTH,\n    SnotelPointData.ALLOWED_VARIABLES.PRECIPITATION,\n]\n\n# Define SNOTEL station\nsnotel_point = SnotelPointData(station_id=\"502:WA:SNTL\", name=\"Green Lake\")\n\n# Get daily SNOTEL data from Green Lake, WA\ndata = snotel_point.get_daily_data(\n    start_date=datetime(*(2010, 1, 1)),\n    end_date=datetime(*(2023, 1, 1)),\n    variables=ALLOWED_VARIABLES\n)\n\ndata.head()","key":"WGoaaSI29f"},{"type":"output","id":"L0GLlMZo8Ry7PytMigbKA","data":[{"output_type":"execute_result","execution_count":2,"metadata":{},"data":{"text/plain":{"content":"                                                                 geometry  \\\ndatetime                  site                                              \n2010-01-01 08:00:00+00:00 502:WA:SNTL  POINT Z (-121.17093 46.54741 5930)   \n2010-01-02 08:00:00+00:00 502:WA:SNTL  POINT Z (-121.17093 46.54741 5930)   \n2010-01-03 08:00:00+00:00 502:WA:SNTL  POINT Z (-121.17093 46.54741 5930)   \n2010-01-04 08:00:00+00:00 502:WA:SNTL  POINT Z (-121.17093 46.54741 5930)   \n2010-01-05 08:00:00+00:00 502:WA:SNTL  POINT Z (-121.17093 46.54741 5930)   \n\n                                        SWE SWE_units  AVG AIR TEMP  \\\ndatetime                  site                                        \n2010-01-01 08:00:00+00:00 502:WA:SNTL   9.2        in         32.18   \n2010-01-02 08:00:00+00:00 502:WA:SNTL   9.7        in         29.30   \n2010-01-03 08:00:00+00:00 502:WA:SNTL  10.0        in         28.94   \n2010-01-04 08:00:00+00:00 502:WA:SNTL  10.1        in         33.80   \n2010-01-05 08:00:00+00:00 502:WA:SNTL  10.8        in         36.86   \n\n                                      AVG AIR TEMP_units  SNOWDEPTH  \\\ndatetime                  site                                        \n2010-01-01 08:00:00+00:00 502:WA:SNTL               degF       34.0   \n2010-01-02 08:00:00+00:00 502:WA:SNTL               degF       37.0   \n2010-01-03 08:00:00+00:00 502:WA:SNTL               degF       38.0   \n2010-01-04 08:00:00+00:00 502:WA:SNTL               degF       38.0   \n2010-01-05 08:00:00+00:00 502:WA:SNTL               degF       38.0   \n\n                                      SNOWDEPTH_units  PRECIPITATION  \\\ndatetime                  site                                         \n2010-01-01 08:00:00+00:00 502:WA:SNTL              in            0.5   \n2010-01-02 08:00:00+00:00 502:WA:SNTL              in            0.3   \n2010-01-03 08:00:00+00:00 502:WA:SNTL              in            0.1   \n2010-01-04 08:00:00+00:00 502:WA:SNTL              in            0.7   \n2010-01-05 08:00:00+00:00 502:WA:SNTL              in            0.1   \n\n                                      PRECIPITATION_units datasource  \ndatetime                  site                                        \n2010-01-01 08:00:00+00:00 502:WA:SNTL                  in       NRCS  \n2010-01-02 08:00:00+00:00 502:WA:SNTL                  in       NRCS  \n2010-01-03 08:00:00+00:00 502:WA:SNTL                  in       NRCS  \n2010-01-04 08:00:00+00:00 502:WA:SNTL                  in       NRCS  \n2010-01-05 08:00:00+00:00 502:WA:SNTL                  in       NRCS  ","content_type":"text/plain"},"text/html":{"content":"\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style=\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003egeometry\u003c/th\u003e\n      \u003cth\u003eSWE\u003c/th\u003e\n      \u003cth\u003eSWE_units\u003c/th\u003e\n      \u003cth\u003eAVG AIR TEMP\u003c/th\u003e\n      \u003cth\u003eAVG AIR TEMP_units\u003c/th\u003e\n      \u003cth\u003eSNOWDEPTH\u003c/th\u003e\n      \u003cth\u003eSNOWDEPTH_units\u003c/th\u003e\n      \u003cth\u003ePRECIPITATION\u003c/th\u003e\n      \u003cth\u003ePRECIPITATION_units\u003c/th\u003e\n      \u003cth\u003edatasource\u003c/th\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003edatetime\u003c/th\u003e\n      \u003cth\u003esite\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003e\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2010-01-01 08:00:00+00:00\u003c/th\u003e\n      \u003cth\u003e502:WA:SNTL\u003c/th\u003e\n      \u003ctd\u003ePOINT Z (-121.17093 46.54741 5930)\u003c/td\u003e\n      \u003ctd\u003e9.2\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e32.18\u003c/td\u003e\n      \u003ctd\u003edegF\u003c/td\u003e\n      \u003ctd\u003e34.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e0.5\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003eNRCS\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2010-01-02 08:00:00+00:00\u003c/th\u003e\n      \u003cth\u003e502:WA:SNTL\u003c/th\u003e\n      \u003ctd\u003ePOINT Z (-121.17093 46.54741 5930)\u003c/td\u003e\n      \u003ctd\u003e9.7\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e29.30\u003c/td\u003e\n      \u003ctd\u003edegF\u003c/td\u003e\n      \u003ctd\u003e37.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e0.3\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003eNRCS\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2010-01-03 08:00:00+00:00\u003c/th\u003e\n      \u003cth\u003e502:WA:SNTL\u003c/th\u003e\n      \u003ctd\u003ePOINT Z (-121.17093 46.54741 5930)\u003c/td\u003e\n      \u003ctd\u003e10.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e28.94\u003c/td\u003e\n      \u003ctd\u003edegF\u003c/td\u003e\n      \u003ctd\u003e38.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003eNRCS\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2010-01-04 08:00:00+00:00\u003c/th\u003e\n      \u003cth\u003e502:WA:SNTL\u003c/th\u003e\n      \u003ctd\u003ePOINT Z (-121.17093 46.54741 5930)\u003c/td\u003e\n      \u003ctd\u003e10.1\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e33.80\u003c/td\u003e\n      \u003ctd\u003edegF\u003c/td\u003e\n      \u003ctd\u003e38.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e0.7\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003eNRCS\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2010-01-05 08:00:00+00:00\u003c/th\u003e\n      \u003cth\u003e502:WA:SNTL\u003c/th\u003e\n      \u003ctd\u003ePOINT Z (-121.17093 46.54741 5930)\u003c/td\u003e\n      \u003ctd\u003e10.8\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e36.86\u003c/td\u003e\n      \u003ctd\u003edegF\u003c/td\u003e\n      \u003ctd\u003e38.0\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003e0.1\u003c/td\u003e\n      \u003ctd\u003ein\u003c/td\u003e\n      \u003ctd\u003eNRCS\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c/div\u003e","content_type":"text/html"}}}],"key":"HmWwb8z3dH"}],"key":"AEOYtS1bqT"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s take a look at the data that we just collected.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"uzNJcwLRiK"}],"key":"hCvFRT1M3O"}],"key":"oLypGrZkCX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Reset the index of the DataFrame for plotting purposes\nfor_plotting=data.reset_index()\n\n# Define the units for each variable\nunits={\n    \"SWE\": \"in\",\n    \"SNOWDEPTH\": \"in\",\n    \"AVG AIR TEMP\": \"degF\",\n    \"PRECIPITATION\": \"in\"\n}\n\n# List the variables for plotting\nvariables_to_plot = [\n    \"SWE\", \"SNOWDEPTH\", \"AVG AIR TEMP\", \"PRECIPITATION\"\n]\n\n# Make the plot\nplt.figure(figsize=(12, 8))\n\nfor variable in variables_to_plot:\n    plt.subplot(2, 2, variables_to_plot.index(variable) + 1)\n    plt.plot(for_plotting[\"datetime\"], for_plotting[variable], label=variable)\n    plt.ylabel(f\"{variable} ({units[variable]})\", fontsize=14)\n    plt.xlabel(\"Date\", fontsize=14)\n\nplt.tight_layout()\nplt.show()","key":"CszabidhI9"},{"type":"output","id":"u2JvDctNdWNrtGO8Shtbj","data":[{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----\u003e \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Reset the index of the DataFrame for plotting purposes\u001b[39;00m\n\u001b[32m      6\u001b[39m for_plotting=data.reset_index()\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"kp0FkfpQVv"}],"key":"nMyhtmuRK2"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We will now process this data so it’s easier to work with. First, we convert from imperial to metric units for easier interpretation. We then set the dates as the index, so that we can derive weekly rolling averages of precipitation and tempoerature.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"SyZdIdKwuD"}],"key":"hHIFhlnVgl"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The dataframe is then cleaned so that only snow depth, SWE, weekly temperature, and weekly precipitation are left. The dataframe is then filtered  for any NaN values, and for any zero/unrealistic snow depth and SWE values. Finally, we derive snow density from the SWE and depth data.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"fr80nnQ7pC"}],"key":"G8w0K7DOpa"}],"key":"M6Q8qJcVNu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"clean_df=(\n    for_plotting\n    .assign(\n        swe=lambda x: x.SWE.map(lambda y: y*2.54 if y is not None else None),\n        snowdepth=lambda x: x.SNOWDEPTH.map(lambda y: y*2.54 if y is not None else None),\n        precipitation=lambda x: x.PRECIPITATION.map(lambda y: y*2.54 if y is not None else None),\n        tempavg=lambda x: x['AVG AIR TEMP'].map(lambda y: (y-32)*5/9 if y is not None else None)\n    )\n    .set_index('datetime')\n    .assign(\n        precip_7_days_avg=lambda x: x.precipitation.shift().rolling(window=\"7D\", min_periods=7).mean(),\n        tempavg_7_days_avg=lambda x: x.tempavg.shift().rolling(window=\"7D\", min_periods=7).mean(),\n    )\n    .filter([\"datetime\", \"swe\", \"snowdepth\", \"tempavg_7_days_avg\", \"precip_7_days_avg\"])\n    .dropna()\n    .query(\n        \"snowdepth != 0 and swe != 0 and \"\n        \"snowdepth \u003e 5 and swe \u003e 3\"\n    )\n    .assign(snowdensity=lambda x: x.swe / x.snowdepth)\n)","key":"UHtlpJFsVA"},{"type":"output","id":"vbBxJOeiLAB2MKG16cBPl","data":[],"key":"off5Mi6hlc"}],"key":"Eu5bz6UAJu"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"clean_df","key":"uW9Tspel2n"},{"type":"output","id":"Gp2lh8wn5Gt9KlRRAb81F","data":[],"key":"GpnbXxxK09"}],"key":"d4Fgarmiel"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Building and Training a Neural Network","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BBhx9TgsJx"}],"identifier":"building-and-training-a-neural-network","label":"Building and Training a Neural Network","html_id":"building-and-training-a-neural-network","implicit":true,"key":"v9ZqsI5tch"}],"key":"sdiai1tVco"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that we have SNOTEL data configured in a desirable format, we can build a simple neural network using PyTorch.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nRZUw6C0Sy"}],"key":"QIepuMz9CS"}],"key":"CotIJh59W6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Basic analysis libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n# PyTorch libraries\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\n# Find the best available computing resource\navailable_device = (\n    \"cuda\"\n    if torch.cuda.is_available()\n    else \"mps\"\n    if torch.backends.mps.is_available()\n    else \"cpu\"\n)\n\nprint(f\"Available device: {available_device}\")","key":"yuJAbItizc"},{"type":"output","id":"owGMNVS04K6NO1xtPS1WR","data":[],"key":"U3FhA6mnjD"}],"key":"YZDZjFGxYz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The above cell identifies the most appropriate computing resource, based on what is available. If NVIDIA GPU or Apple’s Metal Performance Shaders are available, then they are prioritized. Otherwise, the code defaults to CPU. The former options offer faster GPU support, though the CPU option is universally available.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"EQ32UyLl8W"}],"key":"cCCK8TKeav"}],"key":"DhIyhZssWk"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Data Splitting","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sXuvTM29d4"}],"identifier":"data-splitting","label":"Data Splitting","html_id":"data-splitting","implicit":true,"key":"hK2ihcTbeQ"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"With our current SNOTEL data, we are going to split it into training, validation, and testing sets. A typical split is 70% training data, 15% validation data, and 15% testing data.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"SJVmfR3TJu"}],"key":"UWvrIRcXCF"}],"key":"tOr0vir0UJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Non-snow density data\nfeatures = clean_df.drop('snowdensity', axis=1).values\n\n# Snow density data only\ntargets = clean_df['snowdensity'].values\n\n# Split the data into training and temporary sets (70% training, 30% temporary)\nfeatures_train,features_temp,targets_train,targets_temp = train_test_split(features, targets, \n                                                                           test_size=0.3, random_state=0)\n\n# Further split the temp set into validation and test sets (15% each)\nfeatures_val,features_test,targets_val,targets_test = train_test_split(features_temp, targets_temp, \n                                                                       test_size=0.5, random_state=0)","key":"h9nMiXpiLT"},{"type":"output","id":"trBt-X6grndKb2VjHwcxY","data":[],"key":"ylRQpKy4RU"}],"key":"yPi8uBtKCQ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Here is a breakdown of the above cell:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"D9qK535nSl"}],"key":"bNH9tgzk6C"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We identify our “features”, or datasets that will be used to predict snow density. These include SWE, snow depth, temperature, and precipitation.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"MqTFhjazC2"}],"key":"PClw8HYke4"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"We identify our “target”, which is snow density in this example.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"U7T6RYQiEP"}],"key":"MxbcIvpKny"},{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The data is split into model training data (","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"tsScI5Oz40"},{"type":"inlineCode","value":"features_train","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"viu1Z2ov6Q"},{"type":"text","value":", ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"l5K8kURJb5"},{"type":"inlineCode","value":"targets_train","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"xfV8iZQaIU"},{"type":"text","value":") and validation/testing data (","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"mpogDnM6Ep"},{"type":"inlineCode","value":"features_temp","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"m4J7ysqPIM"},{"type":"text","value":", ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"FjiTI3RQdV"},{"type":"inlineCode","value":"targets_temp","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"DqlGIf75zr"},{"type":"text","value":").","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"rmcK78ilvs"}],"key":"lOne6vJ4ob"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"The temporary data sets are further split in half to validation data (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Z125psEe5i"},{"type":"inlineCode","value":"features_val","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"gU1qoYNdNf"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"WUbgtpDtMT"},{"type":"inlineCode","value":"targets_val","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"vSq90Kqnvf"},{"type":"text","value":") and test data (","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"AsPR192EBX"},{"type":"inlineCode","value":"features_test","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"LAW9oLdbtl"},{"type":"text","value":", ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"UOnmHXewDB"},{"type":"inlineCode","value":"targets_test","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nvMOKDySJU"},{"type":"text","value":").","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"F8FkbziO0v"}],"key":"amG0hXyLhy"}],"key":"GTZPrvj2Di"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In both splitting operations, we also set ","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WEtqWpaOg3"},{"type":"inlineCode","value":"random_state=0","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"y5rMiAy5Xo"},{"type":"text","value":". This means that the same training/validation/testing split occurs every time the code is run, to ensure reproducibility.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"YJ2XyQa2w2"}],"key":"VgTsJsTp8f"}],"key":"J9yECfRtOp"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Data Scaling","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"nzpJmda44a"}],"identifier":"data-scaling","label":"Data Scaling","html_id":"data-scaling","implicit":true,"key":"eLAvxQEw6z"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Now that we’ve split the data, we can apply scaling. The scaler should be fit on the training data and then used to transform the training, validation, and test sets.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"yvvnfDGQ2s"}],"key":"Y9NbC41vUW"}],"key":"ZUY5gL6lHJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Generate scaler\nscaler = StandardScaler()\n\n# Fit scaler to training data\nscaler.fit(features_train)\n\n# Transform the training, validation, and test sets\nfeatures_train = scaler.transform(features_train)\nfeatures_val = scaler.transform(features_val)\nfeatures_test = scaler.transform(features_test)","key":"B3MNXapTOY"},{"type":"output","id":"kXRI4d3YZ0Sweow4KUhH-","data":[],"key":"JkfEwKKL74"}],"key":"qpQ4c9BsMy"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":4,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Create Dataset Classes","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NdtK2eK5Bk"}],"identifier":"create-dataset-classes","label":"Create Dataset Classes","html_id":"create-dataset-classes","implicit":true,"key":"JoJPMRn9FT"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Next, we define custom ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"qYGk5OfYB8"},{"type":"inlineCode","value":"Dataset","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ZvdXF5Hc1Y"},{"type":"text","value":" classes for each of the three sets: training, validation, and testing.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"KBBFZb9AQS"}],"key":"BzlkkJIr8Q"}],"key":"BJCKdNw9KG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create class for available data\nclass SNOTELDataset(Dataset):\n    def __init__(self, data, targets):\n        self.data = torch.tensor(data, dtype=torch.float32)\n        self.targets = torch.tensor(targets, dtype=torch.float32).view(-1, 1)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        sample = self.data[idx]\n        target = self.targets[idx]\n        return sample, target\n\n# Create instances of the custom datasets for training, validation, and testing sets\ntrain_dataset = SNOTELDataset(data=features_train, targets=targets_train)\nval_dataset = SNOTELDataset(data=features_val, targets=targets_val)\ntest_dataset = SNOTELDataset(data=features_test, targets=targets_test)","key":"nfqp6ivXU4"},{"type":"output","id":"mjjaBfjX0skq1CN_1zc_u","data":[],"key":"ymY6SyI1t0"}],"key":"S0b7UN9wZC"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now, we use DataLoader to manage our data in mini-batches during training, validation, and testing.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"pwrP4wXpee"}],"key":"s9kclMViVP"}],"key":"J7ygTsGAfz"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create DataLoaders for training, validation, and testing sets\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","key":"yqTISYSmeH"},{"type":"output","id":"mbgKWj-kSCyfcqVxhqwvO","data":[],"key":"NUudwWNlyo"}],"key":"OhXV24Qf6f"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Define the neural network","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"THlKSmW9C1"}],"identifier":"define-the-neural-network","label":"Define the neural network","html_id":"define-the-neural-network","implicit":true,"key":"mUvcY337py"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"To set up our model, we begin by generating a simple feedforward neural network using ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"Ml9GyoJg2Q"},{"type":"inlineCode","value":"torch.nn.Module","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"irQvY022c7"},{"type":"text","value":".","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"cGguEW4O7a"}],"key":"bqCKo9bbxW"}],"key":"PY7pwTg3tl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Define new class for neural network\nclass SNOTELNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(SNOTELNN, self).__init__() # super class to inherit from nn.Module\n        # Define the layers\n        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1\n        self.relu = nn.ReLU()  # ReLU activation function\n        self.fc2 = nn.Linear(hidden_size, output_size)  # Fully connected layer 2\n    \n    def forward(self, x): # x is the batch of input\n        # Define the forward pass\n        out = self.fc1(x)  # Pass input through first layer\n        out = self.relu(out)  # Apply ReLU activation\n        out = self.fc2(out)  # Pass through second layer to get output\n        return out\n\n# Instantiate the model and move it to the device (GPU or CPU)\nmodel = SNOTELNN(input_size=features_train.shape[1], hidden_size=128, output_size=1).to(available_device)","key":"GXk0HE5xz8"},{"type":"output","id":"iwInIyaEHaRjV-3mAcYPw","data":[],"key":"DGtIUzVcCD"}],"key":"Oh0sbE53td"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DUrNHH4QuM"},{"type":"inlineCode","value":"forward","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hgwN64jyrN"},{"type":"text","value":" method defines how the input data flows through the network layers. It specifies the sequence of operations that the data undergoes as it moves from the input layer to the output layer. This method is automatically called when you pass data through the model (e.g., ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"fJx4gpBV7e"},{"type":"inlineCode","value":"outputs = model(inputs)","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"i4JKFEMMhW"},{"type":"text","value":").","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"BOdEm9N8V3"}],"key":"BcUzkl8gJK"}],"key":"x6VpgIaLtu"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"For any ML application, we need to define a loss function and an optimizer. Here, we’ll use Mean Squared Error Loss since we’re dealing with a regression problem. We’ll use the Adam optimizer, which is a good default choice due to its adaptive learning rates.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"E4v5HZoGjt"}],"key":"bcA7IV2KOn"}],"key":"ylhKXR3Pb6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Loss function\ncriterion = nn.MSELoss()\n\n# Optimizer function\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)","key":"KVcY5Vmc8v"},{"type":"output","id":"CC_AQVEuV4YYyY-D6K47Y","data":[],"key":"yZNPpk9KSl"}],"key":"aNCy38GiWn"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Training the Neural Network","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"zamGKNK4iP"}],"identifier":"training-the-neural-network","label":"Training the Neural Network","html_id":"training-the-neural-network","implicit":true,"key":"VJoRRJAjcV"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We now write the training loop, which includes zeroing the gradients, performing the forward pass, computing the loss, backpropagating, and updating the model parameters. We will also validate the model on the validation set after each epoch.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"cGDDSXPqNI"}],"key":"Czoz5cln6s"}],"key":"HwDcXPCrVZ"},{"type":"block","kind":"notebook-content","children":[{"type":"admonition","kind":"note","children":[{"type":"admonitionTitle","children":[{"type":"text","value":"Note","key":"EWxznNtcqx"}],"key":"cjh2z10hGZ"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"An ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"MW0F6zooOp"},{"type":"strong","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Epoch","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"mRiRMTBvYm"}],"key":"vqVknpFfyc"},{"type":"text","value":" refers to one complete pass through the entire training dataset. During each epoch, the model sees every example in the dataset once.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ht4KdAzAtw"}],"key":"jgA5cxeFHw"}],"key":"neaZ5DeOgl"}],"key":"XFo4VM45W5"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"num_epochs = 5\n\n# Lists to store the training and validation losses\ntrain_losses = []\nval_losses = []\n\nfor epoch in range(num_epochs):\n    # Training phase\n    model.train()\n    train_loss = 0.0  # Initialize cumulative training loss\n    \n    for inputs, labels in train_loader:\n        # Move data to the appropriate device\n        inputs, labels = inputs.to(available_device), labels.to(available_device)\n        \n        # Zero the gradients from the previous iteration\n        optimizer.zero_grad()\n        \n        # Perform forward pass\n        outputs = model(inputs)\n        \n        # Compute the loss\n        loss = criterion(outputs, labels)\n        \n        # Perform backward pass (compute gradients)\n        loss.backward()\n        \n        # Update the model parameters\n        optimizer.step()\n        \n        # Accumulate training loss\n        train_loss += loss.item()\n    \n    # Average training loss\n    train_loss /= len(train_loader)\n    train_losses.append(train_loss)  # Store the training loss for this epoch\n    \n    # Validation phase\n    model.eval()  # Set model to evaluation mode\n    val_loss = 0.0\n    \n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(available_device), labels.to(available_device)  # Move to device\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n    \n    # Average validation loss\n    val_loss /= len(val_loader)\n    val_losses.append(val_loss)  # Store the validation loss for this epoch\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')","key":"eo2xVCIm7Y"},{"type":"output","id":"rrFF4Gwy1LRMxyN4bkMNJ","data":[],"key":"GaDgDFbWbe"}],"key":"hrPfICUKwN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Let’s check out the loss from both the training data and the validation data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oo0qhCvCrN"}],"key":"niUjccK9AI"}],"key":"bTpZKtalKy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plotting the training and validation losses\nplt.figure(figsize=(10, 5))\nplt.plot(range(1, num_epochs + 1), train_losses, label='Training Loss')\nplt.plot(range(1, num_epochs + 1), val_losses, label='Validation Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training and Validation Loss Over Epochs')\nplt.legend()\nplt.show()","key":"vHmrZodmA1"},{"type":"output","id":"XNzSckIuJ8YyUVXwYzUYh","data":[],"key":"duCCBnDsW4"}],"key":"lwXXnKvLmf"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Testing the Model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"lgTkh6H8GV"}],"identifier":"testing-the-model","label":"Testing the Model","html_id":"testing-the-model","implicit":true,"key":"s00a0wG18C"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We’ve done a lot of work to prepare the machine learning model for our applications. Now, it’s finally time to test it against our observations.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"c9sKYqIII1"}],"key":"Pn2ZbEbvxO"}],"key":"FEMDIlIzQp"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Evaluate the model on the test set and collect predictions\nmodel.eval()  # Set the model to evaluation mode\ntest_loss = 0.0  # Initialize cumulative test loss\nall_preds = []\nall_labels = []\n\nwith torch.no_grad():  # Disable gradient computation for inference\n    for inputs, labels in test_loader:\n        # Move data to the appropriate device\n        inputs, labels = inputs.to(available_device), labels.to(available_device)\n        \n        # Perform forward pass\n        outputs = model(inputs)\n        \n        # Compute the loss\n        loss = criterion(outputs, labels)\n        \n        # Accumulate test loss\n        test_loss += loss.item()\n        \n        # Store the predictions and the corresponding labels\n        all_preds.extend(outputs.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Calculate the average test loss\ntest_loss /= len(test_loader)\nprint(f'Test Loss: {test_loss:.4f}')\n\n# Convert lists to numpy arrays for plotting\nall_preds = np.array(all_preds)\nall_labels = np.array(all_labels)\n\n# Plot observed vs predicted\nplt.figure(figsize=(8, 8))\nplt.scatter(all_labels, all_preds, alpha=0.7)\nplt.xlabel('Observed (Actual) Values')\nplt.ylabel('Predicted Values')\nplt.title('Observed vs. Predicted Values')\nplt.grid(True)\nplt.show()","key":"vz7Afx8sqw"},{"type":"output","id":"ht8XKvS9YyceI0FwWl-Ie","data":[],"key":"eqNTgdoyBx"}],"key":"ArNM694FIC"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Save the Model","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"DMBRRlniKU"}],"identifier":"save-the-model","label":"Save the Model","html_id":"save-the-model","implicit":true,"key":"gxkZLjqefN"},{"type":"paragraph","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"We now have some pretty good results for predicting snow density. Now it is essential to save our trained model, as doing so allows you to reuse the model for predictions, further training, or sharing with others without having to retrain it from scratch. In PyTorch, saving and loading models is straightforward and can be done using the ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"WPdl0PctYF"},{"type":"inlineCode","value":"torch.save","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"c2kSk3Ch8s"},{"type":"text","value":" and ","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"kAvkihlLpn"},{"type":"inlineCode","value":"torch.load","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"aXeIAgmJDZ"},{"type":"text","value":" functions.","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"BbhPRtMm0L"}],"key":"Vrvzk5QnLG"}],"key":"bXq8SmFCTP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Save the model's state dictionary\ntorch.save(model.state_dict(), 'snotel_nn_model.pth')\n\n\n# Initialize the model architecture\nmodel = SNOTELNN(input_size=features_train.shape[1], hidden_size=128, output_size=1)\n\n# Load the model's state dictionary\nmodel.load_state_dict(torch.load('snotel_nn_model.pth', weights_only=True))\n\n# Set the model to evaluation mode before inference\nmodel.eval()","key":"WtQs75TDXH"},{"type":"output","id":"FhiN6Llprfdz_LawdEiix","data":[],"key":"WrwbmHgq8s"}],"key":"Vk5jKwjLwq"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":3,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Further Information","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZuaCpJoBs3"}],"identifier":"further-information","label":"Further Information","html_id":"further-information","implicit":true,"key":"tftYMYqLHJ"},{"type":"heading","depth":4,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"Hyperparameter Tuning","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"kmNQifXbmy"}],"identifier":"hyperparameter-tuning","label":"Hyperparameter Tuning","html_id":"hyperparameter-tuning","implicit":true,"key":"JgzAxiDSFV"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Hyperparameter tuning is a critical step in building machine learning models. Unlike model parameters (like weights and biases), which are learned from the data during training, hyperparameters are the settings you choose before the training process begins. These include:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"gJFrnsLW3B"}],"key":"PqpCgX3iPD"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":5,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"strong","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"Learning Rate","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YUH5miRHmK"}],"key":"uVgAtaigBa"},{"type":"text","value":": Controls how much to adjust the model’s weights with respect to the loss gradient.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"ZTRk0mXMSS"}],"key":"Kbd01cchna"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"strong","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"children":[{"type":"text","value":"Batch Size","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"J5BJptmkEf"}],"key":"FRrN3q6b4F"},{"type":"text","value":": Determines the number of training examples utilized in one iteration.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lWMSfhqh2t"}],"key":"vKlPBjMyPZ"},{"type":"listItem","spread":true,"position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"strong","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"Number of Hidden Layers and Neurons","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"d85Ge00dE4"}],"key":"ETo57zGOek"},{"type":"text","value":": Specifies the architecture of the neural network.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"Zd9nocEGw0"}],"key":"PRp3gcN3Wx"},{"type":"listItem","spread":true,"position":{"start":{"line":8,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"strong","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"Optimizer","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"Mgo1gJZfuS"}],"key":"H9BGGsFVTo"},{"type":"text","value":": The algorithm used to update model weights based on the computed gradients (e.g., Adam, SGD).","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"q7t6G5gWu0"}],"key":"gt5uOwcTj4"}],"key":"ja7ZeTs1PZ"},{"type":"paragraph","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"children":[{"type":"text","value":"Tuning these hyperparameters can significantly affect the performance of your model. However, finding the optimal set of hyperparameters can be a challenging and time-consuming process, often requiring experimentation.","position":{"start":{"line":10,"column":1},"end":{"line":10,"column":1}},"key":"BQlkA7Yxt1"}],"key":"nB1dUPVMnZ"},{"type":"heading","depth":4,"position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"Manual vs. Automated Tuning","position":{"start":{"line":12,"column":1},"end":{"line":12,"column":1}},"key":"UZ7dPCWRF4"}],"identifier":"manual-vs-automated-tuning","label":"Manual vs. Automated Tuning","html_id":"manual-vs-automated-tuning","implicit":true,"key":"ntnn6hN3rV"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":13,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":13,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"strong","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"children":[{"type":"text","value":"Manual Tuning","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"nrcAqp0Lg5"}],"key":"wcj2s0pt6y"},{"type":"text","value":": Involves adjusting hyperparameters based on intuition, experience, or trial and error. While straightforward, this approach can be inefficient and might not always yield the best results.","position":{"start":{"line":13,"column":1},"end":{"line":13,"column":1}},"key":"di0kgvuWv6"}],"key":"glLHDKEzG6"}],"key":"NO8VXvI4OA"},{"type":"listItem","spread":true,"position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"strong","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"children":[{"type":"text","value":"Automated Tuning","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"NzgcuKidbA"}],"key":"WbF1Zwp6pj"},{"type":"text","value":": Tools like Optuna can help automate the search for the best hyperparameters. These tools explore the hyperparameter space more systematically and can save a lot of time compared to manual tuning.","position":{"start":{"line":15,"column":1},"end":{"line":15,"column":1}},"key":"BpX3Bi6wxq"}],"key":"UzGd2ApBmJ"}],"key":"TYwag2HbdQ"}],"key":"bYz92RckvJ"}],"key":"zgmomdBK7d"}],"key":"ncnQc1YA8t"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"Terrestrial Laser Scanning","url":"/notebooks/tls-data-access","group":"Observations"},"next":{"title":"Snow Modeling","url":"/notebooks/snowmodeling-tutorial-pt1","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"},"project":{"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"title":"Snow Cookbook","authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"contributors":[{"id":"brian-rose","nameParsed":{"literal":"Brian E. J. Rose","given":"Brian E. J.","family":"Rose"},"name":"Brian E. J. Rose","orcid":"0000-0002-9961-3821","email":"brose@albany.edu","affiliations":["UAlbany"],"url":"https://brian-rose.github.io","github":"brian-rose","bluesky":"@brianejrose.bsky.social","linkedin":"https://www.linkedin.com/in/brian-rose-37bb55106/"},{"id":"clyne","nameParsed":{"literal":"John Clyne","given":"John","family":"Clyne"},"name":"John Clyne","orcid":"0000-0003-2788-9017","affiliations":["CISL"],"github":"clyne"},{"id":"jukent","nameParsed":{"literal":"Julia Kent","given":"Julia","family":"Kent"},"name":"Julia Kent","orcid":"0000-0002-5611-8986","affiliations":["CISL"],"github":"jukent"},{"id":"ktyle","nameParsed":{"literal":"Kevin Tyle","given":"Kevin","family":"Tyle"},"name":"Kevin Tyle","orcid":"0000-0001-5249-9665","affiliations":["UAlbany"],"github":"ktyle"},{"id":"andersy005","nameParsed":{"literal":"Anderson Banihirwe","given":"Anderson","family":"Banihirwe"},"name":"Anderson Banihirwe","orcid":"0000-0001-6583-571X","affiliations":["CarbonPlan"],"github":"andersy005"},{"id":"dcamron","nameParsed":{"literal":"Drew Camron","given":"Drew","family":"Camron"},"name":"Drew Camron","orcid":"0000-0001-7246-6502","affiliations":["Unidata"],"github":"dcamron"},{"id":"dopplershift","nameParsed":{"literal":"Ryan May","given":"Ryan","family":"May"},"name":"Ryan May","orcid":"0000-0003-2907-038X","affiliations":["Unidata"],"github":"dopplershift"},{"id":"mgrover1","nameParsed":{"literal":"Maxwell Grover","given":"Maxwell","family":"Grover"},"name":"Maxwell Grover","orcid":"0000-0002-0370-8974","affiliations":["Argonne"],"github":"mgrover1"},{"id":"r-ford","nameParsed":{"literal":"Robert R. Ford","given":"Robert R.","family":"Ford"},"name":"Robert R. Ford","orcid":"0000-0001-5483-4965","affiliations":["UAlbany"],"github":"r-ford"},{"id":"kmpaul","nameParsed":{"literal":"Kevin Paul","given":"Kevin","family":"Paul"},"name":"Kevin Paul","orcid":"0000-0001-8155-8038","affiliations":["NVIDIA"],"github":"kmpaul"},{"id":"jnmorley","nameParsed":{"literal":"James Morley","given":"James","family":"Morley"},"name":"James Morley","orcid":"0009-0005-5193-7981","github":"jnmorley"},{"id":"erogluorhan","nameParsed":{"literal":"Orhan Eroglu","given":"Orhan","family":"Eroglu"},"name":"Orhan Eroglu","orcid":"0000-0003-3099-8775","affiliations":["CISL"],"github":"erogluorhan"},{"id":"lkailynncar","nameParsed":{"literal":"Lily Kailyn","given":"Lily","family":"Kailyn"},"name":"Lily Kailyn","orcid":"0009-0002-0125-5091","affiliations":["CISL"],"github":"lkailynncar"},{"id":"anissa111","nameParsed":{"literal":"Anissa Zacharias","given":"Anissa","family":"Zacharias"},"name":"Anissa Zacharias","orcid":"0000-0002-2666-8493","affiliations":["CISL"],"github":"anissa111"},{"id":"kafitzgerald","nameParsed":{"literal":"Katelyn FitzGerald","given":"Katelyn","family":"FitzGerald"},"name":"Katelyn FitzGerald","orcid":"0000-0003-4184-1917","affiliations":["CISL"],"github":"kafitzgerald"}],"github":"https://github.com/SnowEx/snow-cookbook","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"copyright":"2025","references":{"foundations":{"url":"https://foundations.projectpythia.org"},"xarray":{"url":"https://docs.xarray.dev/en/stable"},"matplotlib":{"url":"https://matplotlib.org/stable"}},"thebe":{"binder":{"url":"https://mybinder.org/","provider":"github","repo":"projectpythia/cookbook-template","ref":"HEAD"}},"toc":[{"file":"README.md"},{"children":[{"file":"notebooks/how-to-cite.md"}],"title":"Preamble"},{"children":[{"file":"notebooks/snowex_data_overview.ipynb"},{"file":"notebooks/earthaccess_snowex.ipynb"},{"file":"notebooks/snowex_database.ipynb"}],"title":"Data Access"},{"children":[{"file":"notebooks/GPR_Lidar_HackweekTutorial.ipynb"},{"file":"notebooks/thermal-ir-tutorial-pt1.ipynb"},{"file":"notebooks/timelapse-camera-tutorial.ipynb"},{"file":"notebooks/uavsar_accessing_imagery_pt1.ipynb"},{"file":"notebooks/microstructure-tutorial.ipynb"},{"file":"notebooks/aviris-ng-data.ipynb"},{"file":"notebooks/tls_data_access.ipynb"}],"title":"Observations"},{"children":[{"file":"notebooks/pytorch_tutorial.ipynb"},{"file":"notebooks/snowmodeling_tutorial_pt1.ipynb"},{"file":"notebooks/UCLA_data_access.ipynb"},{"file":"notebooks/merra2_data_access.ipynb"},{"file":"notebooks/era5_data_access.ipynb"}],"title":"Analysis and Machine Learning"}],"thumbnail":"/snow-cookbook/_preview/9/build/3a5b2698b5d21d107a57901ba13beff9.png","exports":[],"bibliography":[],"index":"index","pages":[{"level":1,"title":"Preamble"},{"slug":"notebooks.how-to-cite","title":"How to Cite This Cookbook","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/72a08caa5cbe5f9cce5999dbd1a81dfd.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Data Access"},{"slug":"notebooks.snowex-data-overview","title":"Field Campaigns Overview","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.earthaccess-snowex","title":"Search and Download using earthaccess","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowex-database","title":"SnowExSQL Database","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Observations"},{"slug":"notebooks.gpr-lidar-hackweektutorial","title":"GPR and Lidar","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.timelapse-camera-tutorial","title":"Time-lapse Cameras","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.uavsar-accessing-imagery-pt1","title":"UAVSAR","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.microstructure-tutorial","title":"Microstructure","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.aviris-ng-data","title":"AVIRIS-NG","description":"","date":"","thumbnail":"/snow-cookbook/_preview/9/build/2f77469a46f5527021926e2a430aabc5.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.tls-data-access","title":"Terrestrial Laser Scanning","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Analysis and Machine Learning"},{"slug":"notebooks.pytorch-tutorial","title":"Neural Networks with PyTorch","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.snowmodeling-tutorial-pt1","title":"Snow Modeling","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.ucla-data-access","title":"Reanalysis Data Access","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.merra2-data-access","title":"MERRA-2","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"notebooks.era5-data-access","title":"ERA5","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/snow-cookbook/_preview/9/build/manifest-B2B2E6A5.js";
import * as route0 from "/snow-cookbook/_preview/9/build/root-IB5726YR.js";
import * as route1 from "/snow-cookbook/_preview/9/build/routes/$-LXLHKVOR.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/snow-cookbook/_preview/9/build/entry.client-UNPC4GT3.js");</script></body></html>