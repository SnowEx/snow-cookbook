{"version":2,"kind":"Notebook","sha256":"38c34e3a32958da2536561ff443ddd1d715078ee4a8069f0bf1d3285fc42260c","slug":"notebooks.era5-data-access","location":"/notebooks/era5_data_access.ipynb","dependencies":[],"frontmatter":{"title":"ERA5","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/HEAD/notebooks/era5_data_access.ipynb","exports":[{"format":"ipynb","filename":"era5_data_access.ipynb","url":"/snow-cookbook/_preview/9/build/era5_data_access-5602b580222ecc997288b98dd1b257e7.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This is a script designed to obtain snow data from the ERA5 reanalysis product. We will be using the Copernicus API to get global, daily snow cover and snow depth information.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aFAl8mL0ZJ"}],"key":"DxLbH7pkzW"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This code is adapted from Tasha Snow’s ERA5 downloading script: ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"cqVftefq13"},{"type":"link","url":"https://github.com/tsnow03/Landsat_SST_algorithm/blob/main/ERADownload.ipynb","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"ERADownload.ipynb","key":"V3R8DeyhYy"}],"urlSource":"https://github.com/tsnow03/Landsat_SST_algorithm/blob/main/ERADownload.ipynb","data":{"kind":"file","org":"tsnow03","repo":"Landsat_SST_algorithm","reference":"main","file":"ERADownload.ipynb","raw":"https://raw.githubusercontent.com/tsnow03/Landsat_SST_algorithm/main/ERADownload.ipynb"},"internal":false,"protocol":"github","key":"u83XSFk8rb"}],"key":"wjsNuA3uMN"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"The Copernicus Climate Data Store (CDS) API is not on CryoCloud by default, so the following cell needs to be run, followed by restarting the kernel.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"tsHApoF766"}],"key":"CtT5LIQ5Wc"}],"key":"zsnULPT3fK"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install ecmwf-api-client\n!pip install cdsapi","key":"hgQ4eoTT8p"},{"type":"output","id":"uLLsbXhIElgDLvb_nC1wV","data":[{"output_type":"stream","name":"stdout","text":"Collecting ecmwf-api-client\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading ecmwf_api_client-1.6.5-py3-none-any.whl.metadata (4.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading ecmwf_api_client-1.6.5-py3-none-any.whl (13 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: ecmwf-api-client\r\n"},{"output_type":"stream","name":"stdout","text":"Successfully installed ecmwf-api-client-1.6.5\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting cdsapi\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading cdsapi-0.7.6-py2.py3-none-any.whl.metadata (3.0 kB)\r\nCollecting ecmwf-datastores-client (from cdsapi)\r\n  Downloading ecmwf_datastores_client-0.4.0-py3-none-any.whl.metadata (21 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: requests>=2.5.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from cdsapi) (2.32.5)\r\nCollecting tqdm (from cdsapi)\r\n  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.5.0->cdsapi) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.5.0->cdsapi) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.5.0->cdsapi) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.5.0->cdsapi) (2025.8.3)\r\nRequirement already satisfied: attrs in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from ecmwf-datastores-client->cdsapi) (25.3.0)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multiurl>=0.3.7 (from ecmwf-datastores-client->cdsapi)\r\n  Downloading multiurl-0.3.7-py3-none-any.whl.metadata (2.8 kB)\r\nRequirement already satisfied: typing-extensions in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from ecmwf-datastores-client->cdsapi) (4.14.1)\r\nRequirement already satisfied: pytz in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from multiurl>=0.3.7->ecmwf-datastores-client->cdsapi) (2025.2)\r\nRequirement already satisfied: python-dateutil in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from multiurl>=0.3.7->ecmwf-datastores-client->cdsapi) (2.9.0.post0)\r\nRequirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-dateutil->multiurl>=0.3.7->ecmwf-datastores-client->cdsapi) (1.17.0)\r\nDownloading cdsapi-0.7.6-py2.py3-none-any.whl (12 kB)\r\nDownloading ecmwf_datastores_client-0.4.0-py3-none-any.whl (29 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading multiurl-0.3.7-py3-none-any.whl (21 kB)\r\nDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tqdm, multiurl, ecmwf-datastores-client, cdsapi\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [cdsapi]\r\n\u001b[?25h\r\u001b[1A\u001b[2KSuccessfully installed cdsapi-0.7.6 ecmwf-datastores-client-0.4.0 multiurl-0.3.7 tqdm-4.67.1\r\n"}],"key":"Yfv0A66mmD"}],"key":"WZP5hmyREL"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To use the CDS API, the user needs credentials to the Copernicus Climate Data Store (CDS). Upon getting a user ID (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"npT43IDtyL"},{"type":"inlineCode","value":"uid","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Q7MOkCS4jw"},{"type":"text","value":") and an API key (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FvRF9ivEUX"},{"type":"inlineCode","value":"api-key","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"mVcP5Ljl9B"},{"type":"text","value":"), they need to run the following cell (skip if you already have ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oI4WJH2dsK"},{"type":"inlineCode","value":"./cdsapirc","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UAcAgswYv3"},{"type":"text","value":" in the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"znpnmrKEuN"},{"type":"inlineCode","value":"/home/jovyan/","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"JtwnK4zDtO"},{"type":"text","value":" directory).","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UakxjnLaLf"}],"key":"OOgUpIrYWq"}],"key":"w0gOcNDEPi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# !echo url: https://cds.climate.copernicus.eu/api/v2 >> /home/jovyan/.cdsapirc\n# !echo key: {uid}:{api-key} >> /home/jovyan/.cdsapirc","key":"MDDwBnHdi3"},{"type":"output","id":"RCgZMaKlQ2pdDejpTjOTN","data":[],"key":"DWGRRhCcDk"}],"key":"unb1t6I1C6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"from ecmwfapi import ECMWFDataServer # Need a ecmwf user name and password first\nimport cdsapi","key":"p5OAwJo3Q0"},{"type":"output","id":"hFSbK_v3lpxVOq2TPhW4p","data":[],"key":"o5y0JL3Nx5"}],"key":"zH16X86fte"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The CDS API can be a bit picky with inputs from ERA5, so first-time users are encouraged to use the online request form (","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xB2nmUMzHL"},{"type":"link","url":"https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"https://​cds​.climate​.copernicus​.eu​/datasets​/reanalysis​-era5​-single​-levels​?tab​=​download","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"aI4xE5T32T"}],"urlSource":"https://cds.climate.copernicus.eu/datasets/reanalysis-era5-single-levels?tab=download","key":"g2ZDrNyjO9"},{"type":"text","value":") to automatically generate a code for their API request, to ensure that the syntax is correct.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"tdWmfpIKYA"}],"key":"k2Z6bo2ZTO"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"The below functions retrieve ERA5 snow depth and snow density and download them to a ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"HP51Lbym8i"},{"type":"inlineCode","value":"tmp/","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"aC2TQCFam3"},{"type":"text","value":" folder. Additional parameters to consider:","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"buyXDOOaQg"}],"key":"FT9q5bzeNC"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":4,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"inlineCode","value":"yearStart","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"geyCxMoJug"},{"type":"text","value":" and ","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"LzXOuAWqCh"},{"type":"inlineCode","value":"yearEnd","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"qOmUGEevWg"},{"type":"text","value":": Start and end year.","position":{"start":{"line":4,"column":1},"end":{"line":4,"column":1}},"key":"XaUBBurUqO"}],"key":"gsBeVzSIJM"},{"type":"listItem","spread":true,"position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"inlineCode","value":"monthStart","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"kNdk8oFcQb"},{"type":"text","value":" and ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"qlsE1GMxeR"},{"type":"inlineCode","value":"monthEnd","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"inZFibcZfS"},{"type":"text","value":": Start and end month.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"PjTFJUsG6l"}],"key":"jFoJ9XsVaN"},{"type":"listItem","spread":true,"position":{"start":{"line":6,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"inlineCode","value":"dayStart","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"sEXt3BRHl1"},{"type":"text","value":" and ","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"lkDe53Y9pw"},{"type":"inlineCode","value":"dayEnd","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"wn5NerHWXM"},{"type":"text","value":": Start and end day.","position":{"start":{"line":6,"column":1},"end":{"line":6,"column":1}},"key":"evPr1UHRl7"}],"key":"eow7MhdjYp"}],"key":"uFKg7w4Uik"},{"type":"paragraph","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"children":[{"type":"text","value":"The function currently grabs daily data from March 1, 2020 - April 30, 2020 at 12:00 UTC each day, and downloads as daily netCDF files. Because ERA5 is generated hourly, users can expand the ","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"kvDS3p3pH0"},{"type":"inlineCode","value":"time","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"RtoOnALlVf"},{"type":"text","value":" entry to include more hours per day.","position":{"start":{"line":8,"column":1},"end":{"line":8,"column":1}},"key":"B3gHnVnB9y"}],"key":"xlb0NjVyaE"}],"key":"PtKtFTpg7Z"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Initialize the CDS API\nc = cdsapi.Client()\n\ndef retrieve_era5():\n    \"\"\"      \n       A function to demonstrate how to iterate efficiently over several years and months etc    \n       for a particular ERA5 request.\n    \"\"\"\n    yearStart = 2020\n    yearEnd = 2020\n    monthStart = 3\n    monthEnd = 3\n    dayStart = 1\n    dayEnd = 31\n    for year in list(range(yearStart, yearEnd + 1)):\n        for month in list(range(monthStart, monthEnd + 1)):\n            for day in list(range(dayStart, dayEnd + 1)):\n                startDy = '%02d' % (day)\n                startMo = '%02d' % (month)\n                startYr = '%04d' % (year)\n                target = \"/home/jovyan/tmp/era5_SWE_%04d%02d%02d.nc\" % (year, month, day)\n                era5_request(startYr, startMo, startDy, target)\n\ndef era5_request(startYr, startMo, startDy, target):\n    \"\"\"      \n        Helper function for era5_retrieve. An ERA-5 request for snow\n        depth and snow cover data for the given years/months/days.\n\n        Inputs\n        ------------\n        startYr: str\n            Starting year of data query, in YYYY format.\n        startMo: str\n            Starting month of data query, in MM format.\n        startDy: str\n            Starting day of data query, in DD format.\n        target: str\n            Path and name of netCDF file to be saved.\n    \"\"\"\n    c.retrieve(\n    'reanalysis-era5-land',\n    {\n        'product_type':['reanalysis'],\n        'data_format':'netcdf',\n        'variable':['snow_depth', 'snow_cover'],\n        'year':[startYr],\n        'month':[startMo],\n        'day':[startDy],\n        'time':['12:00']\n    },\n    target)\n        \nif __name__ == '__main__':\n    retrieve_era5()","key":"THgGTboT1j"},{"type":"output","id":"in7AmhLyThrRk-x-sgoYw","data":[{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mException\u001b[39m                                 Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Initialize the CDS API\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m c = \u001b[43mcdsapi\u001b[49m\u001b[43m.\u001b[49m\u001b[43mClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_era5\u001b[39m():\n\u001b[32m      5\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"      \u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m       A function to demonstrate how to iterate efficiently over several years and months etc    \u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m       for a particular ERA5 request.\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/cdsapi/api.py:281\u001b[39m, in \u001b[36mClient.__new__\u001b[39m\u001b[34m(cls, url, key, *args, **kwargs)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, url=\u001b[38;5;28;01mNone\u001b[39;00m, key=\u001b[38;5;28;01mNone\u001b[39;00m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     _, token, _ = \u001b[43mget_url_key_verify\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m token:\n\u001b[32m    283\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\n\u001b[36mFile \u001b[39m\u001b[32m~/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/cdsapi/api.py:69\u001b[39m, in \u001b[36mget_url_key_verify\u001b[39m\u001b[34m(url, key, verify)\u001b[39m\n\u001b[32m     66\u001b[39m             verify = \u001b[38;5;28mbool\u001b[39m(\u001b[38;5;28mint\u001b[39m(config.get(\u001b[33m\"\u001b[39m\u001b[33mverify\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)))\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m url \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mMissing/incomplete configuration file: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m % (dotrc))\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# If verify is still None, then we set to default value of True\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\n\u001b[31mException\u001b[39m: Missing/incomplete configuration file: /home/runner/.cdsapirc","ename":"Exception","evalue":"Missing/incomplete configuration file: /home/runner/.cdsapirc"}],"key":"FHwnjAOI8Y"}],"key":"k2Qav7wcxr"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Depending on the number of files downloaded (61 in the case of the above example), it can take a while to download everything.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"yP3XsqIBjk"}],"key":"lBwzZeV1gi"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"When it finishes, there should now be daily ERA5 data in netCDF format! To efficiently load all of this data, we are going to use Xarray and its ","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"ZYb9tjbe7k"},{"type":"inlineCode","value":"open_mfdataset()","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Bi8M4Ftwvn"},{"type":"text","value":" function.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AJapS2tcYx"}],"key":"rrj59oq9Bx"}],"key":"BJhdPdELma"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import os\nimport re\nimport tempfile\nimport zipfile\nimport xarray as xr\n\nfrom os import listdir\nfrom os.path import isfile, join","key":"NiozZdKOJQ"},{"type":"output","id":"c7ITm9SarQnPvFOMN1yvm","data":[],"key":"OsxTPnGBYZ"}],"key":"jxSqtMrvLF"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"def process_era5_data(tmp_path):\n    # Find ERA5 Zip files in downloaded directory\n    era5_files = [join(tmp_path,f) for f in listdir(tmp_path) if \"era5_\" in join(tmp_path, f)]\n    \n    # Iteratively unzip each file and collect into a list\n    tmp_files = era5_extract(era5_files)\n\n    print('------------')\n    # Open all ERA5 files into single Xarray\n    ds = xr.open_mfdataset(tmp_files)\n    print(\"All data has been lazy-loaded into Xarray.\")\n\n    # Remove extracted files, for cleanliness\n    for file in tmp_files:\n        os.remove(file)\n    print(\"Extracted ERA-5 files deleted.\")\n\n    return ds\n\ndef era5_extract(era5_files):\n    for file in era5_files:\n        with zipfile.ZipFile(file, 'r') as zfile:\n            print(f'Now extracting data for file: {file}')\n            # Extract all files from current Zip file\n            zfile.extractall(tmp_path)\n\n            # Rename output file to prevent overwriting\n            outfile = join(tmp_path, \"data_0.nc\")\n            date_pattern = re.search(r'\\d{8}', file).group(0)\n            newfile = join(tmp_path, f'data_{date_pattern}.nc')\n            os.rename(outfile, newfile)\n            print(f'Data extracted and saved to file: data_{date_pattern}.nc')\n            print(' ')\n\n    # List of output files\n    tmp_files = [join(tmp_path,f) for f in os.listdir(tmp_path) if \"data_\" in join(tmp_path, f)]\n\n    return tmp_files","key":"gWJiUg6PtG"},{"type":"output","id":"JZdCxm2CwI0wPidcdFjGb","data":[],"key":"FpRbuMqQaj"}],"key":"RXy6qu70eR"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"tmp_path = \"/home/jovyan/tmp/\"\nds = process_era5_data(tmp_path)","key":"Kx8SY8DbHh"},{"type":"output","id":"mkYnItfxfR-ig4CAofRPs","data":[],"key":"D05ojZpYgB"}],"key":"l9GfJdvHRP"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"ds","key":"V56MFjkcO4"},{"type":"output","id":"IpTqH6R_y_mVrSzin9YYt","data":[],"key":"eBM8jTFiHn"}],"key":"ZKdGlZh40e"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Thanks to the above function, loading all of that data is pretty easy! However, it is important to note that the data is currently “lazy-loaded” - we can easily subset and resample the data for our needs, but we will need to load it into memory if we wish to make figures.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Y97LEt2U6v"}],"key":"kXCwRwAE8J"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Fully loading the data as is can be time-consuming, so let’s reduce the data first, starting with making monthly means of snow depth.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"oJOOO9Qnaw"}],"key":"cWEOhbuBfI"}],"key":"tmWhZ0dEJk"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate monthly mean snow depth and snow cover\nera5_monthly = ds.resample(valid_time='1ME').mean()","key":"YMxx3id8Z8"},{"type":"output","id":"wPRxkNeZvFBzZPv1XT0vc","data":[],"key":"kcF7qKTwxO"}],"key":"HItXrP7RZV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Resampling to monthly means reduces the data volume by quite a bit, so let’s now look at global snow depth from the month of March. We will go ahead and load the result into memory using the ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KbJcYVW3dM"},{"type":"inlineCode","value":"compute()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FuoVZVM78m"},{"type":"text","value":" function.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"TPCG5Y4Npe"}],"key":"UF93IoCNqm"}],"key":"ZzYNGNZVGj"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Load March snow depths into memory\nera5_sd_march = era5_monthly['snowc'].compute().squeeze()","key":"CQ4aNnVfzj"},{"type":"output","id":"j8RXevS7BIucb4LbYEoDc","data":[],"key":"XkZEsxVxR8"}],"key":"ePyYl4FEJ0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Finally, we can make a map figure showing global, monthly-averaged snow depth from ERA5.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"kc5Z3Rt2Cc"}],"key":"Vxd3Q25TtQ"}],"key":"JdXEtOvkgT"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nera5_sd_march.plot.imshow(ax=ax, cmap='Blues')\nax.set_xlabel(\"Longitude\", fontsize=12)\nax.set_ylabel(\"Latitude\", fontsize=12)\nax.set_title(\"ERA5 Snow Cover, March 2020\", fontsize=12)\nfig.tight_layout()","key":"pxOoLKhu6X"},{"type":"output","id":"aPGV9TFb7liWPT4RlZn4y","data":[],"key":"B4YlX61Xp0"}],"key":"C7jFNCO4eZ"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now for a different example. Here, we will examine snow depths over Alaska only, and generate a state-wide time series for the month of March.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"Mm4SrW21qE"}],"key":"Bof5LfeLmO"}],"key":"i9e0gVwKWy"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Making bounds for Alaska\nmask_lon = (ds.longitude >= -168.75+360) & (ds.longitude <= -136.01+360)\nmask_lat = (ds.latitude >= 52.64) & (ds.latitude <= 71.59)\n\n# Subset ERA5 data to Alaska lats/lons only\nera5_alaska = ds.where(mask_lon & mask_lat, drop=True)","key":"OJnLITBf1X"},{"type":"output","id":"yiCCH-37-SF1RSAnO0ci2","data":[],"key":"ALpySjg8VI"}],"key":"EdpG6pjVrB"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"As before, we need to load the Alaska data into memory. Because we are looking over a much smaller spatial domain, ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jDpNWRzfKm"},{"type":"inlineCode","value":"compute()","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u1qodlWLay"},{"type":"text","value":" will be much faster.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"QmyjTVgJa9"}],"key":"caiyZKbOZM"}],"key":"kup9cbZFiE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Load Alaska data into memory\nera5_alaska = era5_alaska.compute().squeeze()","key":"J0lDHabzAu"},{"type":"output","id":"W1Z5yPfJEnlk0ypaSRdck","data":[],"key":"w750auhjDM"}],"key":"GL9ueFe6mb"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Again, we can make a map figure showing snow depth over the state of Alaska, this time for March 1, 2020:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"IdKyoa4D3R"}],"key":"i58ecUiakH"}],"key":"Joqejc6UiY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Map plot of Alaska snow depths\nera5_alaska['snowc'].isel(valid_time=0).plot.imshow(vmin=0, vmax=1, cmap=\"Blues\")","key":"cXvzUk095s"},{"type":"output","id":"URs3JT94mEKAqUNjehX0S","data":[],"key":"KJQm2kPftf"}],"key":"fVGUwxnF7I"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"We can also create a spatially-averaged time series of snow depth over the state of Alaska for the entire time period March 1 - April 30:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"hja8Y0nw1R"}],"key":"l4pvBYlxMr"}],"key":"pbJtdLWEmY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate spatial average of snow depths over Alaska\nera5_sd_alaska = era5_alaska['snowc'].mean(('longitude', 'latitude'))","key":"f6cKDeOly3"},{"type":"output","id":"GeHZ3x-Df3-faF737LTXN","data":[],"key":"RxCRP98Anh"}],"key":"Xuc95amGth"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Time series plot of Alaska snow depths\nfig, ax = plt.subplots()\nera5_sd_alaska.plot(ax=ax)\nax.set_xlabel(\"Day\", fontsize=12)\nax.set_ylabel(\"Snow depth [m]\", fontsize=12)\nax.set_title(\"March 1 - April 30, 2020\", fontsize=12)\nfig.tight_layout()","key":"hviWzjfacf"},{"type":"output","id":"Ddhz4I4cqg63IOCSdI75C","data":[],"key":"ctc5Qt7dR5"}],"key":"AmnbhsH2rO"}],"key":"qWtnruQZoh"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"MERRA-2","url":"/notebooks/merra2-data-access","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}