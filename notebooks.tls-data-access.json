{"version":2,"kind":"Notebook","sha256":"05efc3d1b07660e2732c6347352fce2948a2e3ea8073ade49be56a38d1a9f731","slug":"notebooks.tls-data-access","location":"/notebooks/tls_data_access.ipynb","dependencies":[],"frontmatter":{"title":"Terrestrial Laser Scanning","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/main/notebooks/tls_data_access.ipynb","exports":[{"format":"ipynb","filename":"tls_data_access.ipynb","url":"/snow-cookbook/build/tls_data_access-24cb84fe2eb69b03833015f9c7dc9a55.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"Qd3gQX07yX"}],"key":"FNQVbrnTv6"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The TLS data is available through the cloud on NSIDC, so we will be using the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"UF4OL6zA7U"},{"type":"inlineCode","value":"earthaccess","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Lgz8qB1nDa"},{"type":"text","value":" package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Kfc7oRiaJp"}],"key":"MndbniK6or"}],"key":"fYS4d4ycb8"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install --upgrade earthaccess","key":"K3OjCieR1R"},{"type":"output","id":"4g3CyR67st3WgpcoS-sq-","data":[{"output_type":"stream","name":"stdout","text":"Collecting earthaccess\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading earthaccess-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting fsspec>=2022.11 (from earthaccess)\r\n  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting importlib-resources>=6.3.2 (from earthaccess)\r\n  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\nCollecting multimethod>=1.8 (from earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\r\nCollecting pqdm>=0.1 (from earthaccess)\r\n  Downloading pqdm-0.2.0-py2.py3-none-any.whl.metadata (3.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting python-cmr>=0.10.0 (from earthaccess)\r\n  Downloading python_cmr-0.13.0-py3-none-any.whl.metadata (10 kB)\r\nRequirement already satisfied: requests>=2.26 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (2.32.5)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting s3fs>=2022.11 (from earthaccess)\r\n  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\r\nCollecting tinynetrc>=1.3.1 (from earthaccess)\r\n  Downloading tinynetrc-1.3.1-py2.py3-none-any.whl.metadata (2.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: typing-extensions>=4.10.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (4.14.1)\r\nCollecting bounded-pool-executor (from pqdm>=0.1->earthaccess)\r\n  Downloading bounded_pool_executor-0.0.3-py3-none-any.whl.metadata (2.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tqdm (from pqdm>=0.1->earthaccess)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-cmr>=0.10.0->earthaccess) (2.9.0.post0)\r\nRequirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->python-cmr>=0.10.0->earthaccess) (1.17.0)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2025.8.3)\r\nCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiobotocore-2.24.1-py3-none-any.whl.metadata (25 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\nCollecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting botocore<1.39.12,>=1.39.9 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\r\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\nCollecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: attrs>=17.3.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess) (25.3.0)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading earthaccess-0.14.0-py3-none-any.whl (64 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\r\nDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\nDownloading multimethod-2.0-py3-none-any.whl (9.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading pqdm-0.2.0-py2.py3-none-any.whl (6.8 kB)\r\nDownloading python_cmr-0.13.0-py3-none-any.whl (14 kB)\r\nDownloading s3fs-2025.7.0-py3-none-any.whl (30 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading aiobotocore-2.24.1-py3-none-any.whl (85 kB)\r\nDownloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25h"},{"output_type":"stream","name":"stdout","text":"Downloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\nDownloading botocore-1.39.11-py3-none-any.whl (13.9 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m180.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25h"},{"output_type":"stream","name":"stdout","text":"Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\nDownloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\r\nDownloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\r\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\nDownloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\nDownloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading tinynetrc-1.3.1-py2.py3-none-any.whl (3.9 kB)\r\nDownloading bounded_pool_executor-0.0.3-py3-none-any.whl (3.4 kB)\r\nDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tinynetrc, bounded-pool-executor, wrapt, tqdm, propcache, multimethod, multidict, jmespath, importlib-resources, fsspec, frozenlist, aioitertools, aiohappyeyeballs, yarl, python-cmr, pqdm, botocore, aiosignal, aiohttp, aiobotocore, s3fs, earthaccess\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/22\u001b[0m [jmespath]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/22\u001b[0m [fsspec]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/22\u001b[0m [yarl]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m17/22\u001b[0m [aiosignal]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m18/22\u001b[0m [aiohttp]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m20/22\u001b[0m [s3fs]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [earthaccess]\r\n\u001b[?25h\r\u001b[1A\u001b[2KSuccessfully installed aiobotocore-2.24.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 botocore-1.39.11 bounded-pool-executor-0.0.3 earthaccess-0.14.0 frozenlist-1.7.0 fsspec-2025.7.0 importlib-resources-6.5.2 jmespath-1.0.1 multidict-6.6.4 multimethod-2.0 pqdm-0.2.0 propcache-0.3.2 python-cmr-0.13.0 s3fs-2025.7.0 tinynetrc-1.3.1 tqdm-4.67.1 wrapt-1.17.3 yarl-1.20.1\r\n"}],"key":"PPi2V3ESOZ"}],"key":"RwmSzKQePv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import earthaccess\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport shutil\nimport tempfile\nimport xarray as xr","key":"u1hvFo8sAg"},{"type":"output","id":"aCSC_p7JniYybb3ZMKj7j","data":[{"output_type":"stream","name":"stderr","text":"/home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"},{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mearthaccess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"xYIkgdGJUo"}],"key":"jnGaq4cnvN"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"GDEx83VaGv"}],"key":"SfQhd1but6"}],"key":"LwrKVXlbXX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate with Earthdata Login servers\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for snow-on granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-15', '2023-03-15'),\n)","key":"sFxLazsLjd"},{"type":"output","id":"swMrPrKvK_SCH_YTB1w7h","data":[],"key":"SxFqzX2oov"}],"key":"bP4ThDwfQz"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"RO37IHLfVr"},{"type":"inlineCode","value":"rioxarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oZ2M7dYOBP"},{"type":"text","value":"!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sPCpulQTnZ"}],"key":"zRvkrNkOyk"}],"key":"YODSpUoPcn"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Load a single TLS scan\nfiles = earthaccess.open(results)\nsnow_on = rxr.open_rasterio(files[1])","key":"CPbFGXrQVZ"},{"type":"output","id":"uEdyLwFgaQR84iH5rOamI","data":[],"key":"AX5TnyfxTQ"}],"key":"ocVChbaiZ8"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_on.rio.width","key":"qSixv8TNWX"},{"type":"output","id":"CTqKvFhG6ehKu52U01BzJ","data":[],"key":"ue2M7Ddesf"}],"key":"FmnFHHes5S"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"H2Kiaa1fYk"},{"type":"output","id":"QLgZMgOFUNm4rlqJR4pdG","data":[],"key":"Yq1uXsak7I"}],"key":"HpzlJpbNYV"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Two things are noticeable from this TLS data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"d8RA5uJxsG"}],"key":"LCWwzDFP5b"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It has a very high resolution (0.15 m).","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"G2SjOl0ZoP"}],"key":"MZqQs8RPd2"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The signal attenutates after ~60 m, so we have a small field of view.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"DJKC1NJmfC"}],"key":"nAQ9jETHSk"}],"key":"O8VLrxhpfz"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"is46zBluIj"}],"key":"EHNc26vH4K"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In any case, let’s grab the snow-off data from the same location, and try to derive snow depth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"iC5Tgbbgg7"}],"key":"TZ43LpeTcI"}],"key":"l0tLbdcKMY"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Now search for snow-off granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-25', '2022-10-25'),\n)","key":"NSvYgT3SE1"},{"type":"output","id":"nka1wXfTXq-NByw68Oe7m","data":[],"key":"t2OEMiceBu"}],"key":"UHKdemHKUQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"display(results)","key":"MPKiCZXtxa"},{"type":"output","id":"J9IAP2xtXsKBD5TRl-NAQ","data":[],"key":"WC8QYxeouk"}],"key":"b6r6USrPqJ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Again, load a single snow-off TLS scan\nfiles = earthaccess.open(results)\nsnow_off = rxr.open_rasterio(files[1])","key":"T7n8sQCi54"},{"type":"output","id":"TgPldKbtmAXF6ArAXOlJB","data":[],"key":"INL5eqktAa"}],"key":"j3x2QCwiQv"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"af4aWTPbxq"},{"type":"output","id":"b3FMezMfcPkBo17EDjKmy","data":[],"key":"cAm5XHMHYF"}],"key":"gOz8cfklor"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"InJjpzlFsJ"}],"key":"pt0h8AC89N"}],"key":"szOUbY5LHh"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))","key":"yT5TfTN6fK"},{"type":"output","id":"Ab0J0btg8cFYFO7XkZKy4","data":[],"key":"FpVZsgWhgG"}],"key":"Zg7XUKPM17"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"PfsMD25SB6"},{"type":"output","id":"biFvgNHe3W_ANedQ2SqJv","data":[],"key":"fiHjE8AW9a"}],"key":"UsxRHFu2ht"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"I4uuwSnniU"}],"key":"joBy9VSiPB"}],"key":"rLLvFXPdGX"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)","key":"CtjKebxu0i"},{"type":"output","id":"mpvAA6TSeY4egZDSeVjC7","data":[],"key":"IHZLknmfAo"}],"key":"Q4z3aHPSwp"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple Scans Example","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"OW3c2ZLARE"}],"identifier":"multiple-scans-example","label":"Multiple Scans Example","html_id":"multiple-scans-example","implicit":true,"key":"F6BZKnJ11D"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"dgUfgxT6bo"}],"key":"qH3rwg0aGA"}],"key":"R5Toaxr0uc"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Search for snow-on granules\nsnow_on_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-01', '2023-03-31'),\n)\n\nsnow_off_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-01', '2022-10-31'),\n)","key":"B32EvNXv7h"},{"type":"output","id":"3RjrJgYW3k-qVtr0F3eoS","data":[],"key":"qscEvaJUea"}],"key":"XLdT1Ga4sc"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create list of snow-on DataArrays\nsnow_on_files = earthaccess.open(snow_on_results)\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_files = earthaccess.open(snow_off_results)\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]","key":"VTboPnZ04r"},{"type":"output","id":"9xz8abTfgh7D4To5r3AOB","data":[],"key":"GGHWzvLBwu"}],"key":"CuHgJTM27D"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KXODuIKRO7"}],"key":"n7jeFWjO6D"}],"key":"LXrn2ztlXg"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snon_site_ids = []\nsnoff_site_ids = []\n# Get site IDs for each snow-on DataArray\nfor f in snow_on_files:\n    # Get path from file name\n    path = f.path\n    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off DataArray\nfor f in snow_off_files:\n    # Step 1: Extract path\n    path = f.path\n    # Step 2: Use regex to extract the site ID\n    # Pattern: _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(snon_site_ids)\nprint(snoff_site_ids)","key":"Q9afBF4Uy3"},{"type":"output","id":"aEEVwbDgWnOvI9fsZgWut","data":[],"key":"iMeesZTUv7"}],"key":"cL90zLikxl"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site","key":"PjX1t6Wgr2"},{"type":"output","id":"NuJvDeTIsSoSvKi25Y-6F","data":[],"key":"vfqQmAqlyg"}],"key":"gWL31efg7O"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}","key":"dizMmds8Gm"},{"type":"output","id":"PbqQqsn6nn0mNipv7nBrU","data":[],"key":"nI1C7OsUhH"}],"key":"isul8pjGo0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"oVPSQQvqIT"}],"key":"JPzuFNLdNv"}],"key":"nuejKjrw4O"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)","key":"zlgqG4R4UM"},{"type":"output","id":"qfd16lFWVgNt2wcayJIQI","data":[],"key":"rhm8WKHdoF"}],"key":"oNhuTkKVD7"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]","key":"CrXkNvs0la"},{"type":"output","id":"i_mVB-8MaeiI1yos75UHo","data":[],"key":"JcDLNJyezJ"}],"key":"NA2WTSND62"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"NAnOqcv2AR"}],"key":"s8txA4qDWy"}],"key":"CmiGOVRzLD"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)","key":"gTOVnBMych"},{"type":"output","id":"ahXmz4pA8bepZHhFWClKe","data":[],"key":"v5WZNJM6s7"}],"key":"UTuqPEg2gr"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()","key":"fvtrbkQFot"},{"type":"output","id":"lIqSAZfK32HBgqAWv3w7P","data":[],"key":"R9TLaKb9PJ"}],"key":"pWIGnEG07Z"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"j0YXXsVVky"}],"key":"RkrF3oPCP1"}],"key":"a5S7v1xvpK"}],"key":"dhEwQkkJyF"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"AVIRIS-NG","url":"/notebooks/aviris-ng-data","group":"Observations"},"next":{"title":"Neural Networks with PyTorch","url":"/notebooks/pytorch-tutorial","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}