{"version":2,"kind":"Notebook","sha256":"05efc3d1b07660e2732c6347352fce2948a2e3ea8073ade49be56a38d1a9f731","slug":"notebooks.tls-data-access","location":"/notebooks/tls_data_access.ipynb","dependencies":[],"frontmatter":{"title":"Terrestrial Laser Scanning","content_includes_title":false,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"authors":[{"nameParsed":{"literal":"The SnowPit Community","given":"The SnowPit","family":"Community"},"name":"The SnowPit Community","id":"contributors-myst-generated-uid-0"}],"open_access":true,"license":{"content":{"id":"CC-BY-4.0","url":"https://creativecommons.org/licenses/by/4.0/","name":"Creative Commons Attribution 4.0 International","free":true,"CC":true},"code":{"id":"Apache-2.0","url":"https://opensource.org/licenses/Apache-2.0","name":"Apache License 2.0","free":true,"osi":true}},"github":"https://github.com/SnowEx/snow-cookbook","copyright":"2025","affiliations":[{"id":"UAlbany","name":"University at Albany (SUNY)","department":"Atmospheric and Environmental Sciences","url":"https://www.albany.edu/daes"},{"id":"CISL","name":"NSF National Center for Atmospheric Research","department":"Computational and Information Systems Lab","url":"https://www.cisl.ucar.edu"},{"id":"Unidata","name":"NSF Unidata","url":"https://www.unidata.ucar.edu"},{"id":"Argonne","name":"Argonne National Laboratory","department":"Environmental Science Division","url":"https://www.anl.gov/evs"},{"id":"CarbonPlan","name":"CarbonPlan","url":"https://carbonplan.org"},{"id":"NVIDIA","name":"NVIDIA Corporation","url":"https://www.nvidia.com/"}],"numbering":{"title":{"offset":1}},"edit_url":"https://github.com/SnowEx/snow-cookbook/blob/main/notebooks/tls_data_access.ipynb","exports":[{"format":"ipynb","filename":"tls_data_access.ipynb","url":"/snow-cookbook/build/tls_data_access-75840d4b85e207a700705cdbffa95755.ipynb"}]},"widgets":{},"mdast":{"type":"root","children":[{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"AiGLk9Xqzh"}],"key":"y4WGMF88kH"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"The TLS data is available through the cloud on NSIDC, so we will be using the ","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"Dn04lCXSdG"},{"type":"inlineCode","value":"earthaccess","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"zqj9U1GoQp"},{"type":"text","value":" package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"nQadzkncTF"}],"key":"tqJa5WSBNF"}],"key":"iWr2A9pqxR"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"!pip install --upgrade earthaccess","key":"uPUBGwLX9a"},{"type":"output","id":"xKGUHaI0btdNbi6cMkIG2","data":[{"output_type":"stream","name":"stdout","text":"Collecting earthaccess\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading earthaccess-0.14.0-py3-none-any.whl.metadata (8.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting fsspec>=2022.11 (from earthaccess)\r\n  Downloading fsspec-2025.7.0-py3-none-any.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting importlib-resources>=6.3.2 (from earthaccess)\r\n  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multimethod>=1.8 (from earthaccess)\r\n  Downloading multimethod-2.0-py3-none-any.whl.metadata (9.2 kB)\r\nCollecting pqdm>=0.1 (from earthaccess)\r\n  Downloading pqdm-0.2.0-py2.py3-none-any.whl.metadata (3.2 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting python-cmr>=0.10.0 (from earthaccess)\r\n  Downloading python_cmr-0.13.0-py3-none-any.whl.metadata (10 kB)\r\nRequirement already satisfied: requests>=2.26 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (2.32.5)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting s3fs>=2022.11 (from earthaccess)\r\n  Downloading s3fs-2025.7.0-py3-none-any.whl.metadata (1.4 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tinynetrc>=1.3.1 (from earthaccess)\r\n  Downloading tinynetrc-1.3.1-py2.py3-none-any.whl.metadata (2.9 kB)\r\nRequirement already satisfied: typing-extensions>=4.10.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from earthaccess) (4.14.1)\r\nCollecting bounded-pool-executor (from pqdm>=0.1->earthaccess)\r\n  Downloading bounded_pool_executor-0.0.3-py3-none-any.whl.metadata (2.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting tqdm (from pqdm>=0.1->earthaccess)\r\n  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-cmr>=0.10.0->earthaccess) (2.9.0.post0)\r\nRequirement already satisfied: six>=1.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from python-dateutil<3.0.0,>=2.8.2->python-cmr>=0.10.0->earthaccess) (1.17.0)\r\nRequirement already satisfied: charset_normalizer<4,>=2 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.4.3)\r\nRequirement already satisfied: idna<4,>=2.5 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (3.10)\r\nRequirement already satisfied: urllib3<3,>=1.21.1 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2.5.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from requests>=2.26->earthaccess) (2025.8.3)\r\nCollecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2022.11->earthaccess)\r\n  Downloading aiobotocore-2.24.1-py3-none-any.whl.metadata (25 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from s3fs>=2022.11->earthaccess)\r\n  Downloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting botocore<1.39.12,>=1.39.9 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading botocore-1.39.11-py3-none-any.whl.metadata (5.7 kB)\r\nCollecting jmespath<2.0.0,>=0.7.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting multidict<7.0.0,>=6.0.0 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting wrapt<2.0.0,>=1.10.10 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2022.11->earthaccess)\r\n  Downloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\r\nCollecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\nRequirement already satisfied: attrs>=17.3.0 in /home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess) (25.3.0)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n  Downloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->s3fs>=2022.11->earthaccess)\r\n"},{"output_type":"stream","name":"stdout","text":"  Downloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\r\nDownloading earthaccess-0.14.0-py3-none-any.whl (64 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading fsspec-2025.7.0-py3-none-any.whl (199 kB)\r\nDownloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\r\nDownloading multimethod-2.0-py3-none-any.whl (9.8 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading pqdm-0.2.0-py2.py3-none-any.whl (6.8 kB)\r\nDownloading python_cmr-0.13.0-py3-none-any.whl (14 kB)\r\nDownloading s3fs-2025.7.0-py3-none-any.whl (30 kB)\r\nDownloading aiobotocore-2.24.1-py3-none-any.whl (85 kB)\r\nDownloading aiohttp-3.12.15-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\r\nDownloading botocore-1.39.11-py3-none-any.whl (13.9 MB)\r\n\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/13.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m13.6/13.9 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\r\n\u001b[?25h"},{"output_type":"stream","name":"stdout","text":"Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\r\nDownloading multidict-6.6.4-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (254 kB)\r\nDownloading wrapt-1.17.3-cp313-cp313-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\r\nDownloading yarl-1.20.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\r\nDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\nDownloading frozenlist-1.7.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (232 kB)\r\nDownloading propcache-0.3.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\r\nDownloading tinynetrc-1.3.1-py2.py3-none-any.whl (3.9 kB)\r\nDownloading bounded_pool_executor-0.0.3-py3-none-any.whl (3.4 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\r\n"},{"output_type":"stream","name":"stdout","text":"Installing collected packages: tinynetrc, bounded-pool-executor, wrapt, tqdm, propcache, multimethod, multidict, jmespath, importlib-resources, fsspec, frozenlist, aioitertools, aiohappyeyeballs, yarl, python-cmr, pqdm, botocore, aiosignal, aiohttp, aiobotocore, s3fs, earthaccess\r\n\u001b[?25l"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/22\u001b[0m [fsspec]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/22\u001b[0m [yarl]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m16/22\u001b[0m [botocore]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m18/22\u001b[0m [aiohttp]"},{"output_type":"stream","name":"stdout","text":"\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [earthaccess]\r\n\u001b[?25h\r\u001b[1A\u001b[2K"},{"output_type":"stream","name":"stdout","text":"Successfully installed aiobotocore-2.24.1 aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aioitertools-0.12.0 aiosignal-1.4.0 botocore-1.39.11 bounded-pool-executor-0.0.3 earthaccess-0.14.0 frozenlist-1.7.0 fsspec-2025.7.0 importlib-resources-6.5.2 jmespath-1.0.1 multidict-6.6.4 multimethod-2.0 pqdm-0.2.0 propcache-0.3.2 python-cmr-0.13.0 s3fs-2025.7.0 tinynetrc-1.3.1 tqdm-4.67.1 wrapt-1.17.3 yarl-1.20.1\r\n"}],"key":"WXCwUFDjMM"}],"key":"T5jxladlNd"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"import earthaccess\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport re\nimport rioxarray as rxr\nimport shutil\nimport tempfile\nimport xarray as xr","key":"cdFedH4pSo"},{"type":"output","id":"OYOnfPJGHk_jrl3YuCm74","data":[{"output_type":"stream","name":"stderr","text":"/home/runner/micromamba/envs/cookbook-dev/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"},{"output_type":"error","traceback":"\u001b[31m---------------------------------------------------------------------------\u001b[39m\n\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)\n\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mearthaccess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\n\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'","ename":"ModuleNotFoundError","evalue":"No module named 'matplotlib'"}],"key":"jKVsmsXBeN"}],"key":"XqABz7ISaS"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"VMoal3OaaF"}],"key":"ZrXPTLMdxN"}],"key":"s3eYLJ5xDA"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Authenticate with Earthdata Login servers\nauth = earthaccess.login(strategy=\"interactive\")\n\n# Search for snow-on granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-15', '2023-03-15'),\n)","key":"jg4hA4NEce"},{"type":"output","id":"rgs54RZkN3TiwamTG2M2I","data":[],"key":"DIbSUh90z5"}],"key":"pOzu2vgEt0"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with ","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"ZOrPC4h7v9"},{"type":"inlineCode","value":"rioxarray","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"sUkkNV83lR"},{"type":"text","value":"!","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"u6bC8p9kkT"}],"key":"TkeaLDPzaC"}],"key":"Oja6yvlFsp"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Load a single TLS scan\nfiles = earthaccess.open(results)\nsnow_on = rxr.open_rasterio(files[1])","key":"vi3jk3YYP0"},{"type":"output","id":"luYYdwJ4JE5b0GFQd8nfY","data":[],"key":"AWXdfHr2Sq"}],"key":"jWaCFiLaIQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_on.rio.width","key":"kN5lkbzj1j"},{"type":"output","id":"Y6eZMvKekalRBqkX0JVUM","data":[],"key":"nLnlqcU0lE"}],"key":"zpZke85O04"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Visualize the snow-on data\nfig, ax = plt.subplots()\nsnow_on.plot(ax=ax, vmin=123, vmax=126,\n             cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"kNeJItwl5R"},{"type":"output","id":"AFa8WChYj0Welyhksj5ZE","data":[],"key":"Ocoa5iJmp5"}],"key":"AWRIj5BB9G"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Two things are noticeable from this TLS data:","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"UQb2GOBOCh"}],"key":"mc6DUp3NWy"},{"type":"list","ordered":true,"start":1,"spread":false,"position":{"start":{"line":2,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"children":[{"type":"text","value":"It has a very high resolution (0.15 m).","position":{"start":{"line":2,"column":1},"end":{"line":2,"column":1}},"key":"ER1krDGhS5"}],"key":"uLZD7TyuwP"},{"type":"listItem","spread":true,"position":{"start":{"line":3,"column":1},"end":{"line":4,"column":1}},"children":[{"type":"text","value":"The signal attenutates after ~60 m, so we have a small field of view.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"mnCK4M2HeQ"}],"key":"adBdO8iriV"}],"key":"GFaL5DcQND"},{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"YefazKQsH5"}],"key":"UlVXvsvumH"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"In any case, let’s grab the snow-off data from the same location, and try to derive snow depth.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"ySD18nIgQR"}],"key":"UtdZB2v6h0"}],"key":"tRlvBvuWNi"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Now search for snow-off granules\nresults = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-25', '2022-10-25'),\n)","key":"e8HDbqH1cN"},{"type":"output","id":"NjXm47F5G5K5AWR-8HYUY","data":[],"key":"bsaP0rIVWa"}],"key":"N3l77aLcux"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"display(results)","key":"oovzDe2tO5"},{"type":"output","id":"L1LjakTJJbRr5MiJ9p25s","data":[],"key":"UC1VtF3nct"}],"key":"vLIdQwcsvG"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Again, load a single snow-off TLS scan\nfiles = earthaccess.open(results)\nsnow_off = rxr.open_rasterio(files[1])","key":"Rz5vo4tvTs"},{"type":"output","id":"CJ9-AlVHmVsy58SqWT4du","data":[],"key":"N0VW5avJ6I"}],"key":"Y31V1sU3OQ"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"fig, ax = plt.subplots()\nsnow_off.plot(vmin=123, vmax=126,\n              cbar_kwargs={'label': \"Elevation [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"oMKDupuBr9"},{"type":"output","id":"jVBQW2O0bmTwxlYWuxcqY","data":[],"key":"L9ZVTLP5XE"}],"key":"p2qxa5IOfA"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"jwvcTQ4TrK"}],"key":"zmpgiPLZNp"}],"key":"qRhu73Un7I"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Interpolate snow-on data onto the x/y grid of snow-off data\nsnow_on_interp = snow_on.interp(\n    x=snow_off.x,\n    y=snow_off.y,\n    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n)\n\n# Calculate the difference (snow depth)\ndifference = snow_on_interp - snow_off\n\n# Define fill values in data\nfill = snow_off.attrs.get('_FillValue', -9999.0)\n\n# Include only data that is not equal to the fill value\ndifference = difference.where((snow_off != fill) & (snow_on_interp != fill))","key":"tSlaq1n0X4"},{"type":"output","id":"leeHGG06kOvjI1ba_OLQC","data":[],"key":"VzVjjQJ2EA"}],"key":"ABs7Wbv94R"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot snow depth over the TLS scene\nfig, ax = plt.subplots()\ndifference.plot(vmin=0, vmax=1.5,\n                cbar_kwargs={'label': \"Snow depth [m]\"})\nax.set_xlabel(\"Easting [m]\")\nax.set_ylabel(\"Northing [m]\")\nax.set_title(\" \")","key":"a03XneR5xN"},{"type":"output","id":"ilJu6p-iC58s1kMmNKTvT","data":[],"key":"UEFllZ9nDg"}],"key":"C5x2lf6zNR"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"KDiUxResO2"}],"key":"sT9ZybmsXY"}],"key":"dJpsteUGUK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Calculate median snow depth over the scene\nmedian_depth = difference.where(difference>=0).median()\n\n# Make histogram plot of snow depth\nfig, ax = plt.subplots()\ndifference.where(difference>=0).plot.hist(ax=ax, bins=50)\nax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\nax.set_xlim([0, 2.5])\nax.set_ylabel(\"Counts\")\nax.set_xlabel(\"Snow depth [m]\")\nax.set_title(' ')\nax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)","key":"k5cuddRXe1"},{"type":"output","id":"0MXg4tlEM8k95gjVLtVeu","data":[],"key":"m2W6Usfv7M"}],"key":"vDJ37Q8bK4"},{"type":"block","kind":"notebook-content","children":[{"type":"heading","depth":2,"position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Multiple Scans Example","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"k26ik0goKk"}],"identifier":"multiple-scans-example","label":"Multiple Scans Example","html_id":"multiple-scans-example","implicit":true,"key":"ISHsNAy4Oh"},{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations.","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"D5hslXqPsZ"}],"key":"WziCYL2Oj1"}],"key":"Y9XDY6msFp"},{"type":"block","kind":"notebook-code","data":{"scrolled":true},"children":[{"type":"code","lang":"python","executable":true,"value":"# Search for snow-on granules\nsnow_on_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2023-03-01', '2023-03-31'),\n)\n\nsnow_off_results = earthaccess.search_data(\n    #short_name=\"SNEX23_BCEF_TLS\",\n    doi = \"10.5067/R466GRXNA61S\",\n    temporal=('2022-10-01', '2022-10-31'),\n)","key":"qcm6cPYaX2"},{"type":"output","id":"WZAc9RNTLpnzylhDlOSiT","data":[],"key":"wbpmiYUw4D"}],"key":"GeUGDBt2mx"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create list of snow-on DataArrays\nsnow_on_files = earthaccess.open(snow_on_results)\nsnow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n\n# Create list of snow-off DataArrays\nsnow_off_files = earthaccess.open(snow_off_results)\nsnow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]","key":"QNMZivXODQ"},{"type":"output","id":"bkmJLuty8ZhFSbFP4YV3P","data":[],"key":"FW7Ep8u0ul"}],"key":"RVJom5z2gi"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"FtHpKhB1fZ"}],"key":"CMTlk5hOQG"}],"key":"zgLw4FVjA6"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snon_site_ids = []\nsnoff_site_ids = []\n# Get site IDs for each snow-on DataArray\nfor f in snow_on_files:\n    # Get path from file name\n    path = f.path\n    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n    if m:\n        snon_site_ids.append(m.group(2))\n    else:\n        snon_site_ids.append(\"unknown\")\n\n# Get site IDs for each snow-off DataArray\nfor f in snow_off_files:\n    # Step 1: Extract path\n    path = f.path\n    # Step 2: Use regex to extract the site ID\n    # Pattern: _SW_YYYYMMDD_SITEID_V\n    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n    if m:\n        snoff_site_ids.append(m.group(2))\n    else:\n        snoff_site_ids.append(\"unknown\")\n\nprint(snon_site_ids)\nprint(snoff_site_ids)","key":"cpkYOo6QJd"},{"type":"output","id":"h829ax1BbC_gfuYyUarPd","data":[],"key":"SaxYJm161L"}],"key":"pD1RNljnmb"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Add site ID to attributes of DataArrays\nfor r, site in zip(snow_on_rasters, snon_site_ids):\n    r.attrs['site_id'] = site\n\nfor r, site in zip(snow_off_rasters, snoff_site_ids):\n    r.attrs['site_id'] = site","key":"sTANAkpWcS"},{"type":"output","id":"2--aq5xNUIzyZwPOgKE7s","data":[],"key":"mojMGEis30"}],"key":"t1sJ4yi8oE"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create dictionaries linking each DataArray to a site ID\nsnow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\nsnow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}","key":"lWWhZyxN26"},{"type":"output","id":"jNmpVOy-P3Ng8FQ6LrXG5","data":[],"key":"pWmmCOQFo2"}],"key":"v19Lg111gl"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"xHCep8O7nD"}],"key":"HPlAsQMing"}],"key":"wpA7GBhIIR"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Determine site IDs with recorded data for both snow-off and snow-on season\ncommon_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\nprint(\"Common site IDs:\", common_site_ids)","key":"vCrMocXsjF"},{"type":"output","id":"aSuTedEjlY6aYUI9nMfhc","data":[],"key":"FrwK0pJO2Q"}],"key":"eQINfTT1hM"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Create lists of DataArrays for the common sites only\nsnow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\nsnow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]","key":"hasTXMW99U"},{"type":"output","id":"JWu-HyloZpot_TC9uHsGf","data":[],"key":"dudeO6LIdl"}],"key":"N8KVlLaGYt"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"syPjHQwOyn"}],"key":"WFxEYFAiJX"}],"key":"W7ylrKmKUt"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"snow_depths = []\n# Interpolate DataArrays and derive snow depth, as before\nfor so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n    # Interpolate snow-on data onto the x/y grid of snow-off data\n    tmp_interp = so.interp(\n        x=soff.x,\n        y=soff.y,\n    )\n\n    tmp_diff = tmp_interp - soff\n    tmp_diff.attrs['site_id'] = site\n\n    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n    snow_depths.append(tmp_diff)","key":"iKOCHIiibo"},{"type":"output","id":"e0fKL_1ozdQHzecEbz5l7","data":[],"key":"JGioNGu26s"}],"key":"hP89aWTJeK"},{"type":"block","kind":"notebook-code","children":[{"type":"code","lang":"python","executable":true,"value":"# Plot the derived snow depths in a 3x3 figure\nfig, axes = plt.subplots(3, 3, figsize=(12, 12))\naxes = axes.flatten()\n\nfor idx, data_array in enumerate(snow_depths):\n    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n\nplt.tight_layout()\nplt.show()","key":"qOmSmM6toD"},{"type":"output","id":"W3L-xH-vSA9ifdKZ23TqL","data":[],"key":"IF3otMvZ6q"}],"key":"vfwYSYHdng"},{"type":"block","kind":"notebook-content","children":[{"type":"paragraph","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"children":[{"type":"text","value":"That’s all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods.","position":{"start":{"line":1,"column":1},"end":{"line":1,"column":1}},"key":"XRfpHPIV83"}],"key":"YoKdKjQeK6"}],"key":"ukDbIPDpte"}],"key":"YvZv9W6HYv"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"AVIRIS-NG","url":"/notebooks/aviris-ng-data","group":"Observations"},"next":{"title":"Neural Networks with PyTorch","url":"/notebooks/pytorch-tutorial","group":"Analysis and Machine Learning"}}},"domain":"http://localhost:3000"}