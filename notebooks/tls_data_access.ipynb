{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55d3b72c-7259-442f-a813-1b6786813c73",
   "metadata": {},
   "source": [
    "# Terrestrial Laser Scanning\n",
    "\n",
    "This notebook is designed to take terrestrial laser scanner (TLS) data from the SnowEx Alaska Campaigns and derive snow depth. The TLS data is provided in both a raw point cloud format and a processed DEM format. For this example, we will be focusing on the TLS DEMs.\n",
    "\n",
    "The TLS data is available through the cloud on NSIDC, so we will be using the `earthaccess` package. The first example will involve a single TLS image for simplicity, then we will have a second example that examines multiple TLS scans from the campaigns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d61528f-612a-442d-a04a-2332adea56e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import earthaccess\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import rioxarray as rxr\n",
    "import shutil\n",
    "import tempfile\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c960be-fb35-4366-b71f-080f8fd91005",
   "metadata": {},
   "source": [
    "The TLS data was gathered in Bonanza Creek near Fairbanks, AK in two months: October 2022 and March 2023. These months correspond to the snow-off and snow-on seasons, respectively. We will start by getting some sample snow-on TLS data from a single day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ff49cc-6d5b-4c31-8881-a9dc913b8ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Earthdata Login servers\n",
    "auth = earthaccess.login(strategy=\"interactive\")\n",
    "\n",
    "# Search for snow-on granules\n",
    "results = earthaccess.search_data(\n",
    "    #short_name=\"SNEX23_BCEF_TLS\",\n",
    "    doi = \"10.5067/R466GRXNA61S\",\n",
    "    temporal=('2023-03-15', '2023-03-15'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b86078-7d41-4141-8c5a-2eef894eb02f",
   "metadata": {},
   "source": [
    "Because the TLS data is available on-demand through the cloud, we do not need to download it. Instead, we can stream it directly with `rioxarray`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935bddb-77bd-44a6-9f16-840954d28fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load a single TLS scan\n",
    "files = earthaccess.open(results)\n",
    "snow_on = rxr.open_rasterio(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2842243-956e-4e4a-906c-0d3c521a9b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_on.rio.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e49cfef-3705-47ff-84fa-02e3e3f607f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the snow-on data\n",
    "fig, ax = plt.subplots()\n",
    "snow_on.plot(ax=ax, vmin=123, vmax=126,\n",
    "             cbar_kwargs={'label': \"Elevation [m]\"})\n",
    "ax.set_xlabel(\"Easting [m]\")\n",
    "ax.set_ylabel(\"Northing [m]\")\n",
    "ax.set_title(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128c4a43-dafc-433c-85f0-51f51b48bb8c",
   "metadata": {},
   "source": [
    "Two things are noticeable from this TLS data:\n",
    "1. It has a very high resolution (0.15 m).\n",
    "2. The signal attenutates after ~60 m, so we have a small field of view.\n",
    "\n",
    "This suggests that we will be able to obtain very fine-scale measurements of snow depth, but we will need scans from multiple locations to better characterize snow in Bonanza Creek.\n",
    "\n",
    "In any case, let's grab the snow-off data from the same location, and try to derive snow depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f490497-d462-4ecb-9917-2b9216a713fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now search for snow-off granules\n",
    "results = earthaccess.search_data(\n",
    "    #short_name=\"SNEX23_BCEF_TLS\",\n",
    "    doi = \"10.5067/R466GRXNA61S\",\n",
    "    temporal=('2022-10-25', '2022-10-25'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325883d1-b613-49ec-b1db-afa858910f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c549c9-cfea-411d-839a-d6d0654ed444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, load a single snow-off TLS scan\n",
    "files = earthaccess.open(results)\n",
    "snow_off = rxr.open_rasterio(files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c68c4e2-3d4e-4224-b289-ee234f3e7fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "snow_off.plot(vmin=123, vmax=126,\n",
    "              cbar_kwargs={'label': \"Elevation [m]\"})\n",
    "ax.set_xlabel(\"Easting [m]\")\n",
    "ax.set_ylabel(\"Northing [m]\")\n",
    "ax.set_title(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3898fa-8e20-46e2-9084-f5b58d033215",
   "metadata": {},
   "source": [
    "Although the snow-on/-off data look similar to each other, there are slight differences, meaning that we cannot perform a difference right away. We must first interpolate the data, ensuring that fill values are accounted for, then perform the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d349b6-dc6f-4fcf-be67-661ae311eab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate snow-on data onto the x/y grid of snow-off data\n",
    "snow_on_interp = snow_on.interp(\n",
    "    x=snow_off.x,\n",
    "    y=snow_off.y,\n",
    "    kwargs={\"fill_value\": snow_on.attrs.get('_FillValue', np.nan)}\n",
    ")\n",
    "\n",
    "# Calculate the difference (snow depth)\n",
    "difference = snow_on_interp - snow_off\n",
    "\n",
    "# Define fill values in data\n",
    "fill = snow_off.attrs.get('_FillValue', -9999.0)\n",
    "\n",
    "# Include only data that is not equal to the fill value\n",
    "difference = difference.where((snow_off != fill) & (snow_on_interp != fill))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3e3d08-0d1d-48b1-bfe4-75a27946d603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot snow depth over the TLS scene\n",
    "fig, ax = plt.subplots()\n",
    "difference.plot(vmin=0, vmax=1.5,\n",
    "                cbar_kwargs={'label': \"Snow depth [m]\"})\n",
    "ax.set_xlabel(\"Easting [m]\")\n",
    "ax.set_ylabel(\"Northing [m]\")\n",
    "ax.set_title(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716ed774-1466-4443-bf04-6ab839df4925",
   "metadata": {},
   "source": [
    "Although not perfect, this provides a very reasonable snow depth DEM for the TLS data gathered in this location. If we want, we can perform basic statistics on the derived snow depths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b293a7-79e5-4c72-9a2d-6d9c7c7a44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate median snow depth over the scene\n",
    "median_depth = difference.where(difference>=0).median()\n",
    "\n",
    "# Make histogram plot of snow depth\n",
    "fig, ax = plt.subplots()\n",
    "difference.where(difference>=0).plot.hist(ax=ax, bins=50)\n",
    "ax.axvline(x=median_depth, color='black', linewidth=2, linestyle='--') # Median depth line\n",
    "ax.set_xlim([0, 2.5])\n",
    "ax.set_ylabel(\"Counts\")\n",
    "ax.set_xlabel(\"Snow depth [m]\")\n",
    "ax.set_title(' ')\n",
    "ax.text(1, 8000, f'Median depth = {median_depth:.2f} m', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a1598-c662-4378-b407-38339d008e08",
   "metadata": {},
   "source": [
    "# Multiple Scans Example\n",
    "\n",
    "Because we can stream the TLS data through the cloud, this example is very similar to the above code. The main exception is that we will generate a list of DataArrays, from which we derive snow depth for three TLS scanning locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e002c0-a473-45e5-b940-89218fb18d96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Search for snow-on granules\n",
    "snow_on_results = earthaccess.search_data(\n",
    "    #short_name=\"SNEX23_BCEF_TLS\",\n",
    "    doi = \"10.5067/R466GRXNA61S\",\n",
    "    temporal=('2023-03-01', '2023-03-31'),\n",
    ")\n",
    "\n",
    "snow_off_results = earthaccess.search_data(\n",
    "    #short_name=\"SNEX23_BCEF_TLS\",\n",
    "    doi = \"10.5067/R466GRXNA61S\",\n",
    "    temporal=('2022-10-01', '2022-10-31'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f71a80-c118-48db-9790-0d0c4ca86a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of snow-on DataArrays\n",
    "snow_on_files = earthaccess.open(snow_on_results)\n",
    "snow_on_rasters = [rxr.open_rasterio(f) for f in snow_on_files]\n",
    "\n",
    "# Create list of snow-off DataArrays\n",
    "snow_off_files = earthaccess.open(snow_off_results)\n",
    "snow_off_rasters = [rxr.open_rasterio(f) for f in snow_off_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea76e66f-41ed-4b28-a947-2da627252f3f",
   "metadata": {},
   "source": [
    "To make the final plot of this example cleaner, we will assign each TLS scan a label based on the site ID at Bonanza Creek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8921f25-f09b-4e90-8d1f-4bbe7da8b4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "snon_site_ids = []\n",
    "snoff_site_ids = []\n",
    "# Get site IDs for each snow-on DataArray\n",
    "for f in snow_on_files:\n",
    "    # Get path from file name\n",
    "    path = f.path\n",
    "    # Use regex to extract the site ID from file path, given pattern _SW_YYYYMMDD_SITEID_V\n",
    "    m = re.search(r'_(SW|N)_\\d{8}_(.*?)_V', path)\n",
    "    if m:\n",
    "        snon_site_ids.append(m.group(2))\n",
    "    else:\n",
    "        snon_site_ids.append(\"unknown\")\n",
    "\n",
    "# Get site IDs for each snow-off DataArray\n",
    "for f in snow_off_files:\n",
    "    # Step 1: Extract path\n",
    "    path = f.path\n",
    "    # Step 2: Use regex to extract the site ID\n",
    "    # Pattern: _SW_YYYYMMDD_SITEID_V\n",
    "    m = re.search(r'_(SW|N|NE)_\\d{8}_(.*?)_V', path)\n",
    "    if m:\n",
    "        snoff_site_ids.append(m.group(2))\n",
    "    else:\n",
    "        snoff_site_ids.append(\"unknown\")\n",
    "\n",
    "print(snon_site_ids)\n",
    "print(snoff_site_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00163878-ba4e-40e8-8946-e3ce577d09ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add site ID to attributes of DataArrays\n",
    "for r, site in zip(snow_on_rasters, snon_site_ids):\n",
    "    r.attrs['site_id'] = site\n",
    "\n",
    "for r, site in zip(snow_off_rasters, snoff_site_ids):\n",
    "    r.attrs['site_id'] = site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf7b98a-5a7c-4148-a1e2-73f158ba192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries linking each DataArray to a site ID\n",
    "snow_on_dict = {r.attrs['site_id']: r for r in snow_on_rasters}\n",
    "snow_off_dict = {r.attrs['site_id']: r for r in snow_off_rasters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c16ff67-7cdf-4b9d-9180-4bdd55eadafa",
   "metadata": {},
   "source": [
    "Now each TLS scan is linked to a site ID. However, we can see that the snow-on data has many more scans than the snow-off data. Because snow depth data is our priority, we will only consider snow-on scans that share a site ID with the snow-off data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974690a-e98e-47f5-92e5-b69e3a809e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine site IDs with recorded data for both snow-off and snow-on season\n",
    "common_site_ids = sorted(set(snow_on_dict).intersection(snow_off_dict))\n",
    "print(\"Common site IDs:\", common_site_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cfc391-1bb3-4f45-9b25-243de16d7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of DataArrays for the common sites only\n",
    "snow_on_paired = [snow_on_dict[sid] for sid in common_site_ids]\n",
    "snow_off_paired = [snow_off_dict[sid] for sid in common_site_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7d82db-3bf8-4ddc-85fb-d8e7f4b5d812",
   "metadata": {},
   "source": [
    "Now that the site IDs are matched, deriving snow depth is the same as the first example, only with looping to make the calculation (and plotting) easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b2bac-c565-4d57-a36d-5c497bb37315",
   "metadata": {},
   "outputs": [],
   "source": [
    "snow_depths = []\n",
    "# Interpolate DataArrays and derive snow depth, as before\n",
    "for so, soff, site in zip(snow_on_paired, snow_off_paired, common_site_ids):\n",
    "    # Interpolate snow-on data onto the x/y grid of snow-off data\n",
    "    tmp_interp = so.interp(\n",
    "        x=soff.x,\n",
    "        y=soff.y,\n",
    "    )\n",
    "\n",
    "    tmp_diff = tmp_interp - soff\n",
    "    tmp_diff.attrs['site_id'] = site\n",
    "\n",
    "    tmp_diff = tmp_diff.where((tmp_diff[0]>0)&(tmp_diff[0]<=2))\n",
    "    snow_depths.append(tmp_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf471833-7362-4dec-a7d1-22cc0d4c8ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the derived snow depths in a 3x3 figure\n",
    "fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, data_array in enumerate(snow_depths):\n",
    "    data_array.plot(ax=axes[idx], vmin=0, vmax=2)\n",
    "    axes[idx].set_title(f\"{snow_depths[idx].attrs['site_id']}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e18499-cb48-492a-9c73-cf8fa6e31956",
   "metadata": {},
   "source": [
    "That's all there is to it! Some of the coverage is a bit sparse, and the depths over site DEC look rather high, but we otherwise have reasonable snow depths over 9 sites in Bonanza Creek. These could then be compared to other ground based efforts or airborne data to cross-calibrate observation methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
